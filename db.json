{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/CNAME","path":"CNAME","modified":1,"renderable":0},{"_id":"themes/clean-blog/source/css/article.styl","path":"css/article.styl","modified":1,"renderable":1},{"_id":"themes/clean-blog/source/css/base.styl","path":"css/base.styl","modified":1,"renderable":1},{"_id":"themes/clean-blog/source/css/mixins.styl","path":"css/mixins.styl","modified":1,"renderable":1},{"_id":"themes/clean-blog/source/css/style.styl","path":"css/style.styl","modified":1,"renderable":1},{"_id":"themes/clean-blog/source/css/variables.styl","path":"css/variables.styl","modified":1,"renderable":1},{"_id":"themes/clean-blog/source/img/about-bg.jpg","path":"img/about-bg.jpg","modified":1,"renderable":1},{"_id":"source/images/pasted-0.png","path":"images/pasted-0.png","modified":1,"renderable":0},{"_id":"themes/clean-blog/source/img/home-bg.jpg","path":"img/home-bg.jpg","modified":1,"renderable":1},{"_id":"themes/clean-blog/source/img/contact-bg.jpg","path":"img/contact-bg.jpg","modified":1,"renderable":1}],"Cache":[{"_id":"source/CNAME","hash":"04271e73b293a955602e93a3dcfed4cc9d7473de","modified":1541684479804},{"_id":"source/.DS_Store","hash":"35b6916db88e3a4e6fddd0b39f421cab242f5e25","modified":1541691462069},{"_id":"themes/clean-blog/LICENSE","hash":"8726b416df4f067cff579e859f05c4b594b8be09","modified":1541684479825},{"_id":"themes/clean-blog/README.md","hash":"861dd2f959ab75d121226f4f3e2f61f4bc95fddb","modified":1541684479825},{"_id":"themes/clean-blog/_config.yml","hash":"e7f98be5568b1353a876f20c351cfbd363146ba3","modified":1541684479825},{"_id":"source/_discarded/AVFoundation学习笔记六-AVAsset.md","hash":"6c4633a886299ec4cda46a7a696a9f035ff25f80","modified":1541684479804},{"_id":"source/_drafts/.DS_Store","hash":"b9930c13d45ed13ad3ab0ae82b9d32a675c25913","modified":1541691355681},{"_id":"source/_posts/.DS_Store","hash":"715d5d25f8bf56e9b327fb499c7464aaf2323c4d","modified":1541686089450},{"_id":"source/_posts/AVFoundation学习笔记一-AVSpeechSynthesizer.md","hash":"85bf289511e2df4f757a194babf45a15b2b7e6fb","modified":1541684479805},{"_id":"source/_posts/AVFoundation学习笔记一-iOS多媒体环境.md","hash":"64061b6b623e84ce73dd2f814e60145e62d85e6d","modified":1541684479805},{"_id":"source/_posts/AVFoundation学习笔记七-读取相册内容ALAsset和PHAsset.md","hash":"c537013b712339b391b09572002098fad461856c","modified":1541684479806},{"_id":"source/_posts/AVFoundation学习笔记七.md","hash":"a2f3c2db4e60959f996f3cdcb3adde6134fbcbcf","modified":1541687057126},{"_id":"source/_posts/AVFoundation学习笔记二-AVAudioPlayer.md","hash":"9b3ff28627551797ac63074e99d08b218295eb49","modified":1541684479807},{"_id":"source/_posts/AVFoundation学习笔记二-AVAudioSession.md","hash":"7790218bb792db7113e9e1f96d277c40eb5b2e62","modified":1541684479807},{"_id":"source/_posts/AVFoundation学习笔记五-AVAudioRecorder.md","hash":"07b32e70deeb982217384f186dd3826cd7963c08","modified":1541684479808},{"_id":"source/_posts/AVFoundation学习笔记八-AVPlayer及缩略图等相关功能.md","hash":"444df50499a64a39954bbd35472bc059389005de","modified":1541691456509},{"_id":"source/_posts/SRS服务器-二-保存及拉取数据.md","hash":"c67451a31c5dc2fc18000bbbfe91ede208863e79","modified":1541684479809},{"_id":"source/_posts/SRS服务器搭建.md","hash":"d3bf4b593acaa2895daf12547284467758486957","modified":1541684479814},{"_id":"source/_posts/TCP-IP学习笔记一.md","hash":"c9affc3f55fb53d2c8b1cbe2165bdf1eaa75e026","modified":1541684479821},{"_id":"source/_posts/Xcode编译错误-This-application-does-not-support-this-device-s-CPU-type.md","hash":"d605edd1f90101becef1a113dfb90d886da4c698","modified":1541684479822},{"_id":"source/_posts/主机-三系统.md","hash":"5cacd9a02c3184102a5eb7c8ae0fb7991e776c65","modified":1541686047652},{"_id":"source/_posts/冒泡排序.md","hash":"e17035a1de5a3544453fc96b11f19717fa18cb81","modified":1541684479822},{"_id":"source/categories/index.md","hash":"0c0636022f89c33332c469d3fa26810cbf17436a","modified":1541684479823},{"_id":"source/tags/index.md","hash":"4f84d3fbccfa475e49b349fb1fff4bd3b8508969","modified":1541684479824},{"_id":"themes/clean-blog/languages/de.yml","hash":"424a9c1e6ab69334d7873f6574da02ca960aa572","modified":1541684479825},{"_id":"themes/clean-blog/languages/default.yml","hash":"97326c9e6518d9f379778178b3b8f9a58434725d","modified":1541684479826},{"_id":"themes/clean-blog/languages/en.yml","hash":"97326c9e6518d9f379778178b3b8f9a58434725d","modified":1541684479826},{"_id":"themes/clean-blog/languages/es.yml","hash":"cb4eeca0ed3768a77e0cd216300f2b2549628b1b","modified":1541684479826},{"_id":"themes/clean-blog/languages/fr.yml","hash":"e9e6f7cb362ebb7997f11027498a2748fe3bac95","modified":1541684479826},{"_id":"themes/clean-blog/languages/no.yml","hash":"8ca475a3b4f8efe6603030f0013aae39668230e1","modified":1541684479826},{"_id":"themes/clean-blog/languages/pl.yml","hash":"de7eb5850ae65ba7638e907c805fea90617a988c","modified":1541684479826},{"_id":"themes/clean-blog/languages/pt.yml","hash":"1d0c3689eb32fe13f37f8f6f303af7624ebfbaf0","modified":1541684479826},{"_id":"themes/clean-blog/languages/ru.yml","hash":"42df7afeb7a35dc46d272b7f4fb880a9d9ebcaa5","modified":1541684479826},{"_id":"themes/clean-blog/languages/zh-CN.yml","hash":"7bfcb0b8e97d7e5edcfca8ab26d55d9da2573c1c","modified":1541684479826},{"_id":"themes/clean-blog/languages/zh-TW.yml","hash":"9acac6cc4f8002c3fa53ff69fb8cf66c915bd016","modified":1541684479826},{"_id":"themes/clean-blog/layout/archive.ejs","hash":"f2ef73afc3d275333329bb30b9369b82e119da76","modified":1541684479828},{"_id":"themes/clean-blog/layout/index.ejs","hash":"87995288ca6f95a04add641727aedd3f6afa55eb","modified":1541684479828},{"_id":"themes/clean-blog/layout/layout.ejs","hash":"da2f9018047924ddaf376aee5996c7ddc06cebc1","modified":1541684479828},{"_id":"themes/clean-blog/layout/page.ejs","hash":"591af587e1aae962950de7e79bd25c1f060c69ac","modified":1541684479828},{"_id":"themes/clean-blog/layout/post.ejs","hash":"38382e9bbeb6b8d2eafbd53fff2984111f524c1a","modified":1541684479828},{"_id":"source/_posts/AVFoundation学习笔记一-AVSpeechSynthesizer/SpeechSynthesizer.png","hash":"76d09a8ddc59eac06aa868827ff7f1e6879acac1","modified":1541684479805},{"_id":"source/_posts/AVFoundation学习笔记七-读取相册内容ALAsset和PHAsset/ALAsset.png","hash":"ca9151a361109acf1450c5dff578ee5c0594de85","modified":1541684479806},{"_id":"source/_posts/AVFoundation学习笔记二-AVAudioPlayer/audioplayer.png","hash":"d3531a4e9e4fb870567cfbd1ac89bb69605fa603","modified":1541684479807},{"_id":"source/_posts/AVFoundation学习笔记五-AVAudioRecorder/recorder.png","hash":"5a61a1b266d543f66c32d5f1ca870a2707ecf88d","modified":1541684479809},{"_id":"source/_posts/AVFoundation学习笔记八-AVPlayer及缩略图等相关功能/option_result.png","hash":"643d9c20b9db183ffbb54e675b2590f6a2279c53","modified":1541691456545},{"_id":"source/_posts/SRS服务器-二-保存及拉取数据/obs_set.png","hash":"975b007a3f48adf383b5726125a5d1f77e3e9cc8","modified":1541684479809},{"_id":"source/_posts/SRS服务器-二-保存及拉取数据/pushed.png","hash":"f118bf8bd75f6d39f149c2f127346e21f8d96e1a","modified":1541684479811},{"_id":"source/_posts/SRS服务器-二-保存及拉取数据/pushing.png","hash":"8ad7988477db59b0056448b278e7d6bab234fbf3","modified":1541684479811},{"_id":"source/_posts/SRS服务器搭建/obs.png","hash":"8eab194324c4fa5958d9c2acfea85eccf0ae058b","modified":1541684479815},{"_id":"source/_posts/SRS服务器搭建/rtmp映射.png","hash":"c8b050e5845450169a81d8bec9e1277d5c67b85f","modified":1541684479821},{"_id":"source/_posts/SRS服务器搭建/vlc.png","hash":"26c40bfcb2f848ca5e6c83f342546aef0a519157","modified":1541684479821},{"_id":"source/_posts/Xcode编译错误-This-application-does-not-support-this-device-s-CPU-type/buildSetting.png","hash":"1398869635d16ce1c16904589e33a4811381c50d","modified":1541684479822},{"_id":"source/_posts/主机-三系统/.DS_Store","hash":"df2fbeb1400acda0909a32c1cf6bf492f1121e07","modified":1541690192577},{"_id":"themes/clean-blog/layout/_partial/after-footer.ejs","hash":"80970a6cfbf9b1abe0c472636b321a9be08fdc43","modified":1541684479826},{"_id":"themes/clean-blog/layout/_partial/article-archive.ejs","hash":"3d8d98c6545b8332a6d6ed4f8b00327df03ea945","modified":1541684479827},{"_id":"themes/clean-blog/layout/_partial/article-categories.ejs","hash":"5a0bf5a20f670621d8013c9b9d7976b45c8aa80f","modified":1541684479827},{"_id":"themes/clean-blog/layout/_partial/article-full.ejs","hash":"0e7aa9da47f29b2312d9d3165c067576ebca77cf","modified":1541684479827},{"_id":"themes/clean-blog/layout/_partial/article-index.ejs","hash":"e433df4e245e2d4c628052c6e59966563542d94d","modified":1541684479827},{"_id":"themes/clean-blog/layout/_partial/article-tags.ejs","hash":"6136434be09056c1466149cecb3cc2e80d107999","modified":1541684479827},{"_id":"themes/clean-blog/layout/_partial/comments.ejs","hash":"3fedb75436439d1d6979b7e4d20d48a593e12be4","modified":1541684479827},{"_id":"themes/clean-blog/layout/_partial/footer.ejs","hash":"d252fb1a41890e6481bb054f9cc4ceec3c0b0ed9","modified":1541684479827},{"_id":"themes/clean-blog/layout/_partial/gallery.ejs","hash":"21e4f28909f4a79ff7d9f10bdfef6a8cb11632bf","modified":1541684479827},{"_id":"themes/clean-blog/layout/_partial/google-analytics.ejs","hash":"4e6e8de9becea5a1636a4dcadcf7a10c06e2426e","modified":1541684479827},{"_id":"themes/clean-blog/layout/_partial/head.ejs","hash":"3ccfc84e3ed67415fe71a1767d5e77a6b1f84a7a","modified":1541684479827},{"_id":"themes/clean-blog/layout/_partial/menu.ejs","hash":"ba299316400499e9ede154e9627cafb7ce411888","modified":1541684479828},{"_id":"themes/clean-blog/layout/_partial/pagination.ejs","hash":"557d6bb069a1d48af49ae912994653f44b32a570","modified":1541684479828},{"_id":"themes/clean-blog/layout/_partial/tag-category-index.ejs","hash":"10cdc1b7866999c714a666557c150d2c79c1fba9","modified":1541684479828},{"_id":"themes/clean-blog/source/css/article.styl","hash":"f5294d7a3d6127fcb287de3ff0c12aebb1766c7b","modified":1541684479828},{"_id":"themes/clean-blog/source/css/base.styl","hash":"0b54825903d08b5f7f7fe95ef4261c90e980abdb","modified":1541684479828},{"_id":"themes/clean-blog/source/css/mixins.styl","hash":"892f55e8a71f2e23a52e48e217dad3303bbad913","modified":1541684479829},{"_id":"themes/clean-blog/source/css/style.styl","hash":"c40dc495a41007d21c59f342ee42b2d31d7b5ff4","modified":1541684479829},{"_id":"themes/clean-blog/source/css/variables.styl","hash":"cd82df5ca8dfbcfec12d833f01adfac00878e835","modified":1541684479829},{"_id":"themes/clean-blog/source/img/about-bg.jpg","hash":"d39126a6456f2bac0169d1779304725f179c9900","modified":1541684479829},{"_id":"source/_posts/AVFoundation学习笔记七-读取相册内容ALAsset和PHAsset/PHAsset.png","hash":"fc461026f4100148ec42855de6fd90dcda3547c0","modified":1541684479806},{"_id":"source/_posts/AVFoundation学习笔记五-AVAudioRecorder/audio_format.png","hash":"8bcd0f338cce16fa6bcad82cccb809ae5d9720d4","modified":1541684479808},{"_id":"source/images/pasted-0.png","hash":"ae0edd367ca9d7aeacc30ea9d4382330ff0f39ca","modified":1541684479824},{"_id":"themes/clean-blog/source/img/home-bg.jpg","hash":"990f6f9dd0ecb5348bfcc47305553d58c0d8f326","modified":1541684479830},{"_id":"source/_posts/AVFoundation学习笔记一-iOS多媒体环境/ios_media.png","hash":"cb7dcb8b3457f737fb3b2ac4a0646e16302a901c","modified":1541684479806},{"_id":"source/_posts/AVFoundation学习笔记二-AVAudioSession/session_category.png","hash":"ae0edd367ca9d7aeacc30ea9d4382330ff0f39ca","modified":1541684479808},{"_id":"source/_posts/冒泡排序/冒泡.png","hash":"a1a2d1d4b2ede47f70170d9d34b81e2c74d69e49","modified":1541684479823},{"_id":"themes/clean-blog/source/img/contact-bg.jpg","hash":"6af63305c923899017e727b5ca968a2703bc08cf","modified":1541684479829},{"_id":"source/_posts/AVFoundation学习笔记八-AVPlayer及缩略图等相关功能/player_classes.png","hash":"c58ac99eba8668d452a1c81ca01fc1644a764ff7","modified":1541691456626},{"_id":"source/_posts/主机-三系统/主机.png","hash":"548cc0a259d98f62bfee7d73eb8c3d448295a800","modified":1541685978172},{"_id":"source/_posts/SRS服务器-二-保存及拉取数据/play_file.png","hash":"74ac117a6b4a32317a8f18a3ff185ea74c90b33a","modified":1541684479810},{"_id":"source/_posts/SRS服务器-二-保存及拉取数据/vlc_play.png","hash":"0f378ec9990a6c4e831b3bcc272a5a99d35799fc","modified":1541684479814},{"_id":"source/_posts/SRS服务器搭建/result_rtmp.png","hash":"e11ba3864e98fffdde706d009c03711e181cd261","modified":1541684479821},{"_id":"public/categories/index.html","hash":"9d4f3cb7ffd9b4fe85a40e180ede002a4d1c78c0","modified":1541691481486},{"_id":"public/tags/index.html","hash":"5070d428f9d9c814f56d43c7754d4f57cbbf910b","modified":1541691481486},{"_id":"public/2018/11/08/AVFoundation学习笔记七/index.html","hash":"7ee6de96e68a9c1031e61d33f7823f087f8fbecc","modified":1541691481487},{"_id":"public/2018/11/08/主机-三系统/index.html","hash":"fe005534ae31f25cc67c0b88e7fcaa486cf7164b","modified":1541691481487},{"_id":"public/2018/11/05/AVFoundation学习笔记七-读取相册内容ALAsset和PHAsset/index.html","hash":"1d62f890792e6a7f9557ee1f5ad8a1175cb8c621","modified":1541691481487},{"_id":"public/2018/11/02/AVFoundation学习笔记五-AVAudioRecorder/index.html","hash":"d1edef5477ba35c21ec395bac41bf9d3f4a7298c","modified":1541691481487},{"_id":"public/2018/11/01/AVFoundation学习笔记二-AVAudioPlayer/index.html","hash":"6ce324f004b0b6a488899b5b31add6fa7f185de4","modified":1541691481487},{"_id":"public/2018/10/31/SRS服务器-二-保存及拉取数据/index.html","hash":"3f70f900a394d896135967ca2471be4f46847cb2","modified":1541691481487},{"_id":"public/2018/10/31/Xcode编译错误-This-application-does-not-support-this-device-s-CPU-type/index.html","hash":"7ee2ed907356a160bd3a34f3b533c26f1d51e8e1","modified":1541691481487},{"_id":"public/2018/10/24/AVFoundation学习笔记一-AVSpeechSynthesizer/index.html","hash":"5200db08329c5aa8c5a3e6f9f2dc98c26818a2d0","modified":1541691481487},{"_id":"public/2018/10/24/AVFoundation学习笔记一-iOS多媒体环境/index.html","hash":"e5dd99315d35106aebe9fd37f2286d0348aa22d8","modified":1541691481487},{"_id":"public/2018/10/23/SRS服务器搭建/index.html","hash":"82eda2b77a010cad580bfc32f82a8906378caa97","modified":1541691481487},{"_id":"public/2018/10/23/冒泡排序/index.html","hash":"8c03e3eea9793433b6a38672a5183da9490e54c6","modified":1541691481487},{"_id":"public/2018/10/23/TCP-IP学习笔记一/index.html","hash":"48509cd5e142421a3634ef0a8a1f4dd7e5974016","modified":1541691481487},{"_id":"public/archives/index.html","hash":"4fd0c30232c81cf511caef344bda9f9a3963286f","modified":1541691481487},{"_id":"public/archives/page/2/index.html","hash":"15bf60fb31ac222d23114c49a7010fe8f881a993","modified":1541691481487},{"_id":"public/archives/2018/index.html","hash":"6d8bb4f7e67e2619658bdcdade2a2763891b6fc2","modified":1541691481487},{"_id":"public/archives/2018/page/2/index.html","hash":"b4b7edb712b6b05174a39fbcaa35a9b02bc10b37","modified":1541691481487},{"_id":"public/archives/2018/10/index.html","hash":"716c72969d7ffc352687e8e7406e17cefffb6d25","modified":1541691481487},{"_id":"public/archives/2018/11/index.html","hash":"f57e7030b1f43d0b265ea7f15655b2a07ae0228f","modified":1541691481487},{"_id":"public/categories/AVFoundation/index.html","hash":"c8144a24b9ebcc150f0b637d234726696bd26fb0","modified":1541691481487},{"_id":"public/categories/rtmp/index.html","hash":"cebf87297215aa33234484bfc9c67b1bc719ff1b","modified":1541691481488},{"_id":"public/categories/网络协议/index.html","hash":"5b6925a07a34600a94b61c1e701a882c8ca49606","modified":1541691481488},{"_id":"public/categories/iOS/index.html","hash":"789a3e84cd4c7de775eb2ba9ffc57311a1c97bea","modified":1541691481488},{"_id":"public/categories/杂记/index.html","hash":"3770b837225161fa049d4a71213b5efe0b4938f8","modified":1541691481488},{"_id":"public/categories/算法/index.html","hash":"b3add5e49deecd2d9c0b68bc11267798e38cf50d","modified":1541691481488},{"_id":"public/index.html","hash":"10b8433ee828626fb8ae4a41ce6e2cea5a83d744","modified":1541691481488},{"_id":"public/page/2/index.html","hash":"57a0783dfc7653c08216a803aa76c4de436c7e7d","modified":1541691481488},{"_id":"public/tags/文本语音播报/index.html","hash":"ccdefaf11fb93279d48ef8e5d00b5643c800fae7","modified":1541691481488},{"_id":"public/tags/SRS/index.html","hash":"5e4c4498b9664e4403a69427808ef0767b0e32d0","modified":1541691481488},{"_id":"public/tags/TCP-IP/index.html","hash":"63d71707cdc26abde649c11efc726ed181c6ef01","modified":1541691481488},{"_id":"public/tags/Xcode问题/index.html","hash":"93c867097c2dec6ea2ab4b26cec57023b638661b","modified":1541691481489},{"_id":"public/tags/八大排序/index.html","hash":"e88caa9fc6b951797ecde98798a0a6eb7859ea53","modified":1541691481489},{"_id":"public/2018/11/08/AVFoundation学习笔记八-AVPlayer及缩略图等相关功能/index.html","hash":"fab7208c8b1fa91d16a336e5587892cb9cede8c9","modified":1541691481489},{"_id":"public/2018/10/25/AVFoundation学习笔记二-AVAudioSession/index.html","hash":"87837243da99ee6cb4572e3bf4413c80e62456dd","modified":1541691481489},{"_id":"public/CNAME","hash":"04271e73b293a955602e93a3dcfed4cc9d7473de","modified":1541691481492},{"_id":"public/img/about-bg.jpg","hash":"d39126a6456f2bac0169d1779304725f179c9900","modified":1541691481493},{"_id":"public/2018/10/24/AVFoundation学习笔记一-AVSpeechSynthesizer/SpeechSynthesizer.png","hash":"76d09a8ddc59eac06aa868827ff7f1e6879acac1","modified":1541691481493},{"_id":"public/2018/11/01/AVFoundation学习笔记二-AVAudioPlayer/audioplayer.png","hash":"d3531a4e9e4fb870567cfbd1ac89bb69605fa603","modified":1541691481493},{"_id":"public/2018/10/31/Xcode编译错误-This-application-does-not-support-this-device-s-CPU-type/buildSetting.png","hash":"1398869635d16ce1c16904589e33a4811381c50d","modified":1541691481493},{"_id":"public/2018/11/05/AVFoundation学习笔记七-读取相册内容ALAsset和PHAsset/ALAsset.png","hash":"ca9151a361109acf1450c5dff578ee5c0594de85","modified":1541691481493},{"_id":"public/2018/11/02/AVFoundation学习笔记五-AVAudioRecorder/recorder.png","hash":"5a61a1b266d543f66c32d5f1ca870a2707ecf88d","modified":1541691481493},{"_id":"public/2018/10/23/SRS服务器搭建/obs.png","hash":"8eab194324c4fa5958d9c2acfea85eccf0ae058b","modified":1541691481493},{"_id":"public/2018/10/23/SRS服务器搭建/rtmp映射.png","hash":"c8b050e5845450169a81d8bec9e1277d5c67b85f","modified":1541691481493},{"_id":"public/2018/10/23/SRS服务器搭建/vlc.png","hash":"26c40bfcb2f848ca5e6c83f342546aef0a519157","modified":1541691481493},{"_id":"public/2018/10/31/SRS服务器-二-保存及拉取数据/obs_set.png","hash":"975b007a3f48adf383b5726125a5d1f77e3e9cc8","modified":1541691481493},{"_id":"public/2018/10/31/SRS服务器-二-保存及拉取数据/pushed.png","hash":"f118bf8bd75f6d39f149c2f127346e21f8d96e1a","modified":1541691481493},{"_id":"public/2018/10/31/SRS服务器-二-保存及拉取数据/pushing.png","hash":"8ad7988477db59b0056448b278e7d6bab234fbf3","modified":1541691481493},{"_id":"public/2018/11/08/AVFoundation学习笔记八-AVPlayer及缩略图等相关功能/option_result.png","hash":"643d9c20b9db183ffbb54e675b2590f6a2279c53","modified":1541691481493},{"_id":"public/2018/11/05/AVFoundation学习笔记七-读取相册内容ALAsset和PHAsset/PHAsset.png","hash":"fc461026f4100148ec42855de6fd90dcda3547c0","modified":1541691481619},{"_id":"public/2018/11/02/AVFoundation学习笔记五-AVAudioRecorder/audio_format.png","hash":"8bcd0f338cce16fa6bcad82cccb809ae5d9720d4","modified":1541691481620},{"_id":"public/css/article.css","hash":"f0ee490e1207191946fffc9444f891e9b7ae7289","modified":1541691481624},{"_id":"public/css/mixins.css","hash":"45146e7f4346351cd7f364de344aecf9574475f9","modified":1541691481624},{"_id":"public/css/style.css","hash":"029be79fde48199c77c76dbaac80cec3715f0bc8","modified":1541691481624},{"_id":"public/css/variables.css","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1541691481624},{"_id":"public/css/base.css","hash":"91b6c032be9e146dfd68880fe79f77f5d2771b0f","modified":1541691481624},{"_id":"public/2018/10/24/AVFoundation学习笔记一-iOS多媒体环境/ios_media.png","hash":"cb7dcb8b3457f737fb3b2ac4a0646e16302a901c","modified":1541691481624},{"_id":"public/img/home-bg.jpg","hash":"990f6f9dd0ecb5348bfcc47305553d58c0d8f326","modified":1541691481628},{"_id":"public/images/pasted-0.png","hash":"ae0edd367ca9d7aeacc30ea9d4382330ff0f39ca","modified":1541691481628},{"_id":"public/2018/10/25/AVFoundation学习笔记二-AVAudioSession/session_category.png","hash":"ae0edd367ca9d7aeacc30ea9d4382330ff0f39ca","modified":1541691481632},{"_id":"public/2018/11/08/AVFoundation学习笔记八-AVPlayer及缩略图等相关功能/player_classes.png","hash":"c58ac99eba8668d452a1c81ca01fc1644a764ff7","modified":1541691481632},{"_id":"public/2018/10/23/冒泡排序/冒泡.png","hash":"a1a2d1d4b2ede47f70170d9d34b81e2c74d69e49","modified":1541691481635},{"_id":"public/img/contact-bg.jpg","hash":"6af63305c923899017e727b5ca968a2703bc08cf","modified":1541691481637},{"_id":"public/2018/10/31/SRS服务器-二-保存及拉取数据/play_file.png","hash":"74ac117a6b4a32317a8f18a3ff185ea74c90b33a","modified":1541691481650},{"_id":"public/2018/11/08/主机-三系统/主机.png","hash":"548cc0a259d98f62bfee7d73eb8c3d448295a800","modified":1541691481651},{"_id":"public/2018/10/31/SRS服务器-二-保存及拉取数据/vlc_play.png","hash":"0f378ec9990a6c4e831b3bcc272a5a99d35799fc","modified":1541691481655},{"_id":"public/2018/10/23/SRS服务器搭建/result_rtmp.png","hash":"e11ba3864e98fffdde706d009c03711e181cd261","modified":1541691481656}],"Category":[{"name":"AVFoundation","_id":"cjo8raw1b0004drd3p6grgq5d"},{"name":"rtmp","_id":"cjo8raw1l000kdrd3jwixuv8t"},{"name":"网络协议","_id":"cjo8raw1p000vdrd315pqxkn7"},{"name":"iOS","_id":"cjo8raw1p0010drd3py8qw6ct"},{"name":"杂记","_id":"cjo8raw1q0014drd3fmpdykg6"},{"name":"算法","_id":"cjo8raw1q0017drd3zdca005w"}],"Data":[],"Page":[{"title":"categories","date":"2018-10-23T06:44:06.000Z","type":"categories","_content":"","source":"categories/index.md","raw":"title: categories\ndate: 2018-10-23 14:44:06\ntype: \"categories\"\n---\n","updated":"2018-11-08T13:41:19.823Z","path":"categories/index.html","comments":1,"layout":"page","_id":"cjo8raw190001drd3bt8xntwo","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"tags","date":"2015-10-19T22:49:50.000Z","type":"tags","comments":0,"_content":"","source":"tags/index.md","raw":"title: tags\ndate: 2015-10-20 06:49:50\ntype: \"tags\"\ncomments: false\n---\n","updated":"2018-11-08T13:41:19.824Z","path":"tags/index.html","layout":"page","_id":"cjo8raw1b0003drd3nuih8fyy","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"AVFoundation学习笔记二  Speech Synthesis","author":"Cyrus","date":"2018-10-24T15:07:00.000Z","_content":"AVFoundation的文本朗诵主要由以下三个类组成：AVSpeechSynthesizer（语音合成器）、AVSpeechUtterance（语音内容）和AVSpeechSynthesisVoice（语音口音）。这三个类的关系如下图：\n![](SpeechSynthesizer.png)\n简单来说就是一个语音合成器（AVSpeechSynthesizer）可以播放一个或多个可以设置口音（AVSpeechSynthesisVoice）、语调、语速的语音内容（AVSpeechUtterance）。\n\n具体代码步骤：\n1、初始化一个AVSpeechSynthesizer对象\n```\n_synthesizer = [[AVSpeechSynthesizer alloc] init];\n```\n\n2、创建要朗诵的内容\n```\n_speechStrings = @[@\"Hello AV Foundation. How are you?\",\n                           @\"I'm well! Thanks for asking.\",\n                           @\"Are you excited about the book?\",\n                           @\"Very! I have always felt so misunderstood.\",\n                           @\"What's your favorite feature?\",\n                           @\"Oh, they're all my babies.  I couldn't possibly choose.\",\n                           @\"It was great to speak with you!\",\n                           @\"The pleasure was all mine!  Have fun!\"\n                           ];\n```\n\n3、为每个字符串创建一个AVSpeechUtterance对象,并传递给self.synthesizer进行播放\n```\nfor (NSUInteger i = 0; i < self.speechStrings.count; i++) {\n        AVSpeechUtterance *utterance = [[AVSpeechUtterance alloc] initWithString:self.speechStrings[i]];\n        utterance.voice = [AVSpeechSynthesisVoice voiceWithLanguage:@\"en-US\"];\n        utterance.rate = 0.4;\n        utterance.pitchMultiplier = 0.8f;       //声调，0.5（低音调）-2.0（高音调）\n        utterance.postUtteranceDelay = 0.1f;    //播放下一句之前有短时间的暂停\n        [self.synthesizer speakUtterance:utterance];\n    }\n```\n\n相关属性：\n\nAVSpeechSynthesisVoice相关属性\n\n（1）language:voice的主要属性，可以根据language创建voice。可以使用\n```\n+ (NSArray<AVSpeechSynthesisVoice *> *)speechVoices;\n```\n获取所有支持的language,具体如下：\n* Arabic (ar-SA)\n* Chinese (zh-CN, zh-HK, zh-TW)\n* Czech (cs-CZ)\n* Danish (da-DK)\n* Dutch (nl-BE, nl-NL)\n* English (en-AU, en-GB, en-IE, en-US, en-ZA)\n* Finnish (fi-FI)\n* French (fr-CA, fr-FR)\n* German (de-DE)\n* Greek (el-GR)\n* Hebrew (he-IL)\n* Hindi (hi-IN)\n* Hungarian (hu-HU)\n* Indonesian (id-ID)\n* Italian (it-IT)\n* Japanese (ja-JP)\n* Korean (ko-KR)\n* Norwegian (no-NO)\n* Polish (pl-PL)\n* Portuguese (pt-BR, pt-PT)\n* Romanian (ro-RO)\n* Russian (ru-RU)\n* Slovak (sk-SK)\n* Spanish (es-ES, es-MX)\n* Swedish (sv-SE)\n* Thai (th-TH)\n* Turkish (tr-TR)\n\n（2）***quality***：声音质量，枚举值\n```\ntypedef NS_ENUM(NSInteger, AVSpeechSynthesisVoiceQuality) {\n    AVSpeechSynthesisVoiceQualityDefault = 1,\t//默认\n    AVSpeechSynthesisVoiceQualityEnhanced\t\t//增强\n} NS_ENUM_AVAILABLE(10_14, 9_0);\n```\n\nAVSpeechUtterance相关属性\n\n（1）***rate***:指定播放语音时的速率(0.0-1.0),即AVSpeechUtteranceMinimumSpeechRate和AVSpeechUtteranceMaximumSpeechRate之间\n\n（2）***pitchMultiplier***：设置声调,属性值介于0.5(低音调)~2.0(高音调)之间\n\n（3）***volume***:设置音量(0.0-1.0)\n\n（4）***preUtteranceDelay***：postUtteranceDelay告诉synthesizer本句朗读结束后要延迟多少秒再接着朗读下一秒,对应的属性还有***preUtteranceDelay***\n\n此外,<font color=0xff000000>***AVSpeechSynthesizerDelegate***</font>中还提供了一些监听朗读状态的方法.","source":"_posts/AVFoundation学习笔记一-AVSpeechSynthesizer.md","raw":"title: AVFoundation学习笔记二  Speech Synthesis\nauthor: Cyrus\ntags:\n  - 文本语音播报\ncategories:\n  - AVFoundation\ndate: 2018-10-24 23:07:00\n---\nAVFoundation的文本朗诵主要由以下三个类组成：AVSpeechSynthesizer（语音合成器）、AVSpeechUtterance（语音内容）和AVSpeechSynthesisVoice（语音口音）。这三个类的关系如下图：\n![](SpeechSynthesizer.png)\n简单来说就是一个语音合成器（AVSpeechSynthesizer）可以播放一个或多个可以设置口音（AVSpeechSynthesisVoice）、语调、语速的语音内容（AVSpeechUtterance）。\n\n具体代码步骤：\n1、初始化一个AVSpeechSynthesizer对象\n```\n_synthesizer = [[AVSpeechSynthesizer alloc] init];\n```\n\n2、创建要朗诵的内容\n```\n_speechStrings = @[@\"Hello AV Foundation. How are you?\",\n                           @\"I'm well! Thanks for asking.\",\n                           @\"Are you excited about the book?\",\n                           @\"Very! I have always felt so misunderstood.\",\n                           @\"What's your favorite feature?\",\n                           @\"Oh, they're all my babies.  I couldn't possibly choose.\",\n                           @\"It was great to speak with you!\",\n                           @\"The pleasure was all mine!  Have fun!\"\n                           ];\n```\n\n3、为每个字符串创建一个AVSpeechUtterance对象,并传递给self.synthesizer进行播放\n```\nfor (NSUInteger i = 0; i < self.speechStrings.count; i++) {\n        AVSpeechUtterance *utterance = [[AVSpeechUtterance alloc] initWithString:self.speechStrings[i]];\n        utterance.voice = [AVSpeechSynthesisVoice voiceWithLanguage:@\"en-US\"];\n        utterance.rate = 0.4;\n        utterance.pitchMultiplier = 0.8f;       //声调，0.5（低音调）-2.0（高音调）\n        utterance.postUtteranceDelay = 0.1f;    //播放下一句之前有短时间的暂停\n        [self.synthesizer speakUtterance:utterance];\n    }\n```\n\n相关属性：\n\nAVSpeechSynthesisVoice相关属性\n\n（1）language:voice的主要属性，可以根据language创建voice。可以使用\n```\n+ (NSArray<AVSpeechSynthesisVoice *> *)speechVoices;\n```\n获取所有支持的language,具体如下：\n* Arabic (ar-SA)\n* Chinese (zh-CN, zh-HK, zh-TW)\n* Czech (cs-CZ)\n* Danish (da-DK)\n* Dutch (nl-BE, nl-NL)\n* English (en-AU, en-GB, en-IE, en-US, en-ZA)\n* Finnish (fi-FI)\n* French (fr-CA, fr-FR)\n* German (de-DE)\n* Greek (el-GR)\n* Hebrew (he-IL)\n* Hindi (hi-IN)\n* Hungarian (hu-HU)\n* Indonesian (id-ID)\n* Italian (it-IT)\n* Japanese (ja-JP)\n* Korean (ko-KR)\n* Norwegian (no-NO)\n* Polish (pl-PL)\n* Portuguese (pt-BR, pt-PT)\n* Romanian (ro-RO)\n* Russian (ru-RU)\n* Slovak (sk-SK)\n* Spanish (es-ES, es-MX)\n* Swedish (sv-SE)\n* Thai (th-TH)\n* Turkish (tr-TR)\n\n（2）***quality***：声音质量，枚举值\n```\ntypedef NS_ENUM(NSInteger, AVSpeechSynthesisVoiceQuality) {\n    AVSpeechSynthesisVoiceQualityDefault = 1,\t//默认\n    AVSpeechSynthesisVoiceQualityEnhanced\t\t//增强\n} NS_ENUM_AVAILABLE(10_14, 9_0);\n```\n\nAVSpeechUtterance相关属性\n\n（1）***rate***:指定播放语音时的速率(0.0-1.0),即AVSpeechUtteranceMinimumSpeechRate和AVSpeechUtteranceMaximumSpeechRate之间\n\n（2）***pitchMultiplier***：设置声调,属性值介于0.5(低音调)~2.0(高音调)之间\n\n（3）***volume***:设置音量(0.0-1.0)\n\n（4）***preUtteranceDelay***：postUtteranceDelay告诉synthesizer本句朗读结束后要延迟多少秒再接着朗读下一秒,对应的属性还有***preUtteranceDelay***\n\n此外,<font color=0xff000000>***AVSpeechSynthesizerDelegate***</font>中还提供了一些监听朗读状态的方法.","slug":"AVFoundation学习笔记一-AVSpeechSynthesizer","published":1,"updated":"2018-11-08T13:41:19.805Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjo8raw170000drd3scbj6pdu","content":"<p>AVFoundation的文本朗诵主要由以下三个类组成：AVSpeechSynthesizer（语音合成器）、AVSpeechUtterance（语音内容）和AVSpeechSynthesisVoice（语音口音）。这三个类的关系如下图：<br><img src=\"//www.cyrus.fun/2018/10/24/AVFoundation学习笔记一-AVSpeechSynthesizer/SpeechSynthesizer.png\" alt=\"\"><br>简单来说就是一个语音合成器（AVSpeechSynthesizer）可以播放一个或多个可以设置口音（AVSpeechSynthesisVoice）、语调、语速的语音内容（AVSpeechUtterance）。</p>\n<p>具体代码步骤：<br>1、初始化一个AVSpeechSynthesizer对象<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">_synthesizer = [[AVSpeechSynthesizer alloc] init];</span><br></pre></td></tr></table></figure></p>\n<p>2、创建要朗诵的内容<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">_speechStrings = @[@&quot;Hello AV Foundation. How are you?&quot;,</span><br><span class=\"line\">                           @&quot;I&apos;m well! Thanks for asking.&quot;,</span><br><span class=\"line\">                           @&quot;Are you excited about the book?&quot;,</span><br><span class=\"line\">                           @&quot;Very! I have always felt so misunderstood.&quot;,</span><br><span class=\"line\">                           @&quot;What&apos;s your favorite feature?&quot;,</span><br><span class=\"line\">                           @&quot;Oh, they&apos;re all my babies.  I couldn&apos;t possibly choose.&quot;,</span><br><span class=\"line\">                           @&quot;It was great to speak with you!&quot;,</span><br><span class=\"line\">                           @&quot;The pleasure was all mine!  Have fun!&quot;</span><br><span class=\"line\">                           ];</span><br></pre></td></tr></table></figure></p>\n<p>3、为每个字符串创建一个AVSpeechUtterance对象,并传递给self.synthesizer进行播放<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">for (NSUInteger i = 0; i &lt; self.speechStrings.count; i++) &#123;</span><br><span class=\"line\">        AVSpeechUtterance *utterance = [[AVSpeechUtterance alloc] initWithString:self.speechStrings[i]];</span><br><span class=\"line\">        utterance.voice = [AVSpeechSynthesisVoice voiceWithLanguage:@&quot;en-US&quot;];</span><br><span class=\"line\">        utterance.rate = 0.4;</span><br><span class=\"line\">        utterance.pitchMultiplier = 0.8f;       //声调，0.5（低音调）-2.0（高音调）</span><br><span class=\"line\">        utterance.postUtteranceDelay = 0.1f;    //播放下一句之前有短时间的暂停</span><br><span class=\"line\">        [self.synthesizer speakUtterance:utterance];</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure></p>\n<p>相关属性：</p>\n<p>AVSpeechSynthesisVoice相关属性</p>\n<p>（1）language:voice的主要属性，可以根据language创建voice。可以使用<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">+ (NSArray&lt;AVSpeechSynthesisVoice *&gt; *)speechVoices;</span><br></pre></td></tr></table></figure></p>\n<p>获取所有支持的language,具体如下：</p>\n<ul>\n<li>Arabic (ar-SA)</li>\n<li>Chinese (zh-CN, zh-HK, zh-TW)</li>\n<li>Czech (cs-CZ)</li>\n<li>Danish (da-DK)</li>\n<li>Dutch (nl-BE, nl-NL)</li>\n<li>English (en-AU, en-GB, en-IE, en-US, en-ZA)</li>\n<li>Finnish (fi-FI)</li>\n<li>French (fr-CA, fr-FR)</li>\n<li>German (de-DE)</li>\n<li>Greek (el-GR)</li>\n<li>Hebrew (he-IL)</li>\n<li>Hindi (hi-IN)</li>\n<li>Hungarian (hu-HU)</li>\n<li>Indonesian (id-ID)</li>\n<li>Italian (it-IT)</li>\n<li>Japanese (ja-JP)</li>\n<li>Korean (ko-KR)</li>\n<li>Norwegian (no-NO)</li>\n<li>Polish (pl-PL)</li>\n<li>Portuguese (pt-BR, pt-PT)</li>\n<li>Romanian (ro-RO)</li>\n<li>Russian (ru-RU)</li>\n<li>Slovak (sk-SK)</li>\n<li>Spanish (es-ES, es-MX)</li>\n<li>Swedish (sv-SE)</li>\n<li>Thai (th-TH)</li>\n<li>Turkish (tr-TR)</li>\n</ul>\n<p>（2）<strong><em>quality</em></strong>：声音质量，枚举值<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">typedef NS_ENUM(NSInteger, AVSpeechSynthesisVoiceQuality) &#123;</span><br><span class=\"line\">    AVSpeechSynthesisVoiceQualityDefault = 1,\t//默认</span><br><span class=\"line\">    AVSpeechSynthesisVoiceQualityEnhanced\t\t//增强</span><br><span class=\"line\">&#125; NS_ENUM_AVAILABLE(10_14, 9_0);</span><br></pre></td></tr></table></figure></p>\n<p>AVSpeechUtterance相关属性</p>\n<p>（1）<strong><em>rate</em></strong>:指定播放语音时的速率(0.0-1.0),即AVSpeechUtteranceMinimumSpeechRate和AVSpeechUtteranceMaximumSpeechRate之间</p>\n<p>（2）<strong><em>pitchMultiplier</em></strong>：设置声调,属性值介于0.5(低音调)~2.0(高音调)之间</p>\n<p>（3）<strong><em>volume</em></strong>:设置音量(0.0-1.0)</p>\n<p>（4）<strong><em>preUtteranceDelay</em></strong>：postUtteranceDelay告诉synthesizer本句朗读结束后要延迟多少秒再接着朗读下一秒,对应的属性还有<strong><em>preUtteranceDelay</em></strong></p>\n<p>此外,<font color=\"0xff000000\"><strong><em>AVSpeechSynthesizerDelegate</em></strong></font>中还提供了一些监听朗读状态的方法.</p>\n","site":{"data":{}},"excerpt":"","more":"<p>AVFoundation的文本朗诵主要由以下三个类组成：AVSpeechSynthesizer（语音合成器）、AVSpeechUtterance（语音内容）和AVSpeechSynthesisVoice（语音口音）。这三个类的关系如下图：<br><img src=\"//www.cyrus.fun/2018/10/24/AVFoundation学习笔记一-AVSpeechSynthesizer/SpeechSynthesizer.png\" alt=\"\"><br>简单来说就是一个语音合成器（AVSpeechSynthesizer）可以播放一个或多个可以设置口音（AVSpeechSynthesisVoice）、语调、语速的语音内容（AVSpeechUtterance）。</p>\n<p>具体代码步骤：<br>1、初始化一个AVSpeechSynthesizer对象<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">_synthesizer = [[AVSpeechSynthesizer alloc] init];</span><br></pre></td></tr></table></figure></p>\n<p>2、创建要朗诵的内容<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">_speechStrings = @[@&quot;Hello AV Foundation. How are you?&quot;,</span><br><span class=\"line\">                           @&quot;I&apos;m well! Thanks for asking.&quot;,</span><br><span class=\"line\">                           @&quot;Are you excited about the book?&quot;,</span><br><span class=\"line\">                           @&quot;Very! I have always felt so misunderstood.&quot;,</span><br><span class=\"line\">                           @&quot;What&apos;s your favorite feature?&quot;,</span><br><span class=\"line\">                           @&quot;Oh, they&apos;re all my babies.  I couldn&apos;t possibly choose.&quot;,</span><br><span class=\"line\">                           @&quot;It was great to speak with you!&quot;,</span><br><span class=\"line\">                           @&quot;The pleasure was all mine!  Have fun!&quot;</span><br><span class=\"line\">                           ];</span><br></pre></td></tr></table></figure></p>\n<p>3、为每个字符串创建一个AVSpeechUtterance对象,并传递给self.synthesizer进行播放<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">for (NSUInteger i = 0; i &lt; self.speechStrings.count; i++) &#123;</span><br><span class=\"line\">        AVSpeechUtterance *utterance = [[AVSpeechUtterance alloc] initWithString:self.speechStrings[i]];</span><br><span class=\"line\">        utterance.voice = [AVSpeechSynthesisVoice voiceWithLanguage:@&quot;en-US&quot;];</span><br><span class=\"line\">        utterance.rate = 0.4;</span><br><span class=\"line\">        utterance.pitchMultiplier = 0.8f;       //声调，0.5（低音调）-2.0（高音调）</span><br><span class=\"line\">        utterance.postUtteranceDelay = 0.1f;    //播放下一句之前有短时间的暂停</span><br><span class=\"line\">        [self.synthesizer speakUtterance:utterance];</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure></p>\n<p>相关属性：</p>\n<p>AVSpeechSynthesisVoice相关属性</p>\n<p>（1）language:voice的主要属性，可以根据language创建voice。可以使用<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">+ (NSArray&lt;AVSpeechSynthesisVoice *&gt; *)speechVoices;</span><br></pre></td></tr></table></figure></p>\n<p>获取所有支持的language,具体如下：</p>\n<ul>\n<li>Arabic (ar-SA)</li>\n<li>Chinese (zh-CN, zh-HK, zh-TW)</li>\n<li>Czech (cs-CZ)</li>\n<li>Danish (da-DK)</li>\n<li>Dutch (nl-BE, nl-NL)</li>\n<li>English (en-AU, en-GB, en-IE, en-US, en-ZA)</li>\n<li>Finnish (fi-FI)</li>\n<li>French (fr-CA, fr-FR)</li>\n<li>German (de-DE)</li>\n<li>Greek (el-GR)</li>\n<li>Hebrew (he-IL)</li>\n<li>Hindi (hi-IN)</li>\n<li>Hungarian (hu-HU)</li>\n<li>Indonesian (id-ID)</li>\n<li>Italian (it-IT)</li>\n<li>Japanese (ja-JP)</li>\n<li>Korean (ko-KR)</li>\n<li>Norwegian (no-NO)</li>\n<li>Polish (pl-PL)</li>\n<li>Portuguese (pt-BR, pt-PT)</li>\n<li>Romanian (ro-RO)</li>\n<li>Russian (ru-RU)</li>\n<li>Slovak (sk-SK)</li>\n<li>Spanish (es-ES, es-MX)</li>\n<li>Swedish (sv-SE)</li>\n<li>Thai (th-TH)</li>\n<li>Turkish (tr-TR)</li>\n</ul>\n<p>（2）<strong><em>quality</em></strong>：声音质量，枚举值<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">typedef NS_ENUM(NSInteger, AVSpeechSynthesisVoiceQuality) &#123;</span><br><span class=\"line\">    AVSpeechSynthesisVoiceQualityDefault = 1,\t//默认</span><br><span class=\"line\">    AVSpeechSynthesisVoiceQualityEnhanced\t\t//增强</span><br><span class=\"line\">&#125; NS_ENUM_AVAILABLE(10_14, 9_0);</span><br></pre></td></tr></table></figure></p>\n<p>AVSpeechUtterance相关属性</p>\n<p>（1）<strong><em>rate</em></strong>:指定播放语音时的速率(0.0-1.0),即AVSpeechUtteranceMinimumSpeechRate和AVSpeechUtteranceMaximumSpeechRate之间</p>\n<p>（2）<strong><em>pitchMultiplier</em></strong>：设置声调,属性值介于0.5(低音调)~2.0(高音调)之间</p>\n<p>（3）<strong><em>volume</em></strong>:设置音量(0.0-1.0)</p>\n<p>（4）<strong><em>preUtteranceDelay</em></strong>：postUtteranceDelay告诉synthesizer本句朗读结束后要延迟多少秒再接着朗读下一秒,对应的属性还有<strong><em>preUtteranceDelay</em></strong></p>\n<p>此外,<font color=\"0xff000000\"><strong><em>AVSpeechSynthesizerDelegate</em></strong></font>中还提供了一些监听朗读状态的方法.</p>\n"},{"title":"AVFoundation学习笔记一 iOS多媒体环境","author":"Cyrus","date":"2018-10-24T12:14:00.000Z","_content":"![](ios_media.png)\n\n### Core Audio\nCore Audio是OS X和iOS系统上处理所有音频事件的框架。\n* 1、为音频和HIDI内容的录制、播放和处理提供相应接口；\n* 2、高层级AudioQueueServers框架提供的处理基本音频播放和录音相关的功能；\n* 3、低层级Audio Units针对音频信号进行完全控制的功能。\n\n### Core Video\nCore Video是OS X和iOS系统上针对数字视频所提供的管道模式。Core Video为其相对的Core Media<font color=ff0000>提供图片缓存和缓存池支持，提供了一个能够对数字视频逐帧访问的接口</font>。\n\n### Core Media\nCore Media是AVFoundation所用到的低层级媒体管道的一部分。提供针对音频样本和视频帧处理所需的低层级数据类型和接口。Core Media还提供了CMTime数据类型的时基模型。\n\n### Core Animation\nCore Animation是OS X和iOS提供的合成及动画相关框架，封装了OpenGL和OpenGL ES功能的基本Objective-C的各种类。（似乎已经改为<font color=ff0000>Metal</font>作为Core Animation的低层渲染）\n\n### AVFoundation (本系列主要内容)\n处于高层级框架和低层级框架之间，以Objective-C接口方式提供了很多低层级框架才能实现的功能和性能,可以和高层级的框架无缝衔接。\n* 1、文本朗诵 （AVSpeechSynthesizer）\n* 2、音频播放和录制（AVAudioPlayer和AVAudioRecorder）\n* 3、媒体文件元数据（AVMetadataItem）\n* 4、视频播放 （AVPlayer 和 AVPlayerItem）\n* 5、媒体捕捉 （AVCaptureSession）\n* 6、媒体读写 （AVAssetReader和AVAssetWriter）\n* 7、媒体编辑","source":"_posts/AVFoundation学习笔记一-iOS多媒体环境.md","raw":"title: AVFoundation学习笔记一 iOS多媒体环境\nauthor: Cyrus\ntags: []\ncategories:\n  - AVFoundation\ndate: 2018-10-24 20:14:00\n---\n![](ios_media.png)\n\n### Core Audio\nCore Audio是OS X和iOS系统上处理所有音频事件的框架。\n* 1、为音频和HIDI内容的录制、播放和处理提供相应接口；\n* 2、高层级AudioQueueServers框架提供的处理基本音频播放和录音相关的功能；\n* 3、低层级Audio Units针对音频信号进行完全控制的功能。\n\n### Core Video\nCore Video是OS X和iOS系统上针对数字视频所提供的管道模式。Core Video为其相对的Core Media<font color=ff0000>提供图片缓存和缓存池支持，提供了一个能够对数字视频逐帧访问的接口</font>。\n\n### Core Media\nCore Media是AVFoundation所用到的低层级媒体管道的一部分。提供针对音频样本和视频帧处理所需的低层级数据类型和接口。Core Media还提供了CMTime数据类型的时基模型。\n\n### Core Animation\nCore Animation是OS X和iOS提供的合成及动画相关框架，封装了OpenGL和OpenGL ES功能的基本Objective-C的各种类。（似乎已经改为<font color=ff0000>Metal</font>作为Core Animation的低层渲染）\n\n### AVFoundation (本系列主要内容)\n处于高层级框架和低层级框架之间，以Objective-C接口方式提供了很多低层级框架才能实现的功能和性能,可以和高层级的框架无缝衔接。\n* 1、文本朗诵 （AVSpeechSynthesizer）\n* 2、音频播放和录制（AVAudioPlayer和AVAudioRecorder）\n* 3、媒体文件元数据（AVMetadataItem）\n* 4、视频播放 （AVPlayer 和 AVPlayerItem）\n* 5、媒体捕捉 （AVCaptureSession）\n* 6、媒体读写 （AVAssetReader和AVAssetWriter）\n* 7、媒体编辑","slug":"AVFoundation学习笔记一-iOS多媒体环境","published":1,"updated":"2018-11-08T13:41:19.805Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjo8raw1a0002drd3v6lrnltw","content":"<p><img src=\"//www.cyrus.fun/2018/10/24/AVFoundation学习笔记一-iOS多媒体环境/ios_media.png\" alt=\"\"></p>\n<h3 id=\"Core-Audio\"><a href=\"#Core-Audio\" class=\"headerlink\" title=\"Core Audio\"></a>Core Audio</h3><p>Core Audio是OS X和iOS系统上处理所有音频事件的框架。</p>\n<ul>\n<li>1、为音频和HIDI内容的录制、播放和处理提供相应接口；</li>\n<li>2、高层级AudioQueueServers框架提供的处理基本音频播放和录音相关的功能；</li>\n<li>3、低层级Audio Units针对音频信号进行完全控制的功能。</li>\n</ul>\n<h3 id=\"Core-Video\"><a href=\"#Core-Video\" class=\"headerlink\" title=\"Core Video\"></a>Core Video</h3><p>Core Video是OS X和iOS系统上针对数字视频所提供的管道模式。Core Video为其相对的Core Media<font color=\"ff0000\">提供图片缓存和缓存池支持，提供了一个能够对数字视频逐帧访问的接口</font>。</p>\n<h3 id=\"Core-Media\"><a href=\"#Core-Media\" class=\"headerlink\" title=\"Core Media\"></a>Core Media</h3><p>Core Media是AVFoundation所用到的低层级媒体管道的一部分。提供针对音频样本和视频帧处理所需的低层级数据类型和接口。Core Media还提供了CMTime数据类型的时基模型。</p>\n<h3 id=\"Core-Animation\"><a href=\"#Core-Animation\" class=\"headerlink\" title=\"Core Animation\"></a>Core Animation</h3><p>Core Animation是OS X和iOS提供的合成及动画相关框架，封装了OpenGL和OpenGL ES功能的基本Objective-C的各种类。（似乎已经改为<font color=\"ff0000\">Metal</font>作为Core Animation的低层渲染）</p>\n<h3 id=\"AVFoundation-本系列主要内容\"><a href=\"#AVFoundation-本系列主要内容\" class=\"headerlink\" title=\"AVFoundation (本系列主要内容)\"></a>AVFoundation (本系列主要内容)</h3><p>处于高层级框架和低层级框架之间，以Objective-C接口方式提供了很多低层级框架才能实现的功能和性能,可以和高层级的框架无缝衔接。</p>\n<ul>\n<li>1、文本朗诵 （AVSpeechSynthesizer）</li>\n<li>2、音频播放和录制（AVAudioPlayer和AVAudioRecorder）</li>\n<li>3、媒体文件元数据（AVMetadataItem）</li>\n<li>4、视频播放 （AVPlayer 和 AVPlayerItem）</li>\n<li>5、媒体捕捉 （AVCaptureSession）</li>\n<li>6、媒体读写 （AVAssetReader和AVAssetWriter）</li>\n<li>7、媒体编辑</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p><img src=\"//www.cyrus.fun/2018/10/24/AVFoundation学习笔记一-iOS多媒体环境/ios_media.png\" alt=\"\"></p>\n<h3 id=\"Core-Audio\"><a href=\"#Core-Audio\" class=\"headerlink\" title=\"Core Audio\"></a>Core Audio</h3><p>Core Audio是OS X和iOS系统上处理所有音频事件的框架。</p>\n<ul>\n<li>1、为音频和HIDI内容的录制、播放和处理提供相应接口；</li>\n<li>2、高层级AudioQueueServers框架提供的处理基本音频播放和录音相关的功能；</li>\n<li>3、低层级Audio Units针对音频信号进行完全控制的功能。</li>\n</ul>\n<h3 id=\"Core-Video\"><a href=\"#Core-Video\" class=\"headerlink\" title=\"Core Video\"></a>Core Video</h3><p>Core Video是OS X和iOS系统上针对数字视频所提供的管道模式。Core Video为其相对的Core Media<font color=\"ff0000\">提供图片缓存和缓存池支持，提供了一个能够对数字视频逐帧访问的接口</font>。</p>\n<h3 id=\"Core-Media\"><a href=\"#Core-Media\" class=\"headerlink\" title=\"Core Media\"></a>Core Media</h3><p>Core Media是AVFoundation所用到的低层级媒体管道的一部分。提供针对音频样本和视频帧处理所需的低层级数据类型和接口。Core Media还提供了CMTime数据类型的时基模型。</p>\n<h3 id=\"Core-Animation\"><a href=\"#Core-Animation\" class=\"headerlink\" title=\"Core Animation\"></a>Core Animation</h3><p>Core Animation是OS X和iOS提供的合成及动画相关框架，封装了OpenGL和OpenGL ES功能的基本Objective-C的各种类。（似乎已经改为<font color=\"ff0000\">Metal</font>作为Core Animation的低层渲染）</p>\n<h3 id=\"AVFoundation-本系列主要内容\"><a href=\"#AVFoundation-本系列主要内容\" class=\"headerlink\" title=\"AVFoundation (本系列主要内容)\"></a>AVFoundation (本系列主要内容)</h3><p>处于高层级框架和低层级框架之间，以Objective-C接口方式提供了很多低层级框架才能实现的功能和性能,可以和高层级的框架无缝衔接。</p>\n<ul>\n<li>1、文本朗诵 （AVSpeechSynthesizer）</li>\n<li>2、音频播放和录制（AVAudioPlayer和AVAudioRecorder）</li>\n<li>3、媒体文件元数据（AVMetadataItem）</li>\n<li>4、视频播放 （AVPlayer 和 AVPlayerItem）</li>\n<li>5、媒体捕捉 （AVCaptureSession）</li>\n<li>6、媒体读写 （AVAssetReader和AVAssetWriter）</li>\n<li>7、媒体编辑</li>\n</ul>\n"},{"title":"AVFoundation学习笔记六 读取相册内容ALAsset和PHAsset","author":"Cyrus","date":"2018-11-05T09:04:00.000Z","_content":"\n### ALAsset (iOS9.0已废弃)\n1、导入头文件\n```\n#import <AssetsLibrary/AssetsLibrary.h>\n```\n\n2、具体流程\n![](ALAsset.png)\n\n3、相关代码\n```\n//1、创建ALAssetsLibrary\n    ALAssetsLibrary *library = [[ALAssetsLibrary alloc] init];\n    //2、根据传入的type，在block中获得ALAssetsGroup，即相应的相册\n    [library enumerateGroupsWithTypes:ALAssetsGroupSavedPhotos usingBlock:^(ALAssetsGroup *group, BOOL *stop) {\n        //3、相册设置筛选类型\n        [group setAssetsFilter:[ALAssetsFilter allVideos]];\n        //4、根据o筛选类型，遍历相册，在block回调中得到相应ALAsset\n        [group enumerateAssetsAtIndexes:[NSIndexSet indexSetWithIndex:0] options:0 usingBlock:^(ALAsset *result, NSUInteger index, BOOL *stop) {\n            //5、对ALAsset进行相关操作\n            if (result) {\n                ALAssetRepresentation *representation = [result defaultRepresentation];\n                NSURL *url = representation.url;\n                NSLog(@\"%@\", url);\n            }\n        }];\n\n    } failureBlock:^(NSError *error) {\n        NSLog(@\"error: %@\", error.localizedDescription);\n    }];\n```\n\n### PHAsset (ALAsset的代替）\n1、导入头文件\n```\n#import <Photos/Photos.h>\n```\n\n2、具体流程\n![](PHAsset.png)\n\n3、相关代码\n```\n/**\n     * 1、PHAssetCollection（类似上面ALAssetsGroup相册的概念,有多个类，根据具体情况选择），调用fetch 开头的函数，得到一个PHFetchResult<PHAssetCollection *> *结果对象（相当于符合筛选的PHAssetCollection相册数组）\n     *   PHFetchResult:类似于C++的模板类，提供统一的collection类、PHAsset类筛选结果的遍历、获取方法\n     */\n    PHFetchResult *results = [PHAssetCollection fetchAssetCollectionsWithType:PHAssetCollectionTypeAlbum subtype:PHAssetCollectionSubtypeAlbumRegular options:0];\n    //2、遍历results,对象为上面调用fetch函数的collection类\n    [results enumerateObjectsUsingBlock:^(PHAssetCollection *obj, NSUInteger idx, BOOL * _Nonnull stop) {\n        //3、PHAsset调用fetch方法，获取相应PHAssetCollection相册内符合要求的PHAsset集合PHFetchResult\n        PHFetchResult *assets = [PHAsset fetchAssetsInAssetCollection:obj options:nil];\n        //4、遍历assets\n        [assets enumerateObjectsUsingBlock:^(PHAsset *obj, NSUInteger idx, BOOL * _Nonnull stop) {\n            //根据asset的mediaType类型，调用相应的PHImageManager request方法（注意不同类型传入的options参数不同）\n            if (obj.mediaType == PHAssetMediaTypeImage) {\n                [[PHImageManager defaultManager] requestImageForAsset:obj targetSize:CGSizeMake(obj.pixelWidth, obj.pixelHeight) contentMode:PHImageContentModeDefault options:[[PHImageRequestOptions alloc] init] resultHandler:^(UIImage * _Nullable result, NSDictionary * _Nullable info) {\n                    NSLog(@\"%@\", [NSThread currentThread]);\n                    UIImageView *imageView = [[UIImageView alloc] initWithFrame:self.view.bounds];\n                    imageView.image = result;\n                    [self.view addSubview:imageView];\n                }];\n            } else if (obj.mediaType == PHAssetMediaTypeVideo) {\n                \n            }\n        }];\n    }];\n```\n\n","source":"_posts/AVFoundation学习笔记七-读取相册内容ALAsset和PHAsset.md","raw":"title: AVFoundation学习笔记六 读取相册内容ALAsset和PHAsset\nauthor: Cyrus\ntags: []\ncategories:\n  - AVFoundation\ndate: 2018-11-05 17:04:00\n---\n\n### ALAsset (iOS9.0已废弃)\n1、导入头文件\n```\n#import <AssetsLibrary/AssetsLibrary.h>\n```\n\n2、具体流程\n![](ALAsset.png)\n\n3、相关代码\n```\n//1、创建ALAssetsLibrary\n    ALAssetsLibrary *library = [[ALAssetsLibrary alloc] init];\n    //2、根据传入的type，在block中获得ALAssetsGroup，即相应的相册\n    [library enumerateGroupsWithTypes:ALAssetsGroupSavedPhotos usingBlock:^(ALAssetsGroup *group, BOOL *stop) {\n        //3、相册设置筛选类型\n        [group setAssetsFilter:[ALAssetsFilter allVideos]];\n        //4、根据o筛选类型，遍历相册，在block回调中得到相应ALAsset\n        [group enumerateAssetsAtIndexes:[NSIndexSet indexSetWithIndex:0] options:0 usingBlock:^(ALAsset *result, NSUInteger index, BOOL *stop) {\n            //5、对ALAsset进行相关操作\n            if (result) {\n                ALAssetRepresentation *representation = [result defaultRepresentation];\n                NSURL *url = representation.url;\n                NSLog(@\"%@\", url);\n            }\n        }];\n\n    } failureBlock:^(NSError *error) {\n        NSLog(@\"error: %@\", error.localizedDescription);\n    }];\n```\n\n### PHAsset (ALAsset的代替）\n1、导入头文件\n```\n#import <Photos/Photos.h>\n```\n\n2、具体流程\n![](PHAsset.png)\n\n3、相关代码\n```\n/**\n     * 1、PHAssetCollection（类似上面ALAssetsGroup相册的概念,有多个类，根据具体情况选择），调用fetch 开头的函数，得到一个PHFetchResult<PHAssetCollection *> *结果对象（相当于符合筛选的PHAssetCollection相册数组）\n     *   PHFetchResult:类似于C++的模板类，提供统一的collection类、PHAsset类筛选结果的遍历、获取方法\n     */\n    PHFetchResult *results = [PHAssetCollection fetchAssetCollectionsWithType:PHAssetCollectionTypeAlbum subtype:PHAssetCollectionSubtypeAlbumRegular options:0];\n    //2、遍历results,对象为上面调用fetch函数的collection类\n    [results enumerateObjectsUsingBlock:^(PHAssetCollection *obj, NSUInteger idx, BOOL * _Nonnull stop) {\n        //3、PHAsset调用fetch方法，获取相应PHAssetCollection相册内符合要求的PHAsset集合PHFetchResult\n        PHFetchResult *assets = [PHAsset fetchAssetsInAssetCollection:obj options:nil];\n        //4、遍历assets\n        [assets enumerateObjectsUsingBlock:^(PHAsset *obj, NSUInteger idx, BOOL * _Nonnull stop) {\n            //根据asset的mediaType类型，调用相应的PHImageManager request方法（注意不同类型传入的options参数不同）\n            if (obj.mediaType == PHAssetMediaTypeImage) {\n                [[PHImageManager defaultManager] requestImageForAsset:obj targetSize:CGSizeMake(obj.pixelWidth, obj.pixelHeight) contentMode:PHImageContentModeDefault options:[[PHImageRequestOptions alloc] init] resultHandler:^(UIImage * _Nullable result, NSDictionary * _Nullable info) {\n                    NSLog(@\"%@\", [NSThread currentThread]);\n                    UIImageView *imageView = [[UIImageView alloc] initWithFrame:self.view.bounds];\n                    imageView.image = result;\n                    [self.view addSubview:imageView];\n                }];\n            } else if (obj.mediaType == PHAssetMediaTypeVideo) {\n                \n            }\n        }];\n    }];\n```\n\n","slug":"AVFoundation学习笔记七-读取相册内容ALAsset和PHAsset","published":1,"updated":"2018-11-08T13:41:19.806Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjo8raw1d0006drd3ven3mgar","content":"<h3 id=\"ALAsset-iOS9-0已废弃\"><a href=\"#ALAsset-iOS9-0已废弃\" class=\"headerlink\" title=\"ALAsset (iOS9.0已废弃)\"></a>ALAsset (iOS9.0已废弃)</h3><p>1、导入头文件<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#import &lt;AssetsLibrary/AssetsLibrary.h&gt;</span><br></pre></td></tr></table></figure></p>\n<p>2、具体流程<br><img src=\"//www.cyrus.fun/2018/11/05/AVFoundation学习笔记七-读取相册内容ALAsset和PHAsset/ALAsset.png\" alt=\"\"></p>\n<p>3、相关代码<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//1、创建ALAssetsLibrary</span><br><span class=\"line\">    ALAssetsLibrary *library = [[ALAssetsLibrary alloc] init];</span><br><span class=\"line\">    //2、根据传入的type，在block中获得ALAssetsGroup，即相应的相册</span><br><span class=\"line\">    [library enumerateGroupsWithTypes:ALAssetsGroupSavedPhotos usingBlock:^(ALAssetsGroup *group, BOOL *stop) &#123;</span><br><span class=\"line\">        //3、相册设置筛选类型</span><br><span class=\"line\">        [group setAssetsFilter:[ALAssetsFilter allVideos]];</span><br><span class=\"line\">        //4、根据o筛选类型，遍历相册，在block回调中得到相应ALAsset</span><br><span class=\"line\">        [group enumerateAssetsAtIndexes:[NSIndexSet indexSetWithIndex:0] options:0 usingBlock:^(ALAsset *result, NSUInteger index, BOOL *stop) &#123;</span><br><span class=\"line\">            //5、对ALAsset进行相关操作</span><br><span class=\"line\">            if (result) &#123;</span><br><span class=\"line\">                ALAssetRepresentation *representation = [result defaultRepresentation];</span><br><span class=\"line\">                NSURL *url = representation.url;</span><br><span class=\"line\">                NSLog(@&quot;%@&quot;, url);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;];</span><br><span class=\"line\"></span><br><span class=\"line\">    &#125; failureBlock:^(NSError *error) &#123;</span><br><span class=\"line\">        NSLog(@&quot;error: %@&quot;, error.localizedDescription);</span><br><span class=\"line\">    &#125;];</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"PHAsset-ALAsset的代替）\"><a href=\"#PHAsset-ALAsset的代替）\" class=\"headerlink\" title=\"PHAsset (ALAsset的代替）\"></a>PHAsset (ALAsset的代替）</h3><p>1、导入头文件<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#import &lt;Photos/Photos.h&gt;</span><br></pre></td></tr></table></figure></p>\n<p>2、具体流程<br><img src=\"//www.cyrus.fun/2018/11/05/AVFoundation学习笔记七-读取相册内容ALAsset和PHAsset/PHAsset.png\" alt=\"\"></p>\n<p>3、相关代码<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/**</span><br><span class=\"line\">     * 1、PHAssetCollection（类似上面ALAssetsGroup相册的概念,有多个类，根据具体情况选择），调用fetch 开头的函数，得到一个PHFetchResult&lt;PHAssetCollection *&gt; *结果对象（相当于符合筛选的PHAssetCollection相册数组）</span><br><span class=\"line\">     *   PHFetchResult:类似于C++的模板类，提供统一的collection类、PHAsset类筛选结果的遍历、获取方法</span><br><span class=\"line\">     */</span><br><span class=\"line\">    PHFetchResult *results = [PHAssetCollection fetchAssetCollectionsWithType:PHAssetCollectionTypeAlbum subtype:PHAssetCollectionSubtypeAlbumRegular options:0];</span><br><span class=\"line\">    //2、遍历results,对象为上面调用fetch函数的collection类</span><br><span class=\"line\">    [results enumerateObjectsUsingBlock:^(PHAssetCollection *obj, NSUInteger idx, BOOL * _Nonnull stop) &#123;</span><br><span class=\"line\">        //3、PHAsset调用fetch方法，获取相应PHAssetCollection相册内符合要求的PHAsset集合PHFetchResult</span><br><span class=\"line\">        PHFetchResult *assets = [PHAsset fetchAssetsInAssetCollection:obj options:nil];</span><br><span class=\"line\">        //4、遍历assets</span><br><span class=\"line\">        [assets enumerateObjectsUsingBlock:^(PHAsset *obj, NSUInteger idx, BOOL * _Nonnull stop) &#123;</span><br><span class=\"line\">            //根据asset的mediaType类型，调用相应的PHImageManager request方法（注意不同类型传入的options参数不同）</span><br><span class=\"line\">            if (obj.mediaType == PHAssetMediaTypeImage) &#123;</span><br><span class=\"line\">                [[PHImageManager defaultManager] requestImageForAsset:obj targetSize:CGSizeMake(obj.pixelWidth, obj.pixelHeight) contentMode:PHImageContentModeDefault options:[[PHImageRequestOptions alloc] init] resultHandler:^(UIImage * _Nullable result, NSDictionary * _Nullable info) &#123;</span><br><span class=\"line\">                    NSLog(@&quot;%@&quot;, [NSThread currentThread]);</span><br><span class=\"line\">                    UIImageView *imageView = [[UIImageView alloc] initWithFrame:self.view.bounds];</span><br><span class=\"line\">                    imageView.image = result;</span><br><span class=\"line\">                    [self.view addSubview:imageView];</span><br><span class=\"line\">                &#125;];</span><br><span class=\"line\">            &#125; else if (obj.mediaType == PHAssetMediaTypeVideo) &#123;</span><br><span class=\"line\">                </span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;];</span><br><span class=\"line\">    &#125;];</span><br></pre></td></tr></table></figure></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"ALAsset-iOS9-0已废弃\"><a href=\"#ALAsset-iOS9-0已废弃\" class=\"headerlink\" title=\"ALAsset (iOS9.0已废弃)\"></a>ALAsset (iOS9.0已废弃)</h3><p>1、导入头文件<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#import &lt;AssetsLibrary/AssetsLibrary.h&gt;</span><br></pre></td></tr></table></figure></p>\n<p>2、具体流程<br><img src=\"//www.cyrus.fun/2018/11/05/AVFoundation学习笔记七-读取相册内容ALAsset和PHAsset/ALAsset.png\" alt=\"\"></p>\n<p>3、相关代码<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//1、创建ALAssetsLibrary</span><br><span class=\"line\">    ALAssetsLibrary *library = [[ALAssetsLibrary alloc] init];</span><br><span class=\"line\">    //2、根据传入的type，在block中获得ALAssetsGroup，即相应的相册</span><br><span class=\"line\">    [library enumerateGroupsWithTypes:ALAssetsGroupSavedPhotos usingBlock:^(ALAssetsGroup *group, BOOL *stop) &#123;</span><br><span class=\"line\">        //3、相册设置筛选类型</span><br><span class=\"line\">        [group setAssetsFilter:[ALAssetsFilter allVideos]];</span><br><span class=\"line\">        //4、根据o筛选类型，遍历相册，在block回调中得到相应ALAsset</span><br><span class=\"line\">        [group enumerateAssetsAtIndexes:[NSIndexSet indexSetWithIndex:0] options:0 usingBlock:^(ALAsset *result, NSUInteger index, BOOL *stop) &#123;</span><br><span class=\"line\">            //5、对ALAsset进行相关操作</span><br><span class=\"line\">            if (result) &#123;</span><br><span class=\"line\">                ALAssetRepresentation *representation = [result defaultRepresentation];</span><br><span class=\"line\">                NSURL *url = representation.url;</span><br><span class=\"line\">                NSLog(@&quot;%@&quot;, url);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;];</span><br><span class=\"line\"></span><br><span class=\"line\">    &#125; failureBlock:^(NSError *error) &#123;</span><br><span class=\"line\">        NSLog(@&quot;error: %@&quot;, error.localizedDescription);</span><br><span class=\"line\">    &#125;];</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"PHAsset-ALAsset的代替）\"><a href=\"#PHAsset-ALAsset的代替）\" class=\"headerlink\" title=\"PHAsset (ALAsset的代替）\"></a>PHAsset (ALAsset的代替）</h3><p>1、导入头文件<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#import &lt;Photos/Photos.h&gt;</span><br></pre></td></tr></table></figure></p>\n<p>2、具体流程<br><img src=\"//www.cyrus.fun/2018/11/05/AVFoundation学习笔记七-读取相册内容ALAsset和PHAsset/PHAsset.png\" alt=\"\"></p>\n<p>3、相关代码<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/**</span><br><span class=\"line\">     * 1、PHAssetCollection（类似上面ALAssetsGroup相册的概念,有多个类，根据具体情况选择），调用fetch 开头的函数，得到一个PHFetchResult&lt;PHAssetCollection *&gt; *结果对象（相当于符合筛选的PHAssetCollection相册数组）</span><br><span class=\"line\">     *   PHFetchResult:类似于C++的模板类，提供统一的collection类、PHAsset类筛选结果的遍历、获取方法</span><br><span class=\"line\">     */</span><br><span class=\"line\">    PHFetchResult *results = [PHAssetCollection fetchAssetCollectionsWithType:PHAssetCollectionTypeAlbum subtype:PHAssetCollectionSubtypeAlbumRegular options:0];</span><br><span class=\"line\">    //2、遍历results,对象为上面调用fetch函数的collection类</span><br><span class=\"line\">    [results enumerateObjectsUsingBlock:^(PHAssetCollection *obj, NSUInteger idx, BOOL * _Nonnull stop) &#123;</span><br><span class=\"line\">        //3、PHAsset调用fetch方法，获取相应PHAssetCollection相册内符合要求的PHAsset集合PHFetchResult</span><br><span class=\"line\">        PHFetchResult *assets = [PHAsset fetchAssetsInAssetCollection:obj options:nil];</span><br><span class=\"line\">        //4、遍历assets</span><br><span class=\"line\">        [assets enumerateObjectsUsingBlock:^(PHAsset *obj, NSUInteger idx, BOOL * _Nonnull stop) &#123;</span><br><span class=\"line\">            //根据asset的mediaType类型，调用相应的PHImageManager request方法（注意不同类型传入的options参数不同）</span><br><span class=\"line\">            if (obj.mediaType == PHAssetMediaTypeImage) &#123;</span><br><span class=\"line\">                [[PHImageManager defaultManager] requestImageForAsset:obj targetSize:CGSizeMake(obj.pixelWidth, obj.pixelHeight) contentMode:PHImageContentModeDefault options:[[PHImageRequestOptions alloc] init] resultHandler:^(UIImage * _Nullable result, NSDictionary * _Nullable info) &#123;</span><br><span class=\"line\">                    NSLog(@&quot;%@&quot;, [NSThread currentThread]);</span><br><span class=\"line\">                    UIImageView *imageView = [[UIImageView alloc] initWithFrame:self.view.bounds];</span><br><span class=\"line\">                    imageView.image = result;</span><br><span class=\"line\">                    [self.view addSubview:imageView];</span><br><span class=\"line\">                &#125;];</span><br><span class=\"line\">            &#125; else if (obj.mediaType == PHAssetMediaTypeVideo) &#123;</span><br><span class=\"line\">                </span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;];</span><br><span class=\"line\">    &#125;];</span><br></pre></td></tr></table></figure></p>\n"},{"title":"AVFoundation学习笔记七 异步加载属性及媒体元数据","author":"Cyrus","date":"2018-11-08T14:21:00.000Z","_content":"\nAVAsset有多种方法和属性，比如时长、创建日期和元数据等，同时还包含一些用于获取和使用曲目集合的方法。AVAsset使用延迟载入资源的属性（懒加载）,直到请求才载入。这样可以更快地创建AVAsset对象（没有载入相关媒体/元数据的时间）。这样会产生一些问题，那就是首次访问某些属性时，如asset的duration(总时长），如MP3文件没有在头文件中设置TLEN标签（用于记录duration值）,则需要解析整个文件来确定时长。如果发生在主线程，就会阻塞主线程。所以，AVAsset/AVAssetTrack/ AVMetadataItem等类都实现了AVAsynchronousKeyValueLoading协议，以实现异步查询属性的功能。\n\n### AVAsynchronousKeyValueLoading 协议\n```\n//查询给定属性是否会导致程序卡顿，AVKeyValueStatusLoaded:不会卡顿，反之卡顿\n- (AVKeyValueStatus)statusOfValueForKey:(NSString *)key error:(NSError * _Nullable * _Nullable)outError;\n\n//异步加载属性\n- (void)loadValuesAsynchronouslyForKeys:(NSArray<NSString *> *)keys completionHandler:(nullable void (^)(void))handler;\n```\n\n代码示例\n```\nNSURL *assetURL = [[NSBundle mainBundle] URLForResource:@\"xxx\" withExtension:@\"xxx\"];\n    AVAsset *asset = [AVAsset assetWithURL:assetURL];\n    \n    //1、设置要查询的属性（数组）\n    NSArray *keys = @[@\"tracks\"];\n    [asset loadValuesAsynchronouslyForKeys:keys completionHandler:^{\n        //判断相关属性的状态并进行对应处理\n        AVKeyValueStatus status = [asset statusOfValueForKey:@\"tracks\" error:nil];\n        switch (status) {\n            case AVKeyValueStatusLoaded:\n                //continue processing\n                break;\n            case AVKeyValueStatusFailed:\n                //handle failure with error\n                break;\n            case AVKeyValueStatusCancelled:\n                //handle explicit cancellation\n                break;\n            default:\n                //handle all other case\n                break;\n        }\n    }];\n```\n\n注意：loadValuesAsynchronouslyForKeys:completionHandler: 可以一次查询多个属性，但completionHandle只会回调一次，且所查询的属性调用statusOfValueForKey：的返回值不一定相同。","source":"_posts/AVFoundation学习笔记七.md","raw":"title: AVFoundation学习笔记七 异步加载属性及媒体元数据\nauthor: Cyrus\ntags: []\ncategories:\n  - AVFoundation\ndate: 2018-11-08 22:21:00\n---\n\nAVAsset有多种方法和属性，比如时长、创建日期和元数据等，同时还包含一些用于获取和使用曲目集合的方法。AVAsset使用延迟载入资源的属性（懒加载）,直到请求才载入。这样可以更快地创建AVAsset对象（没有载入相关媒体/元数据的时间）。这样会产生一些问题，那就是首次访问某些属性时，如asset的duration(总时长），如MP3文件没有在头文件中设置TLEN标签（用于记录duration值）,则需要解析整个文件来确定时长。如果发生在主线程，就会阻塞主线程。所以，AVAsset/AVAssetTrack/ AVMetadataItem等类都实现了AVAsynchronousKeyValueLoading协议，以实现异步查询属性的功能。\n\n### AVAsynchronousKeyValueLoading 协议\n```\n//查询给定属性是否会导致程序卡顿，AVKeyValueStatusLoaded:不会卡顿，反之卡顿\n- (AVKeyValueStatus)statusOfValueForKey:(NSString *)key error:(NSError * _Nullable * _Nullable)outError;\n\n//异步加载属性\n- (void)loadValuesAsynchronouslyForKeys:(NSArray<NSString *> *)keys completionHandler:(nullable void (^)(void))handler;\n```\n\n代码示例\n```\nNSURL *assetURL = [[NSBundle mainBundle] URLForResource:@\"xxx\" withExtension:@\"xxx\"];\n    AVAsset *asset = [AVAsset assetWithURL:assetURL];\n    \n    //1、设置要查询的属性（数组）\n    NSArray *keys = @[@\"tracks\"];\n    [asset loadValuesAsynchronouslyForKeys:keys completionHandler:^{\n        //判断相关属性的状态并进行对应处理\n        AVKeyValueStatus status = [asset statusOfValueForKey:@\"tracks\" error:nil];\n        switch (status) {\n            case AVKeyValueStatusLoaded:\n                //continue processing\n                break;\n            case AVKeyValueStatusFailed:\n                //handle failure with error\n                break;\n            case AVKeyValueStatusCancelled:\n                //handle explicit cancellation\n                break;\n            default:\n                //handle all other case\n                break;\n        }\n    }];\n```\n\n注意：loadValuesAsynchronouslyForKeys:completionHandler: 可以一次查询多个属性，但completionHandle只会回调一次，且所查询的属性调用statusOfValueForKey：的返回值不一定相同。","slug":"AVFoundation学习笔记七","published":1,"updated":"2018-11-08T14:24:17.126Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjo8raw1e0007drd3f6rybsde","content":"<p>AVAsset有多种方法和属性，比如时长、创建日期和元数据等，同时还包含一些用于获取和使用曲目集合的方法。AVAsset使用延迟载入资源的属性（懒加载）,直到请求才载入。这样可以更快地创建AVAsset对象（没有载入相关媒体/元数据的时间）。这样会产生一些问题，那就是首次访问某些属性时，如asset的duration(总时长），如MP3文件没有在头文件中设置TLEN标签（用于记录duration值）,则需要解析整个文件来确定时长。如果发生在主线程，就会阻塞主线程。所以，AVAsset/AVAssetTrack/ AVMetadataItem等类都实现了AVAsynchronousKeyValueLoading协议，以实现异步查询属性的功能。</p>\n<h3 id=\"AVAsynchronousKeyValueLoading-协议\"><a href=\"#AVAsynchronousKeyValueLoading-协议\" class=\"headerlink\" title=\"AVAsynchronousKeyValueLoading 协议\"></a>AVAsynchronousKeyValueLoading 协议</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//查询给定属性是否会导致程序卡顿，AVKeyValueStatusLoaded:不会卡顿，反之卡顿</span><br><span class=\"line\">- (AVKeyValueStatus)statusOfValueForKey:(NSString *)key error:(NSError * _Nullable * _Nullable)outError;</span><br><span class=\"line\"></span><br><span class=\"line\">//异步加载属性</span><br><span class=\"line\">- (void)loadValuesAsynchronouslyForKeys:(NSArray&lt;NSString *&gt; *)keys completionHandler:(nullable void (^)(void))handler;</span><br></pre></td></tr></table></figure>\n<p>代码示例<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">NSURL *assetURL = [[NSBundle mainBundle] URLForResource:@&quot;xxx&quot; withExtension:@&quot;xxx&quot;];</span><br><span class=\"line\">    AVAsset *asset = [AVAsset assetWithURL:assetURL];</span><br><span class=\"line\">    </span><br><span class=\"line\">    //1、设置要查询的属性（数组）</span><br><span class=\"line\">    NSArray *keys = @[@&quot;tracks&quot;];</span><br><span class=\"line\">    [asset loadValuesAsynchronouslyForKeys:keys completionHandler:^&#123;</span><br><span class=\"line\">        //判断相关属性的状态并进行对应处理</span><br><span class=\"line\">        AVKeyValueStatus status = [asset statusOfValueForKey:@&quot;tracks&quot; error:nil];</span><br><span class=\"line\">        switch (status) &#123;</span><br><span class=\"line\">            case AVKeyValueStatusLoaded:</span><br><span class=\"line\">                //continue processing</span><br><span class=\"line\">                break;</span><br><span class=\"line\">            case AVKeyValueStatusFailed:</span><br><span class=\"line\">                //handle failure with error</span><br><span class=\"line\">                break;</span><br><span class=\"line\">            case AVKeyValueStatusCancelled:</span><br><span class=\"line\">                //handle explicit cancellation</span><br><span class=\"line\">                break;</span><br><span class=\"line\">            default:</span><br><span class=\"line\">                //handle all other case</span><br><span class=\"line\">                break;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;];</span><br></pre></td></tr></table></figure></p>\n<p>注意：loadValuesAsynchronouslyForKeys:completionHandler: 可以一次查询多个属性，但completionHandle只会回调一次，且所查询的属性调用statusOfValueForKey：的返回值不一定相同。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>AVAsset有多种方法和属性，比如时长、创建日期和元数据等，同时还包含一些用于获取和使用曲目集合的方法。AVAsset使用延迟载入资源的属性（懒加载）,直到请求才载入。这样可以更快地创建AVAsset对象（没有载入相关媒体/元数据的时间）。这样会产生一些问题，那就是首次访问某些属性时，如asset的duration(总时长），如MP3文件没有在头文件中设置TLEN标签（用于记录duration值）,则需要解析整个文件来确定时长。如果发生在主线程，就会阻塞主线程。所以，AVAsset/AVAssetTrack/ AVMetadataItem等类都实现了AVAsynchronousKeyValueLoading协议，以实现异步查询属性的功能。</p>\n<h3 id=\"AVAsynchronousKeyValueLoading-协议\"><a href=\"#AVAsynchronousKeyValueLoading-协议\" class=\"headerlink\" title=\"AVAsynchronousKeyValueLoading 协议\"></a>AVAsynchronousKeyValueLoading 协议</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//查询给定属性是否会导致程序卡顿，AVKeyValueStatusLoaded:不会卡顿，反之卡顿</span><br><span class=\"line\">- (AVKeyValueStatus)statusOfValueForKey:(NSString *)key error:(NSError * _Nullable * _Nullable)outError;</span><br><span class=\"line\"></span><br><span class=\"line\">//异步加载属性</span><br><span class=\"line\">- (void)loadValuesAsynchronouslyForKeys:(NSArray&lt;NSString *&gt; *)keys completionHandler:(nullable void (^)(void))handler;</span><br></pre></td></tr></table></figure>\n<p>代码示例<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">NSURL *assetURL = [[NSBundle mainBundle] URLForResource:@&quot;xxx&quot; withExtension:@&quot;xxx&quot;];</span><br><span class=\"line\">    AVAsset *asset = [AVAsset assetWithURL:assetURL];</span><br><span class=\"line\">    </span><br><span class=\"line\">    //1、设置要查询的属性（数组）</span><br><span class=\"line\">    NSArray *keys = @[@&quot;tracks&quot;];</span><br><span class=\"line\">    [asset loadValuesAsynchronouslyForKeys:keys completionHandler:^&#123;</span><br><span class=\"line\">        //判断相关属性的状态并进行对应处理</span><br><span class=\"line\">        AVKeyValueStatus status = [asset statusOfValueForKey:@&quot;tracks&quot; error:nil];</span><br><span class=\"line\">        switch (status) &#123;</span><br><span class=\"line\">            case AVKeyValueStatusLoaded:</span><br><span class=\"line\">                //continue processing</span><br><span class=\"line\">                break;</span><br><span class=\"line\">            case AVKeyValueStatusFailed:</span><br><span class=\"line\">                //handle failure with error</span><br><span class=\"line\">                break;</span><br><span class=\"line\">            case AVKeyValueStatusCancelled:</span><br><span class=\"line\">                //handle explicit cancellation</span><br><span class=\"line\">                break;</span><br><span class=\"line\">            default:</span><br><span class=\"line\">                //handle all other case</span><br><span class=\"line\">                break;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;];</span><br></pre></td></tr></table></figure></p>\n<p>注意：loadValuesAsynchronouslyForKeys:completionHandler: 可以一次查询多个属性，但completionHandle只会回调一次，且所查询的属性调用statusOfValueForKey：的返回值不一定相同。</p>\n"},{"title":"AVFoundation学习笔记四  AVAudioPlayer","author":"Cyrus","date":"2018-11-01T15:10:00.000Z","_content":"![](audioplayer.png)\n\nAVAudioPlayer 比较简单，主要说几个有用的方法和属性。\n#### 属性\n* 1、pan:立体声设置，0:立体声  -1：左声道  1：右声道\n* 2、volume:  音量    0.0 - 1.0\n* 3、rate: 播放速率    0.5 - 2.0      0.5：半速  1.0：正常速度   2.0：倍速\n* 4、currentTime: 音频文件的播放时间\n* 5、deviceCurrentTime: 输出设备播放音频的时间，注意如果播放中被暂停此时间也会继续累加\n* 6、numberOfLoop:  循环播放次数，默认为1， -1为无限循环\n* 7、settting: 文件的基本信息\n```\n{\n    AVAudioFileTypeKey = 1667327590;\t\\\\大端序数据，转主机序后为lpcm\n    AVChannelLayoutKey = <02006500 03000000 00000000>;\n    AVEncoderBitRateKey = 0;\n    AVFormatIDKey = 1819304813;\t\t\\\\大端序数据，转主机序后为caff\n    AVLinearPCMBitDepthKey = 16;\t\\\\采样精度\n    AVLinearPCMIsBigEndianKey = 1;\t\\\\数据是否以大端序保存\n    AVLinearPCMIsFloatKey = 0;\t\t\n    AVLinearPCMIsNonInterleaved = 0;\n    AVNumberOfChannelsKey = 2;\t\t\\\\通道数\n    AVSampleRateKey = 44100;\t\t\\\\采样率\n}\n```\n* 8、duration: 文件总时长\n* 9、numberOfChannels： 该音频的声道数\n* 10、meteringEnabled： 是否允许测量声道平均值和峰值\n\n#### 方法\n* 1、- (BOOL)prepareToPlay;  取得需要的音频硬件并预加载AudioQueue缓冲区.\n* 2、- (BOOL)play;\n* 3、- (BOOL)playAtTime:(NSTimeInterval)time； 播放没有调用prepareToPlay的话会隐式调用\n* 4、- (void)pause;\n* 5、- (void)stop;  停止播放。<font color=ff0000>区别：stop会把prepareToPlay所做的准备释放掉，pause不会，即pause后调用play响应较快。</font>\n* 6、-（void）updateMeters;  meteringEnabled为true时，刷新对应声道强度的峰值和平均值\n* 7、- (float)peakPowerForChannel:(NSUInteger)channelNumber; 对应声道强度的峰值\n* 8、- (float)averagePowerForChannel:(NSUInteger)channelNumber; 对应声道强度的平均值\n\n<font color=ff0000>注：7、8有效的前提条件为 meteringEnabled = YES && 调用了updateMeters。此计数是以对数刻度计量的，-160表示完全安静，0表示最大输入值。</font>可用于动态展示音频强度状态。\n\n","source":"_posts/AVFoundation学习笔记二-AVAudioPlayer.md","raw":"title: AVFoundation学习笔记四  AVAudioPlayer\nauthor: Cyrus\ntags: []\ncategories:\n  - AVFoundation\ndate: 2018-11-01 23:10:00\n---\n![](audioplayer.png)\n\nAVAudioPlayer 比较简单，主要说几个有用的方法和属性。\n#### 属性\n* 1、pan:立体声设置，0:立体声  -1：左声道  1：右声道\n* 2、volume:  音量    0.0 - 1.0\n* 3、rate: 播放速率    0.5 - 2.0      0.5：半速  1.0：正常速度   2.0：倍速\n* 4、currentTime: 音频文件的播放时间\n* 5、deviceCurrentTime: 输出设备播放音频的时间，注意如果播放中被暂停此时间也会继续累加\n* 6、numberOfLoop:  循环播放次数，默认为1， -1为无限循环\n* 7、settting: 文件的基本信息\n```\n{\n    AVAudioFileTypeKey = 1667327590;\t\\\\大端序数据，转主机序后为lpcm\n    AVChannelLayoutKey = <02006500 03000000 00000000>;\n    AVEncoderBitRateKey = 0;\n    AVFormatIDKey = 1819304813;\t\t\\\\大端序数据，转主机序后为caff\n    AVLinearPCMBitDepthKey = 16;\t\\\\采样精度\n    AVLinearPCMIsBigEndianKey = 1;\t\\\\数据是否以大端序保存\n    AVLinearPCMIsFloatKey = 0;\t\t\n    AVLinearPCMIsNonInterleaved = 0;\n    AVNumberOfChannelsKey = 2;\t\t\\\\通道数\n    AVSampleRateKey = 44100;\t\t\\\\采样率\n}\n```\n* 8、duration: 文件总时长\n* 9、numberOfChannels： 该音频的声道数\n* 10、meteringEnabled： 是否允许测量声道平均值和峰值\n\n#### 方法\n* 1、- (BOOL)prepareToPlay;  取得需要的音频硬件并预加载AudioQueue缓冲区.\n* 2、- (BOOL)play;\n* 3、- (BOOL)playAtTime:(NSTimeInterval)time； 播放没有调用prepareToPlay的话会隐式调用\n* 4、- (void)pause;\n* 5、- (void)stop;  停止播放。<font color=ff0000>区别：stop会把prepareToPlay所做的准备释放掉，pause不会，即pause后调用play响应较快。</font>\n* 6、-（void）updateMeters;  meteringEnabled为true时，刷新对应声道强度的峰值和平均值\n* 7、- (float)peakPowerForChannel:(NSUInteger)channelNumber; 对应声道强度的峰值\n* 8、- (float)averagePowerForChannel:(NSUInteger)channelNumber; 对应声道强度的平均值\n\n<font color=ff0000>注：7、8有效的前提条件为 meteringEnabled = YES && 调用了updateMeters。此计数是以对数刻度计量的，-160表示完全安静，0表示最大输入值。</font>可用于动态展示音频强度状态。\n\n","slug":"AVFoundation学习笔记二-AVAudioPlayer","published":1,"updated":"2018-11-08T13:41:19.807Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjo8raw1f0008drd3zcx5t78h","content":"<p><img src=\"//www.cyrus.fun/2018/11/01/AVFoundation学习笔记二-AVAudioPlayer/audioplayer.png\" alt=\"\"></p>\n<p>AVAudioPlayer 比较简单，主要说几个有用的方法和属性。</p>\n<h4 id=\"属性\"><a href=\"#属性\" class=\"headerlink\" title=\"属性\"></a>属性</h4><ul>\n<li>1、pan:立体声设置，0:立体声  -1：左声道  1：右声道</li>\n<li>2、volume:  音量    0.0 - 1.0</li>\n<li>3、rate: 播放速率    0.5 - 2.0      0.5：半速  1.0：正常速度   2.0：倍速</li>\n<li>4、currentTime: 音频文件的播放时间</li>\n<li>5、deviceCurrentTime: 输出设备播放音频的时间，注意如果播放中被暂停此时间也会继续累加</li>\n<li>6、numberOfLoop:  循环播放次数，默认为1， -1为无限循环</li>\n<li><p>7、settting: 文件的基本信息</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">    AVAudioFileTypeKey = 1667327590;\t\\\\大端序数据，转主机序后为lpcm</span><br><span class=\"line\">    AVChannelLayoutKey = &lt;02006500 03000000 00000000&gt;;</span><br><span class=\"line\">    AVEncoderBitRateKey = 0;</span><br><span class=\"line\">    AVFormatIDKey = 1819304813;\t\t\\\\大端序数据，转主机序后为caff</span><br><span class=\"line\">    AVLinearPCMBitDepthKey = 16;\t\\\\采样精度</span><br><span class=\"line\">    AVLinearPCMIsBigEndianKey = 1;\t\\\\数据是否以大端序保存</span><br><span class=\"line\">    AVLinearPCMIsFloatKey = 0;\t\t</span><br><span class=\"line\">    AVLinearPCMIsNonInterleaved = 0;</span><br><span class=\"line\">    AVNumberOfChannelsKey = 2;\t\t\\\\通道数</span><br><span class=\"line\">    AVSampleRateKey = 44100;\t\t\\\\采样率</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>8、duration: 文件总时长</p>\n</li>\n<li>9、numberOfChannels： 该音频的声道数</li>\n<li>10、meteringEnabled： 是否允许测量声道平均值和峰值</li>\n</ul>\n<h4 id=\"方法\"><a href=\"#方法\" class=\"headerlink\" title=\"方法\"></a>方法</h4><ul>\n<li>1、- (BOOL)prepareToPlay;  取得需要的音频硬件并预加载AudioQueue缓冲区.</li>\n<li>2、- (BOOL)play;</li>\n<li>3、- (BOOL)playAtTime:(NSTimeInterval)time； 播放没有调用prepareToPlay的话会隐式调用</li>\n<li>4、- (void)pause;</li>\n<li>5、- (void)stop;  停止播放。<font color=\"ff0000\">区别：stop会把prepareToPlay所做的准备释放掉，pause不会，即pause后调用play响应较快。</font></li>\n<li>6、-（void）updateMeters;  meteringEnabled为true时，刷新对应声道强度的峰值和平均值</li>\n<li>7、- (float)peakPowerForChannel:(NSUInteger)channelNumber; 对应声道强度的峰值</li>\n<li>8、- (float)averagePowerForChannel:(NSUInteger)channelNumber; 对应声道强度的平均值</li>\n</ul>\n<p><font color=\"ff0000\">注：7、8有效的前提条件为 meteringEnabled = YES &amp;&amp; 调用了updateMeters。此计数是以对数刻度计量的，-160表示完全安静，0表示最大输入值。</font>可用于动态展示音频强度状态。</p>\n","site":{"data":{}},"excerpt":"","more":"<p><img src=\"//www.cyrus.fun/2018/11/01/AVFoundation学习笔记二-AVAudioPlayer/audioplayer.png\" alt=\"\"></p>\n<p>AVAudioPlayer 比较简单，主要说几个有用的方法和属性。</p>\n<h4 id=\"属性\"><a href=\"#属性\" class=\"headerlink\" title=\"属性\"></a>属性</h4><ul>\n<li>1、pan:立体声设置，0:立体声  -1：左声道  1：右声道</li>\n<li>2、volume:  音量    0.0 - 1.0</li>\n<li>3、rate: 播放速率    0.5 - 2.0      0.5：半速  1.0：正常速度   2.0：倍速</li>\n<li>4、currentTime: 音频文件的播放时间</li>\n<li>5、deviceCurrentTime: 输出设备播放音频的时间，注意如果播放中被暂停此时间也会继续累加</li>\n<li>6、numberOfLoop:  循环播放次数，默认为1， -1为无限循环</li>\n<li><p>7、settting: 文件的基本信息</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">    AVAudioFileTypeKey = 1667327590;\t\\\\大端序数据，转主机序后为lpcm</span><br><span class=\"line\">    AVChannelLayoutKey = &lt;02006500 03000000 00000000&gt;;</span><br><span class=\"line\">    AVEncoderBitRateKey = 0;</span><br><span class=\"line\">    AVFormatIDKey = 1819304813;\t\t\\\\大端序数据，转主机序后为caff</span><br><span class=\"line\">    AVLinearPCMBitDepthKey = 16;\t\\\\采样精度</span><br><span class=\"line\">    AVLinearPCMIsBigEndianKey = 1;\t\\\\数据是否以大端序保存</span><br><span class=\"line\">    AVLinearPCMIsFloatKey = 0;\t\t</span><br><span class=\"line\">    AVLinearPCMIsNonInterleaved = 0;</span><br><span class=\"line\">    AVNumberOfChannelsKey = 2;\t\t\\\\通道数</span><br><span class=\"line\">    AVSampleRateKey = 44100;\t\t\\\\采样率</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>8、duration: 文件总时长</p>\n</li>\n<li>9、numberOfChannels： 该音频的声道数</li>\n<li>10、meteringEnabled： 是否允许测量声道平均值和峰值</li>\n</ul>\n<h4 id=\"方法\"><a href=\"#方法\" class=\"headerlink\" title=\"方法\"></a>方法</h4><ul>\n<li>1、- (BOOL)prepareToPlay;  取得需要的音频硬件并预加载AudioQueue缓冲区.</li>\n<li>2、- (BOOL)play;</li>\n<li>3、- (BOOL)playAtTime:(NSTimeInterval)time； 播放没有调用prepareToPlay的话会隐式调用</li>\n<li>4、- (void)pause;</li>\n<li>5、- (void)stop;  停止播放。<font color=\"ff0000\">区别：stop会把prepareToPlay所做的准备释放掉，pause不会，即pause后调用play响应较快。</font></li>\n<li>6、-（void）updateMeters;  meteringEnabled为true时，刷新对应声道强度的峰值和平均值</li>\n<li>7、- (float)peakPowerForChannel:(NSUInteger)channelNumber; 对应声道强度的峰值</li>\n<li>8、- (float)averagePowerForChannel:(NSUInteger)channelNumber; 对应声道强度的平均值</li>\n</ul>\n<p><font color=\"ff0000\">注：7、8有效的前提条件为 meteringEnabled = YES &amp;&amp; 调用了updateMeters。此计数是以对数刻度计量的，-160表示完全安静，0表示最大输入值。</font>可用于动态展示音频强度状态。</p>\n"},{"title":"AVFoundation学习笔记五 AVAudioRecorder","author":"Cyrus","date":"2018-11-02T07:28:00.000Z","_content":"![](recorder.png)\n比较简单的类，主要说一下几个注意的地方：\n### 一、配置AVAudioSession\n```\nAVAudioSession *session = [AVAudioSession sharedInstance];\n    NSError *error;\n    if (![session setCategory:AVAudioSessionCategoryPlayAndRecord error:&error]) {\n        NSLog(@\"Category Error: %@\", [error localizedDescription]);\n    }\n    if (![session setActive:YES error:&error]) {\n        NSLog(@\"Activation Error: %@\", [error localizedDescription]);\n    }\n```\n\n### 二、settings参数\n创建AVAudioRecorder的方法中，settings是最重要的参数，有着众多的配置参数：\n```\n- (nullable instancetype)initWithURL:(NSURL *)url settings:(NSDictionary<NSString *, id> *)settings error:(NSError **)outError;\n```\nsettings中的key可以在***AVFoundation->framework文件夹->AVAudio->AVAudioSettings.h***中找到。\n\nsettings常见的key值：\n* **AVFormatIDKey**：定义了写入内容的音频格式，值类型存在于 AudioFormatID枚举中，由相应四字节字符组成的32位整形，如：\n![](audio_format.png)\n<font color=ff0000>注意</font>：指定的类型必须与URL定义的文件名对应，比如录制一个test.wav，隐含的意思是录制的音频必须满足Waveform Audio File Format(WAVE)的格式要求，即低字节序（AVLinearPCMIsBigEndianKey 值为NO）、LinerPCM。如果AudioFormatID的值不是 kAudioFormatLinearPCM。NSError的错误信息为：\nThe  operation couldn’t be completed.(OSStatus error 118449215).\n118449215 = ‘fmt?’,即不兼容格式\n* **AVSampleRateKey**:采样率，对输入的模拟音频信号每一秒内的采样数，如8kHz,AM广播的录制效果，不件较小。44.1kHz，CD质量的采样率，文件比较大。尽量使用标准采样率，如8000、16000、22050和44100。\n* **AVNumberOfChannelsKey**:通道数，1：单声道  2：立体声\n* **AVLinearPCMBitDepthKey**:采样精度/位深， 8位或16位，用于lpcm\n* **AVLinearPCMIsBigEndianKey**:是否大端保存数据，用于lpcm\n* **AVLinearPCMIsFloatKey**:采样数据是否为浮点型\n* **AVEncoderBitDepthHintKey**:编码位深，8-32，非lpcm使用\n* **AVEncoderAudioQualityKey**:编码质量，非lpcm使用\n```\ntypedef NS_ENUM(NSInteger, AVAudioQuality) {\n \tAVAudioQualityMin    = 0,\n \tAVAudioQualityLow    = 0x20,\n \tAVAudioQualityMedium = 0x40,\n \tAVAudioQualityHigh   = 0x60,\n \tAVAudioQualityMax    = 0x7F\n};\n```","source":"_posts/AVFoundation学习笔记五-AVAudioRecorder.md","raw":"title: AVFoundation学习笔记五 AVAudioRecorder\nauthor: Cyrus\ntags: []\ncategories:\n  - AVFoundation\ndate: 2018-11-02 15:28:00\n---\n![](recorder.png)\n比较简单的类，主要说一下几个注意的地方：\n### 一、配置AVAudioSession\n```\nAVAudioSession *session = [AVAudioSession sharedInstance];\n    NSError *error;\n    if (![session setCategory:AVAudioSessionCategoryPlayAndRecord error:&error]) {\n        NSLog(@\"Category Error: %@\", [error localizedDescription]);\n    }\n    if (![session setActive:YES error:&error]) {\n        NSLog(@\"Activation Error: %@\", [error localizedDescription]);\n    }\n```\n\n### 二、settings参数\n创建AVAudioRecorder的方法中，settings是最重要的参数，有着众多的配置参数：\n```\n- (nullable instancetype)initWithURL:(NSURL *)url settings:(NSDictionary<NSString *, id> *)settings error:(NSError **)outError;\n```\nsettings中的key可以在***AVFoundation->framework文件夹->AVAudio->AVAudioSettings.h***中找到。\n\nsettings常见的key值：\n* **AVFormatIDKey**：定义了写入内容的音频格式，值类型存在于 AudioFormatID枚举中，由相应四字节字符组成的32位整形，如：\n![](audio_format.png)\n<font color=ff0000>注意</font>：指定的类型必须与URL定义的文件名对应，比如录制一个test.wav，隐含的意思是录制的音频必须满足Waveform Audio File Format(WAVE)的格式要求，即低字节序（AVLinearPCMIsBigEndianKey 值为NO）、LinerPCM。如果AudioFormatID的值不是 kAudioFormatLinearPCM。NSError的错误信息为：\nThe  operation couldn’t be completed.(OSStatus error 118449215).\n118449215 = ‘fmt?’,即不兼容格式\n* **AVSampleRateKey**:采样率，对输入的模拟音频信号每一秒内的采样数，如8kHz,AM广播的录制效果，不件较小。44.1kHz，CD质量的采样率，文件比较大。尽量使用标准采样率，如8000、16000、22050和44100。\n* **AVNumberOfChannelsKey**:通道数，1：单声道  2：立体声\n* **AVLinearPCMBitDepthKey**:采样精度/位深， 8位或16位，用于lpcm\n* **AVLinearPCMIsBigEndianKey**:是否大端保存数据，用于lpcm\n* **AVLinearPCMIsFloatKey**:采样数据是否为浮点型\n* **AVEncoderBitDepthHintKey**:编码位深，8-32，非lpcm使用\n* **AVEncoderAudioQualityKey**:编码质量，非lpcm使用\n```\ntypedef NS_ENUM(NSInteger, AVAudioQuality) {\n \tAVAudioQualityMin    = 0,\n \tAVAudioQualityLow    = 0x20,\n \tAVAudioQualityMedium = 0x40,\n \tAVAudioQualityHigh   = 0x60,\n \tAVAudioQualityMax    = 0x7F\n};\n```","slug":"AVFoundation学习笔记五-AVAudioRecorder","published":1,"updated":"2018-11-08T13:41:19.808Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjo8raw1g000bdrd3q0ww146v","content":"<p><img src=\"//www.cyrus.fun/2018/11/02/AVFoundation学习笔记五-AVAudioRecorder/recorder.png\" alt=\"\"><br>比较简单的类，主要说一下几个注意的地方：</p>\n<h3 id=\"一、配置AVAudioSession\"><a href=\"#一、配置AVAudioSession\" class=\"headerlink\" title=\"一、配置AVAudioSession\"></a>一、配置AVAudioSession</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">AVAudioSession *session = [AVAudioSession sharedInstance];</span><br><span class=\"line\">    NSError *error;</span><br><span class=\"line\">    if (![session setCategory:AVAudioSessionCategoryPlayAndRecord error:&amp;error]) &#123;</span><br><span class=\"line\">        NSLog(@&quot;Category Error: %@&quot;, [error localizedDescription]);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    if (![session setActive:YES error:&amp;error]) &#123;</span><br><span class=\"line\">        NSLog(@&quot;Activation Error: %@&quot;, [error localizedDescription]);</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"二、settings参数\"><a href=\"#二、settings参数\" class=\"headerlink\" title=\"二、settings参数\"></a>二、settings参数</h3><p>创建AVAudioRecorder的方法中，settings是最重要的参数，有着众多的配置参数：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">- (nullable instancetype)initWithURL:(NSURL *)url settings:(NSDictionary&lt;NSString *, id&gt; *)settings error:(NSError **)outError;</span><br></pre></td></tr></table></figure></p>\n<p>settings中的key可以在<strong><em>AVFoundation-&gt;framework文件夹-&gt;AVAudio-&gt;AVAudioSettings.h</em></strong>中找到。</p>\n<p>settings常见的key值：</p>\n<ul>\n<li><strong>AVFormatIDKey</strong>：定义了写入内容的音频格式，值类型存在于 AudioFormatID枚举中，由相应四字节字符组成的32位整形，如：<br><img src=\"//www.cyrus.fun/2018/11/02/AVFoundation学习笔记五-AVAudioRecorder/audio_format.png\" alt=\"\"><br><font color=\"ff0000\">注意</font>：指定的类型必须与URL定义的文件名对应，比如录制一个test.wav，隐含的意思是录制的音频必须满足Waveform Audio File Format(WAVE)的格式要求，即低字节序（AVLinearPCMIsBigEndianKey 值为NO）、LinerPCM。如果AudioFormatID的值不是 kAudioFormatLinearPCM。NSError的错误信息为：<br>The  operation couldn’t be completed.(OSStatus error 118449215).<br>118449215 = ‘fmt?’,即不兼容格式</li>\n<li><strong>AVSampleRateKey</strong>:采样率，对输入的模拟音频信号每一秒内的采样数，如8kHz,AM广播的录制效果，不件较小。44.1kHz，CD质量的采样率，文件比较大。尽量使用标准采样率，如8000、16000、22050和44100。</li>\n<li><strong>AVNumberOfChannelsKey</strong>:通道数，1：单声道  2：立体声</li>\n<li><strong>AVLinearPCMBitDepthKey</strong>:采样精度/位深， 8位或16位，用于lpcm</li>\n<li><strong>AVLinearPCMIsBigEndianKey</strong>:是否大端保存数据，用于lpcm</li>\n<li><strong>AVLinearPCMIsFloatKey</strong>:采样数据是否为浮点型</li>\n<li><strong>AVEncoderBitDepthHintKey</strong>:编码位深，8-32，非lpcm使用</li>\n<li><strong>AVEncoderAudioQualityKey</strong>:编码质量，非lpcm使用<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">typedef NS_ENUM(NSInteger, AVAudioQuality) &#123;</span><br><span class=\"line\"> \tAVAudioQualityMin    = 0,</span><br><span class=\"line\"> \tAVAudioQualityLow    = 0x20,</span><br><span class=\"line\"> \tAVAudioQualityMedium = 0x40,</span><br><span class=\"line\"> \tAVAudioQualityHigh   = 0x60,</span><br><span class=\"line\"> \tAVAudioQualityMax    = 0x7F</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p><img src=\"//www.cyrus.fun/2018/11/02/AVFoundation学习笔记五-AVAudioRecorder/recorder.png\" alt=\"\"><br>比较简单的类，主要说一下几个注意的地方：</p>\n<h3 id=\"一、配置AVAudioSession\"><a href=\"#一、配置AVAudioSession\" class=\"headerlink\" title=\"一、配置AVAudioSession\"></a>一、配置AVAudioSession</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">AVAudioSession *session = [AVAudioSession sharedInstance];</span><br><span class=\"line\">    NSError *error;</span><br><span class=\"line\">    if (![session setCategory:AVAudioSessionCategoryPlayAndRecord error:&amp;error]) &#123;</span><br><span class=\"line\">        NSLog(@&quot;Category Error: %@&quot;, [error localizedDescription]);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    if (![session setActive:YES error:&amp;error]) &#123;</span><br><span class=\"line\">        NSLog(@&quot;Activation Error: %@&quot;, [error localizedDescription]);</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"二、settings参数\"><a href=\"#二、settings参数\" class=\"headerlink\" title=\"二、settings参数\"></a>二、settings参数</h3><p>创建AVAudioRecorder的方法中，settings是最重要的参数，有着众多的配置参数：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">- (nullable instancetype)initWithURL:(NSURL *)url settings:(NSDictionary&lt;NSString *, id&gt; *)settings error:(NSError **)outError;</span><br></pre></td></tr></table></figure></p>\n<p>settings中的key可以在<strong><em>AVFoundation-&gt;framework文件夹-&gt;AVAudio-&gt;AVAudioSettings.h</em></strong>中找到。</p>\n<p>settings常见的key值：</p>\n<ul>\n<li><strong>AVFormatIDKey</strong>：定义了写入内容的音频格式，值类型存在于 AudioFormatID枚举中，由相应四字节字符组成的32位整形，如：<br><img src=\"//www.cyrus.fun/2018/11/02/AVFoundation学习笔记五-AVAudioRecorder/audio_format.png\" alt=\"\"><br><font color=\"ff0000\">注意</font>：指定的类型必须与URL定义的文件名对应，比如录制一个test.wav，隐含的意思是录制的音频必须满足Waveform Audio File Format(WAVE)的格式要求，即低字节序（AVLinearPCMIsBigEndianKey 值为NO）、LinerPCM。如果AudioFormatID的值不是 kAudioFormatLinearPCM。NSError的错误信息为：<br>The  operation couldn’t be completed.(OSStatus error 118449215).<br>118449215 = ‘fmt?’,即不兼容格式</li>\n<li><strong>AVSampleRateKey</strong>:采样率，对输入的模拟音频信号每一秒内的采样数，如8kHz,AM广播的录制效果，不件较小。44.1kHz，CD质量的采样率，文件比较大。尽量使用标准采样率，如8000、16000、22050和44100。</li>\n<li><strong>AVNumberOfChannelsKey</strong>:通道数，1：单声道  2：立体声</li>\n<li><strong>AVLinearPCMBitDepthKey</strong>:采样精度/位深， 8位或16位，用于lpcm</li>\n<li><strong>AVLinearPCMIsBigEndianKey</strong>:是否大端保存数据，用于lpcm</li>\n<li><strong>AVLinearPCMIsFloatKey</strong>:采样数据是否为浮点型</li>\n<li><strong>AVEncoderBitDepthHintKey</strong>:编码位深，8-32，非lpcm使用</li>\n<li><strong>AVEncoderAudioQualityKey</strong>:编码质量，非lpcm使用<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">typedef NS_ENUM(NSInteger, AVAudioQuality) &#123;</span><br><span class=\"line\"> \tAVAudioQualityMin    = 0,</span><br><span class=\"line\"> \tAVAudioQualityLow    = 0x20,</span><br><span class=\"line\"> \tAVAudioQualityMedium = 0x40,</span><br><span class=\"line\"> \tAVAudioQualityHigh   = 0x60,</span><br><span class=\"line\"> \tAVAudioQualityMax    = 0x7F</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></li>\n</ul>\n"},{"title":"SRS服务器 二 保存及拉取文件数据","author":"Cyrus","date":"2018-10-31T14:35:00.000Z","_content":"在SRS服务器一中讲到了SRS服务器的搭建，现在讲一下SRS服务器保存推流文件的设置。\n\n### 一、SRS服务器保存推流文件的设置\n\n1、找到srs.conf文件配置\n```\ncd srs/trunk/\nvi conf/srs.conf\n```\n\n2、修改如下：\n```\n# main config for srs.\n# @see full.conf for detail config.\n\nlisten              1935;\nmax_connections     1000;\nsrs_log_tank        file;\nsrs_log_file        ./objs/srs.log;\nhttp_api {\n    enabled         on;\n    listen          1985;\n}\nhttp_server {\n    enabled         on;\n    listen          8080;\n    dir             ./objs/nginx/html;\n}\nstats {\n    network         0;\n    disk            sda sdb xvda xvdb;\n}\nvhost __defaultVhost__ {\n    dvr {\t\t//dvr保存数据的配置\n        enabled    on;\n#        dvr_path    ./objs/nginx/html/[app]/[stream].[timestamp].flv;\n        dvr_path    ./objs/nginx/html/[app]-[stream].flv\n        dvr_plan    session;\n        dvr_duration    30;\n        dvr_wait_keyframe    on;\n        time_jitter    full;\n    }\n}\n```\n其中dvr_path就是文件保存地址,保存文件必须为flv格式。在推流过程中，文件会保存为xxx.flv.tmp，停止推流后自动修改为xxx.flv。\nobs推流：\n![](obs_set.png)\nvlc播放：\n![](vlc_play.png)\n推流时：\n![](pushing.png)\n推流后：\n![](pushed.png)\n\n直接播放保存的flv文件(点播)：\n![](play_file.png)\n注：只有存放在***/objs/nginx/html***目录下的***flv格式文件***才能播放。另推流时暂存的xxx.flv.tmp文件也可以用这种方式播放，即<font color=ff0000>播放的文件，只跟文件存放数据的格式有关，跟文件名无关</font>。\n\n\n\n","source":"_posts/SRS服务器-二-保存及拉取数据.md","raw":"title: SRS服务器 二 保存及拉取文件数据\nauthor: Cyrus\ntags:\n  - SRS\ncategories:\n  - rtmp\ndate: 2018-10-31 22:35:00\n---\n在SRS服务器一中讲到了SRS服务器的搭建，现在讲一下SRS服务器保存推流文件的设置。\n\n### 一、SRS服务器保存推流文件的设置\n\n1、找到srs.conf文件配置\n```\ncd srs/trunk/\nvi conf/srs.conf\n```\n\n2、修改如下：\n```\n# main config for srs.\n# @see full.conf for detail config.\n\nlisten              1935;\nmax_connections     1000;\nsrs_log_tank        file;\nsrs_log_file        ./objs/srs.log;\nhttp_api {\n    enabled         on;\n    listen          1985;\n}\nhttp_server {\n    enabled         on;\n    listen          8080;\n    dir             ./objs/nginx/html;\n}\nstats {\n    network         0;\n    disk            sda sdb xvda xvdb;\n}\nvhost __defaultVhost__ {\n    dvr {\t\t//dvr保存数据的配置\n        enabled    on;\n#        dvr_path    ./objs/nginx/html/[app]/[stream].[timestamp].flv;\n        dvr_path    ./objs/nginx/html/[app]-[stream].flv\n        dvr_plan    session;\n        dvr_duration    30;\n        dvr_wait_keyframe    on;\n        time_jitter    full;\n    }\n}\n```\n其中dvr_path就是文件保存地址,保存文件必须为flv格式。在推流过程中，文件会保存为xxx.flv.tmp，停止推流后自动修改为xxx.flv。\nobs推流：\n![](obs_set.png)\nvlc播放：\n![](vlc_play.png)\n推流时：\n![](pushing.png)\n推流后：\n![](pushed.png)\n\n直接播放保存的flv文件(点播)：\n![](play_file.png)\n注：只有存放在***/objs/nginx/html***目录下的***flv格式文件***才能播放。另推流时暂存的xxx.flv.tmp文件也可以用这种方式播放，即<font color=ff0000>播放的文件，只跟文件存放数据的格式有关，跟文件名无关</font>。\n\n\n\n","slug":"SRS服务器-二-保存及拉取数据","published":1,"updated":"2018-11-08T13:41:19.809Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjo8raw1h000cdrd3l6cmdswq","content":"<p>在SRS服务器一中讲到了SRS服务器的搭建，现在讲一下SRS服务器保存推流文件的设置。</p>\n<h3 id=\"一、SRS服务器保存推流文件的设置\"><a href=\"#一、SRS服务器保存推流文件的设置\" class=\"headerlink\" title=\"一、SRS服务器保存推流文件的设置\"></a>一、SRS服务器保存推流文件的设置</h3><p>1、找到srs.conf文件配置<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd srs/trunk/</span><br><span class=\"line\">vi conf/srs.conf</span><br></pre></td></tr></table></figure></p>\n<p>2、修改如下：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># main config for srs.</span><br><span class=\"line\"># @see full.conf for detail config.</span><br><span class=\"line\"></span><br><span class=\"line\">listen              1935;</span><br><span class=\"line\">max_connections     1000;</span><br><span class=\"line\">srs_log_tank        file;</span><br><span class=\"line\">srs_log_file        ./objs/srs.log;</span><br><span class=\"line\">http_api &#123;</span><br><span class=\"line\">    enabled         on;</span><br><span class=\"line\">    listen          1985;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">http_server &#123;</span><br><span class=\"line\">    enabled         on;</span><br><span class=\"line\">    listen          8080;</span><br><span class=\"line\">    dir             ./objs/nginx/html;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">stats &#123;</span><br><span class=\"line\">    network         0;</span><br><span class=\"line\">    disk            sda sdb xvda xvdb;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">vhost __defaultVhost__ &#123;</span><br><span class=\"line\">    dvr &#123;\t\t//dvr保存数据的配置</span><br><span class=\"line\">        enabled    on;</span><br><span class=\"line\">#        dvr_path    ./objs/nginx/html/[app]/[stream].[timestamp].flv;</span><br><span class=\"line\">        dvr_path    ./objs/nginx/html/[app]-[stream].flv</span><br><span class=\"line\">        dvr_plan    session;</span><br><span class=\"line\">        dvr_duration    30;</span><br><span class=\"line\">        dvr_wait_keyframe    on;</span><br><span class=\"line\">        time_jitter    full;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>其中dvr_path就是文件保存地址,保存文件必须为flv格式。在推流过程中，文件会保存为xxx.flv.tmp，停止推流后自动修改为xxx.flv。<br>obs推流：<br><img src=\"//www.cyrus.fun/2018/10/31/SRS服务器-二-保存及拉取数据/obs_set.png\" alt=\"\"><br>vlc播放：<br><img src=\"//www.cyrus.fun/2018/10/31/SRS服务器-二-保存及拉取数据/vlc_play.png\" alt=\"\"><br>推流时：<br><img src=\"//www.cyrus.fun/2018/10/31/SRS服务器-二-保存及拉取数据/pushing.png\" alt=\"\"><br>推流后：<br><img src=\"//www.cyrus.fun/2018/10/31/SRS服务器-二-保存及拉取数据/pushed.png\" alt=\"\"></p>\n<p>直接播放保存的flv文件(点播)：<br><img src=\"//www.cyrus.fun/2018/10/31/SRS服务器-二-保存及拉取数据/play_file.png\" alt=\"\"><br>注：只有存放在<strong><em>/objs/nginx/html</em></strong>目录下的<strong><em>flv格式文件</em></strong>才能播放。另推流时暂存的xxx.flv.tmp文件也可以用这种方式播放，即<font color=\"ff0000\">播放的文件，只跟文件存放数据的格式有关，跟文件名无关</font>。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>在SRS服务器一中讲到了SRS服务器的搭建，现在讲一下SRS服务器保存推流文件的设置。</p>\n<h3 id=\"一、SRS服务器保存推流文件的设置\"><a href=\"#一、SRS服务器保存推流文件的设置\" class=\"headerlink\" title=\"一、SRS服务器保存推流文件的设置\"></a>一、SRS服务器保存推流文件的设置</h3><p>1、找到srs.conf文件配置<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd srs/trunk/</span><br><span class=\"line\">vi conf/srs.conf</span><br></pre></td></tr></table></figure></p>\n<p>2、修改如下：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># main config for srs.</span><br><span class=\"line\"># @see full.conf for detail config.</span><br><span class=\"line\"></span><br><span class=\"line\">listen              1935;</span><br><span class=\"line\">max_connections     1000;</span><br><span class=\"line\">srs_log_tank        file;</span><br><span class=\"line\">srs_log_file        ./objs/srs.log;</span><br><span class=\"line\">http_api &#123;</span><br><span class=\"line\">    enabled         on;</span><br><span class=\"line\">    listen          1985;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">http_server &#123;</span><br><span class=\"line\">    enabled         on;</span><br><span class=\"line\">    listen          8080;</span><br><span class=\"line\">    dir             ./objs/nginx/html;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">stats &#123;</span><br><span class=\"line\">    network         0;</span><br><span class=\"line\">    disk            sda sdb xvda xvdb;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">vhost __defaultVhost__ &#123;</span><br><span class=\"line\">    dvr &#123;\t\t//dvr保存数据的配置</span><br><span class=\"line\">        enabled    on;</span><br><span class=\"line\">#        dvr_path    ./objs/nginx/html/[app]/[stream].[timestamp].flv;</span><br><span class=\"line\">        dvr_path    ./objs/nginx/html/[app]-[stream].flv</span><br><span class=\"line\">        dvr_plan    session;</span><br><span class=\"line\">        dvr_duration    30;</span><br><span class=\"line\">        dvr_wait_keyframe    on;</span><br><span class=\"line\">        time_jitter    full;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>其中dvr_path就是文件保存地址,保存文件必须为flv格式。在推流过程中，文件会保存为xxx.flv.tmp，停止推流后自动修改为xxx.flv。<br>obs推流：<br><img src=\"//www.cyrus.fun/2018/10/31/SRS服务器-二-保存及拉取数据/obs_set.png\" alt=\"\"><br>vlc播放：<br><img src=\"//www.cyrus.fun/2018/10/31/SRS服务器-二-保存及拉取数据/vlc_play.png\" alt=\"\"><br>推流时：<br><img src=\"//www.cyrus.fun/2018/10/31/SRS服务器-二-保存及拉取数据/pushing.png\" alt=\"\"><br>推流后：<br><img src=\"//www.cyrus.fun/2018/10/31/SRS服务器-二-保存及拉取数据/pushed.png\" alt=\"\"></p>\n<p>直接播放保存的flv文件(点播)：<br><img src=\"//www.cyrus.fun/2018/10/31/SRS服务器-二-保存及拉取数据/play_file.png\" alt=\"\"><br>注：只有存放在<strong><em>/objs/nginx/html</em></strong>目录下的<strong><em>flv格式文件</em></strong>才能播放。另推流时暂存的xxx.flv.tmp文件也可以用这种方式播放，即<font color=\"ff0000\">播放的文件，只跟文件存放数据的格式有关，跟文件名无关</font>。</p>\n"},{"title":"SRS服务器一 搭建","author":"Cyrus","date":"2018-10-23T15:33:00.000Z","_content":"### 一、什么是srs服务器\n\n按照项目github上的说法：SRS定位是运营级的互联网直播服务器集群，追求更好的概念完整性和最简单实现的代码。也就是说srs服务器是一个功能强大，容易实现的直播服务器。\n\n除了srs，直播服务器还有下面这些选择：\n\nFMS — Adobe公司出品的服务器，价格昂贵，当然是最正宗的，因为RTMP就是Adobe公司的私有协议；\n\nWowza — 需要授权费，效率和稳定性都还不错；\n\nRed5 — 一个开源实现， 效率和稳定性都稍微差些，由于它是Java实现的，所以天生支持跨平台运行；\n\nNignx-rtmp-module – -nginx的一个第三方模块，如果你熟悉nginx那是不错的选择，当然它也是免费的，不过功能就没有其他几个丰富了\n\n### 二、srs服务器的搭建（Ubuntu或Centos）\n\n#### 1、下载\n```\ngit clone https://github.com/ossrs/srs\n```\n#### 2、编译\n```\ncd srs/trunk\n./configure && make\n```\n服务器配置相对好点的，可以尝试 make -jn(n为线程数)加快编辑速度\n\n#### 3、编辑conf/rtmp.conf文件，配置内容：\n```\nlisten              1935;\npid                 ./objs/srs.pid;\nchunk_size          60000;\nff_log_dir          ./objs;\nsrs_log_tank        file;  \n#配置日志答应到文件，需要和srs_log_level配合使用\nsrs_log_level       trace;\n#制定配置文件的级别，默认级别是trace\nsrs_log_file        ./objs/srs.log;  \n#制定日志文件的位置。\nmax_connections     1000;\n#最大连接数\ndaemon              on;\n#以daemon的方式启动，如果要启动在console，那么需要配置daemon off;并且，需要配置srs_log_tank console;\nutc_time            off;\n#是否使用utc时间。如果该值为off则使用本地时间，如果开始使用utc时间。\nvhost __defaultVhost__ {   \n#默认的vhost，在没有指明vhost的情况，默认使用这个vhost。\n}\n```\n\n#### 4、启动服务\n在trunk目录下\n```\n ./objs/srs -c conf/srs.conf\n```\n*其他操作相关指令\n```\n停止 ./etc/init.d/srs stop\n重启 ./etc/init.d/srs restart\n```\n\n#### 5、其他注意事项\n*如果是阿里云服务器，需要设置端口映射。\n安全规则->添加安全规则\n![](SRS服务器搭建/rtmp映射.png)\n\n### 三、rtmp推流与播放\n\n#### 1、使用obs推流\nobs是一款免费且开源的用于视频录制以及直播串流的软件。在Windows, Mac以及Linux下均有客户端。obs设置如下:\n![](SRS服务器搭建/obs.png)\n\n#### 2、使用vlc播放\nVLC 是一款自由、开源的跨平台多媒体播放器及框架，可播放大多数多媒体文件，以及 DVD、音频 CD、VCD 及各类流媒体协议。vcl播放链接是obs的URL/流密钥，如下图：\n![](SRS服务器搭建/vlc.png)\n\n#### 3、最终效果如下图\n![](SRS服务器搭建/result_rtmp.png)","source":"_posts/SRS服务器搭建.md","raw":"title: SRS服务器一 搭建\nauthor: Cyrus\ntags:\n  - SRS\ncategories:\n  - rtmp\ndate: 2018-10-23 23:33:00\n---\n### 一、什么是srs服务器\n\n按照项目github上的说法：SRS定位是运营级的互联网直播服务器集群，追求更好的概念完整性和最简单实现的代码。也就是说srs服务器是一个功能强大，容易实现的直播服务器。\n\n除了srs，直播服务器还有下面这些选择：\n\nFMS — Adobe公司出品的服务器，价格昂贵，当然是最正宗的，因为RTMP就是Adobe公司的私有协议；\n\nWowza — 需要授权费，效率和稳定性都还不错；\n\nRed5 — 一个开源实现， 效率和稳定性都稍微差些，由于它是Java实现的，所以天生支持跨平台运行；\n\nNignx-rtmp-module – -nginx的一个第三方模块，如果你熟悉nginx那是不错的选择，当然它也是免费的，不过功能就没有其他几个丰富了\n\n### 二、srs服务器的搭建（Ubuntu或Centos）\n\n#### 1、下载\n```\ngit clone https://github.com/ossrs/srs\n```\n#### 2、编译\n```\ncd srs/trunk\n./configure && make\n```\n服务器配置相对好点的，可以尝试 make -jn(n为线程数)加快编辑速度\n\n#### 3、编辑conf/rtmp.conf文件，配置内容：\n```\nlisten              1935;\npid                 ./objs/srs.pid;\nchunk_size          60000;\nff_log_dir          ./objs;\nsrs_log_tank        file;  \n#配置日志答应到文件，需要和srs_log_level配合使用\nsrs_log_level       trace;\n#制定配置文件的级别，默认级别是trace\nsrs_log_file        ./objs/srs.log;  \n#制定日志文件的位置。\nmax_connections     1000;\n#最大连接数\ndaemon              on;\n#以daemon的方式启动，如果要启动在console，那么需要配置daemon off;并且，需要配置srs_log_tank console;\nutc_time            off;\n#是否使用utc时间。如果该值为off则使用本地时间，如果开始使用utc时间。\nvhost __defaultVhost__ {   \n#默认的vhost，在没有指明vhost的情况，默认使用这个vhost。\n}\n```\n\n#### 4、启动服务\n在trunk目录下\n```\n ./objs/srs -c conf/srs.conf\n```\n*其他操作相关指令\n```\n停止 ./etc/init.d/srs stop\n重启 ./etc/init.d/srs restart\n```\n\n#### 5、其他注意事项\n*如果是阿里云服务器，需要设置端口映射。\n安全规则->添加安全规则\n![](SRS服务器搭建/rtmp映射.png)\n\n### 三、rtmp推流与播放\n\n#### 1、使用obs推流\nobs是一款免费且开源的用于视频录制以及直播串流的软件。在Windows, Mac以及Linux下均有客户端。obs设置如下:\n![](SRS服务器搭建/obs.png)\n\n#### 2、使用vlc播放\nVLC 是一款自由、开源的跨平台多媒体播放器及框架，可播放大多数多媒体文件，以及 DVD、音频 CD、VCD 及各类流媒体协议。vcl播放链接是obs的URL/流密钥，如下图：\n![](SRS服务器搭建/vlc.png)\n\n#### 3、最终效果如下图\n![](SRS服务器搭建/result_rtmp.png)","slug":"SRS服务器搭建","published":1,"updated":"2018-11-08T13:41:19.814Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjo8raw1i000fdrd3jy9vijs7","content":"<h3 id=\"一、什么是srs服务器\"><a href=\"#一、什么是srs服务器\" class=\"headerlink\" title=\"一、什么是srs服务器\"></a>一、什么是srs服务器</h3><p>按照项目github上的说法：SRS定位是运营级的互联网直播服务器集群，追求更好的概念完整性和最简单实现的代码。也就是说srs服务器是一个功能强大，容易实现的直播服务器。</p>\n<p>除了srs，直播服务器还有下面这些选择：</p>\n<p>FMS — Adobe公司出品的服务器，价格昂贵，当然是最正宗的，因为RTMP就是Adobe公司的私有协议；</p>\n<p>Wowza — 需要授权费，效率和稳定性都还不错；</p>\n<p>Red5 — 一个开源实现， 效率和稳定性都稍微差些，由于它是Java实现的，所以天生支持跨平台运行；</p>\n<p>Nignx-rtmp-module – -nginx的一个第三方模块，如果你熟悉nginx那是不错的选择，当然它也是免费的，不过功能就没有其他几个丰富了</p>\n<h3 id=\"二、srs服务器的搭建（Ubuntu或Centos）\"><a href=\"#二、srs服务器的搭建（Ubuntu或Centos）\" class=\"headerlink\" title=\"二、srs服务器的搭建（Ubuntu或Centos）\"></a>二、srs服务器的搭建（Ubuntu或Centos）</h3><h4 id=\"1、下载\"><a href=\"#1、下载\" class=\"headerlink\" title=\"1、下载\"></a>1、下载</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git clone https://github.com/ossrs/srs</span><br></pre></td></tr></table></figure>\n<h4 id=\"2、编译\"><a href=\"#2、编译\" class=\"headerlink\" title=\"2、编译\"></a>2、编译</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd srs/trunk</span><br><span class=\"line\">./configure &amp;&amp; make</span><br></pre></td></tr></table></figure>\n<p>服务器配置相对好点的，可以尝试 make -jn(n为线程数)加快编辑速度</p>\n<h4 id=\"3、编辑conf-rtmp-conf文件，配置内容：\"><a href=\"#3、编辑conf-rtmp-conf文件，配置内容：\" class=\"headerlink\" title=\"3、编辑conf/rtmp.conf文件，配置内容：\"></a>3、编辑conf/rtmp.conf文件，配置内容：</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">listen              1935;</span><br><span class=\"line\">pid                 ./objs/srs.pid;</span><br><span class=\"line\">chunk_size          60000;</span><br><span class=\"line\">ff_log_dir          ./objs;</span><br><span class=\"line\">srs_log_tank        file;  </span><br><span class=\"line\">#配置日志答应到文件，需要和srs_log_level配合使用</span><br><span class=\"line\">srs_log_level       trace;</span><br><span class=\"line\">#制定配置文件的级别，默认级别是trace</span><br><span class=\"line\">srs_log_file        ./objs/srs.log;  </span><br><span class=\"line\">#制定日志文件的位置。</span><br><span class=\"line\">max_connections     1000;</span><br><span class=\"line\">#最大连接数</span><br><span class=\"line\">daemon              on;</span><br><span class=\"line\">#以daemon的方式启动，如果要启动在console，那么需要配置daemon off;并且，需要配置srs_log_tank console;</span><br><span class=\"line\">utc_time            off;</span><br><span class=\"line\">#是否使用utc时间。如果该值为off则使用本地时间，如果开始使用utc时间。</span><br><span class=\"line\">vhost __defaultVhost__ &#123;   </span><br><span class=\"line\">#默认的vhost，在没有指明vhost的情况，默认使用这个vhost。</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"4、启动服务\"><a href=\"#4、启动服务\" class=\"headerlink\" title=\"4、启动服务\"></a>4、启动服务</h4><p>在trunk目录下<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./objs/srs -c conf/srs.conf</span><br></pre></td></tr></table></figure></p>\n<p>*其他操作相关指令<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">停止 ./etc/init.d/srs stop</span><br><span class=\"line\">重启 ./etc/init.d/srs restart</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"5、其他注意事项\"><a href=\"#5、其他注意事项\" class=\"headerlink\" title=\"5、其他注意事项\"></a>5、其他注意事项</h4><p>*如果是阿里云服务器，需要设置端口映射。<br>安全规则-&gt;添加安全规则<br><img src=\"//www.cyrus.fun/2018/10/23/SRS服务器搭建/rtmp映射.png\" alt=\"\"></p>\n<h3 id=\"三、rtmp推流与播放\"><a href=\"#三、rtmp推流与播放\" class=\"headerlink\" title=\"三、rtmp推流与播放\"></a>三、rtmp推流与播放</h3><h4 id=\"1、使用obs推流\"><a href=\"#1、使用obs推流\" class=\"headerlink\" title=\"1、使用obs推流\"></a>1、使用obs推流</h4><p>obs是一款免费且开源的用于视频录制以及直播串流的软件。在Windows, Mac以及Linux下均有客户端。obs设置如下:<br><img src=\"//www.cyrus.fun/2018/10/23/SRS服务器搭建/obs.png\" alt=\"\"></p>\n<h4 id=\"2、使用vlc播放\"><a href=\"#2、使用vlc播放\" class=\"headerlink\" title=\"2、使用vlc播放\"></a>2、使用vlc播放</h4><p>VLC 是一款自由、开源的跨平台多媒体播放器及框架，可播放大多数多媒体文件，以及 DVD、音频 CD、VCD 及各类流媒体协议。vcl播放链接是obs的URL/流密钥，如下图：<br><img src=\"//www.cyrus.fun/2018/10/23/SRS服务器搭建/vlc.png\" alt=\"\"></p>\n<h4 id=\"3、最终效果如下图\"><a href=\"#3、最终效果如下图\" class=\"headerlink\" title=\"3、最终效果如下图\"></a>3、最终效果如下图</h4><p><img src=\"//www.cyrus.fun/2018/10/23/SRS服务器搭建/result_rtmp.png\" alt=\"\"></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"一、什么是srs服务器\"><a href=\"#一、什么是srs服务器\" class=\"headerlink\" title=\"一、什么是srs服务器\"></a>一、什么是srs服务器</h3><p>按照项目github上的说法：SRS定位是运营级的互联网直播服务器集群，追求更好的概念完整性和最简单实现的代码。也就是说srs服务器是一个功能强大，容易实现的直播服务器。</p>\n<p>除了srs，直播服务器还有下面这些选择：</p>\n<p>FMS — Adobe公司出品的服务器，价格昂贵，当然是最正宗的，因为RTMP就是Adobe公司的私有协议；</p>\n<p>Wowza — 需要授权费，效率和稳定性都还不错；</p>\n<p>Red5 — 一个开源实现， 效率和稳定性都稍微差些，由于它是Java实现的，所以天生支持跨平台运行；</p>\n<p>Nignx-rtmp-module – -nginx的一个第三方模块，如果你熟悉nginx那是不错的选择，当然它也是免费的，不过功能就没有其他几个丰富了</p>\n<h3 id=\"二、srs服务器的搭建（Ubuntu或Centos）\"><a href=\"#二、srs服务器的搭建（Ubuntu或Centos）\" class=\"headerlink\" title=\"二、srs服务器的搭建（Ubuntu或Centos）\"></a>二、srs服务器的搭建（Ubuntu或Centos）</h3><h4 id=\"1、下载\"><a href=\"#1、下载\" class=\"headerlink\" title=\"1、下载\"></a>1、下载</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git clone https://github.com/ossrs/srs</span><br></pre></td></tr></table></figure>\n<h4 id=\"2、编译\"><a href=\"#2、编译\" class=\"headerlink\" title=\"2、编译\"></a>2、编译</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd srs/trunk</span><br><span class=\"line\">./configure &amp;&amp; make</span><br></pre></td></tr></table></figure>\n<p>服务器配置相对好点的，可以尝试 make -jn(n为线程数)加快编辑速度</p>\n<h4 id=\"3、编辑conf-rtmp-conf文件，配置内容：\"><a href=\"#3、编辑conf-rtmp-conf文件，配置内容：\" class=\"headerlink\" title=\"3、编辑conf/rtmp.conf文件，配置内容：\"></a>3、编辑conf/rtmp.conf文件，配置内容：</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">listen              1935;</span><br><span class=\"line\">pid                 ./objs/srs.pid;</span><br><span class=\"line\">chunk_size          60000;</span><br><span class=\"line\">ff_log_dir          ./objs;</span><br><span class=\"line\">srs_log_tank        file;  </span><br><span class=\"line\">#配置日志答应到文件，需要和srs_log_level配合使用</span><br><span class=\"line\">srs_log_level       trace;</span><br><span class=\"line\">#制定配置文件的级别，默认级别是trace</span><br><span class=\"line\">srs_log_file        ./objs/srs.log;  </span><br><span class=\"line\">#制定日志文件的位置。</span><br><span class=\"line\">max_connections     1000;</span><br><span class=\"line\">#最大连接数</span><br><span class=\"line\">daemon              on;</span><br><span class=\"line\">#以daemon的方式启动，如果要启动在console，那么需要配置daemon off;并且，需要配置srs_log_tank console;</span><br><span class=\"line\">utc_time            off;</span><br><span class=\"line\">#是否使用utc时间。如果该值为off则使用本地时间，如果开始使用utc时间。</span><br><span class=\"line\">vhost __defaultVhost__ &#123;   </span><br><span class=\"line\">#默认的vhost，在没有指明vhost的情况，默认使用这个vhost。</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"4、启动服务\"><a href=\"#4、启动服务\" class=\"headerlink\" title=\"4、启动服务\"></a>4、启动服务</h4><p>在trunk目录下<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./objs/srs -c conf/srs.conf</span><br></pre></td></tr></table></figure></p>\n<p>*其他操作相关指令<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">停止 ./etc/init.d/srs stop</span><br><span class=\"line\">重启 ./etc/init.d/srs restart</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"5、其他注意事项\"><a href=\"#5、其他注意事项\" class=\"headerlink\" title=\"5、其他注意事项\"></a>5、其他注意事项</h4><p>*如果是阿里云服务器，需要设置端口映射。<br>安全规则-&gt;添加安全规则<br><img src=\"//www.cyrus.fun/2018/10/23/SRS服务器搭建/rtmp映射.png\" alt=\"\"></p>\n<h3 id=\"三、rtmp推流与播放\"><a href=\"#三、rtmp推流与播放\" class=\"headerlink\" title=\"三、rtmp推流与播放\"></a>三、rtmp推流与播放</h3><h4 id=\"1、使用obs推流\"><a href=\"#1、使用obs推流\" class=\"headerlink\" title=\"1、使用obs推流\"></a>1、使用obs推流</h4><p>obs是一款免费且开源的用于视频录制以及直播串流的软件。在Windows, Mac以及Linux下均有客户端。obs设置如下:<br><img src=\"//www.cyrus.fun/2018/10/23/SRS服务器搭建/obs.png\" alt=\"\"></p>\n<h4 id=\"2、使用vlc播放\"><a href=\"#2、使用vlc播放\" class=\"headerlink\" title=\"2、使用vlc播放\"></a>2、使用vlc播放</h4><p>VLC 是一款自由、开源的跨平台多媒体播放器及框架，可播放大多数多媒体文件，以及 DVD、音频 CD、VCD 及各类流媒体协议。vcl播放链接是obs的URL/流密钥，如下图：<br><img src=\"//www.cyrus.fun/2018/10/23/SRS服务器搭建/vlc.png\" alt=\"\"></p>\n<h4 id=\"3、最终效果如下图\"><a href=\"#3、最终效果如下图\" class=\"headerlink\" title=\"3、最终效果如下图\"></a>3、最终效果如下图</h4><p><img src=\"//www.cyrus.fun/2018/10/23/SRS服务器搭建/result_rtmp.png\" alt=\"\"></p>\n"},{"title":"TCP/IP学习笔记一","author":"Cyrus","date":"2018-10-23T14:55:00.000Z","_content":"\t近期看了挺长一段时间的TCP/IP相关的知识，主要有UNIX网络编程、极客时间上的趣谈网络协议（推荐）和一些相关视频、博客，打算抽空整理一下，主要围绕一个完整的网络请求，从发出到返回数据的过程是怎样的？大致分为以下几个方面：\n    1、TCP/IP协议分为哪几层，各层的作用及相应的协议；\n    2、一个请求怎么找到服务器的；\n    3、三次握手和四次挥手的细节。\n    ","source":"_posts/TCP-IP学习笔记一.md","raw":"title: TCP/IP学习笔记一\nauthor: Cyrus\ntags:\n  - TCP/IP\ncategories:\n  - 网络协议\ndate: 2018-10-23 22:55:00\n---\n\t近期看了挺长一段时间的TCP/IP相关的知识，主要有UNIX网络编程、极客时间上的趣谈网络协议（推荐）和一些相关视频、博客，打算抽空整理一下，主要围绕一个完整的网络请求，从发出到返回数据的过程是怎样的？大致分为以下几个方面：\n    1、TCP/IP协议分为哪几层，各层的作用及相应的协议；\n    2、一个请求怎么找到服务器的；\n    3、三次握手和四次挥手的细节。\n    ","slug":"TCP-IP学习笔记一","published":1,"updated":"2018-11-08T13:41:19.821Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjo8raw1k000idrd3xqpejyw4","content":"<pre><code>近期看了挺长一段时间的TCP/IP相关的知识，主要有UNIX网络编程、极客时间上的趣谈网络协议（推荐）和一些相关视频、博客，打算抽空整理一下，主要围绕一个完整的网络请求，从发出到返回数据的过程是怎样的？大致分为以下几个方面：\n1、TCP/IP协议分为哪几层，各层的作用及相应的协议；\n2、一个请求怎么找到服务器的；\n3、三次握手和四次挥手的细节。\n</code></pre>","site":{"data":{}},"excerpt":"","more":"<pre><code>近期看了挺长一段时间的TCP/IP相关的知识，主要有UNIX网络编程、极客时间上的趣谈网络协议（推荐）和一些相关视频、博客，打算抽空整理一下，主要围绕一个完整的网络请求，从发出到返回数据的过程是怎样的？大致分为以下几个方面：\n1、TCP/IP协议分为哪几层，各层的作用及相应的协议；\n2、一个请求怎么找到服务器的；\n3、三次握手和四次挥手的细节。\n</code></pre>"},{"title":"Xcode编译错误:This application does not support this device's CPU type","author":"Cyrus","date":"2018-10-31T14:24:00.000Z","_content":"最近运行一个旧项目代码，出现错误提示：This application does not support this device's CPU type\n原因：Xcode设置了32-bit architecture，而手机是64-bit的CPU。\n解决方法：修改build Setting->Architectures 为 **architectrues - $(ARCHS_STANDARD)**\n![](buildSetting.png)","source":"_posts/Xcode编译错误-This-application-does-not-support-this-device-s-CPU-type.md","raw":"title: 'Xcode编译错误:This application does not support this device''s CPU type'\nauthor: Cyrus\ntags:\n  - Xcode问题\ncategories:\n  - iOS\ndate: 2018-10-31 22:24:00\n---\n最近运行一个旧项目代码，出现错误提示：This application does not support this device's CPU type\n原因：Xcode设置了32-bit architecture，而手机是64-bit的CPU。\n解决方法：修改build Setting->Architectures 为 **architectrues - $(ARCHS_STANDARD)**\n![](buildSetting.png)","slug":"Xcode编译错误-This-application-does-not-support-this-device-s-CPU-type","published":1,"updated":"2018-11-08T13:41:19.822Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjo8raw1l000ldrd3dyp6uvoa","content":"<p>最近运行一个旧项目代码，出现错误提示：This application does not support this device’s CPU type<br>原因：Xcode设置了32-bit architecture，而手机是64-bit的CPU。<br>解决方法：修改build Setting-&gt;Architectures 为 <strong>architectrues - $(ARCHS_STANDARD)</strong><br><img src=\"//www.cyrus.fun/2018/10/31/Xcode编译错误-This-application-does-not-support-this-device-s-CPU-type/buildSetting.png\" alt=\"\"></p>\n","site":{"data":{}},"excerpt":"","more":"<p>最近运行一个旧项目代码，出现错误提示：This application does not support this device’s CPU type<br>原因：Xcode设置了32-bit architecture，而手机是64-bit的CPU。<br>解决方法：修改build Setting-&gt;Architectures 为 <strong>architectrues - $(ARCHS_STANDARD)</strong><br><img src=\"//www.cyrus.fun/2018/10/31/Xcode编译错误-This-application-does-not-support-this-device-s-CPU-type/buildSetting.png\" alt=\"\"></p>\n"},{"title":"主机+win10+黑苹果+ubuntu","author":"Cyrus","date":"2018-11-08T13:53:00.000Z","_content":"双11还没到，就剁手配了台主机，z390+8700k+1080Ti。折腾了好几天，才把win10、黑苹果、ubuntu都给装上去了。先来个开机图：\n![](主机.png)\n\n### 装机\n机箱是安钛克P110搭配ATX主板，本以为跟之前看到的主机差不多大小，结果到手一看，整整大了好几圈，囧。。。第一次组装，从8多点装到半夜2、3点才装好，装上win10,一次点亮没毛病。这里啥专业几个点：\n1、大霜塔散热真心大，也真心不好装。。。\n2、主板固定后，CPU电源、主板电源线真心难插，建议插上后再固定主板，然后再插到电源上。。。\n3、机箱+CPU散热共6个风扇，一开机呼呼的，有点吵。。。\n\n### 装系统\n一个英特尔P760 500G的m.2，速度快，用来装黑苹果（主用系统）\n一个三星860 evo 500的sata，用来装win10和ubuntu\n一个希捷1T的机械硬盘，用来放视频资料什么的。\n\n#### win10\nwin10的安装没什么好说的，装就对了。装完之后发现上不了网，只能拿出主板附带的光盘，再找出以前笔记本换固态拆下来的古董级光驱（都8102年了，就不能给个U盘？显卡驱动也是），装了驱动，立马显示可以上网了。（因为板载网卡I219V比较新？后面Ubuntu也遇到了装完系统上不了网的情况，汗。。。）再放显卡附带光盘安装，毫无悬念，win10收工。\n\n#### 黑苹果\n黑苹果装的是10.13.6，10.14刚出来，bug多，而且没有显卡驱动。\n如果舍得花点钱，建议20块注册下黑苹果乐园，镜像驱动相关应用找起来容易点。有钱又懒得折腾的，x宝百来块，不到两个钟解决问题。\n生命在于折腾，说说折腾过程中遇到的几个问题：\n\n1、最好用usb2.0的U盘安装，别问我为什么？想着3.0的U盘速度快，结果跑码10s卡死，前前后后下了3、4个镜像，20来个G，呵呵。。。如果只有3.0U盘，插到主板2.0的USB口也可以，貌似。。。\n\n2、关于用MultiBeast安装驱动的问题，我网卡、USB都用这个装的，没问题，但是，声卡建议还是用其他方法，一开始不懂，一直没声音，直接用这个装了万能声卡、alc和Realtek 1220,直接进不了系统，gg…clover安全模式下删掉驱动也没解决，再次重装。\n\n3、识别不了USB3.0。可以参考下 https://hackintosher.com/guides/hackintosh-high-sierra-10-13-6-update-guide/\n\n4、进入win10、ubuntu之类的非OS X系统，关机时，务必先“关机”，不要选“重启”，有些驱动会掉，像万能声卡就掉了。。。\n\n#### Ubuntu16.04\nubuntu安装也没太多说的，win10盘分了200多G出来，照下面分区：\n\n1.大小：500MB；\n   新分区类型：主分区\n   新分区位置：空间起始位置\n   用于：EFI\n   \n2.大小：500MB；\n   新分区类型：主分区\n   新分区位置：空间起始位置\n   用于：Ext4\n   挂载点：/Boot\n   \n3.大小：18000MB；\n   新分区类型：主分区\n   新分区位置：空间起始位置\n   用于：交换空间（swap area）（=物理内存*2,8GB也够用）\n   \n4.大小：***MB；\n   新分区类型：主分区\n   新分区位置：空间起始位置\n   用于：Ext4\n   挂载点：/\n\n问题是安装好后EFI分区似乎没用到。开机，渣画面+没网络，需要网卡驱动和显卡驱动。\n\n网卡驱动：http://www.mamicode.com/info-detail-1710888.html\n\n显卡驱动：https://blog.csdn.net/weixin_40294256/article/details/79157838\n\n### 结论\n花了几天时间，自己组了台电脑，装了三个系统并成功运行，还是挺有成就感的。\n\n1、黑苹果声卡驱动为万能声卡，美中不足，但是平时也就戴耳机看看教学视频之类的，感觉还行，不强求了，以后有兴致了再研究研究重新整；\n\n2、ubuntu的引导没有添加到clover里面，需要切换开机启动项，比较麻烦，后面有时间再看；\n\n3、装了三个系统，隔了很多分区，有点乱。。。","source":"_posts/主机-三系统.md","raw":"title: 主机+win10+黑苹果+ubuntu\nauthor: Cyrus\ntags: []\ncategories:\n  - 杂记\ndate: 2018-11-08 21:53:00\n---\n双11还没到，就剁手配了台主机，z390+8700k+1080Ti。折腾了好几天，才把win10、黑苹果、ubuntu都给装上去了。先来个开机图：\n![](主机.png)\n\n### 装机\n机箱是安钛克P110搭配ATX主板，本以为跟之前看到的主机差不多大小，结果到手一看，整整大了好几圈，囧。。。第一次组装，从8多点装到半夜2、3点才装好，装上win10,一次点亮没毛病。这里啥专业几个点：\n1、大霜塔散热真心大，也真心不好装。。。\n2、主板固定后，CPU电源、主板电源线真心难插，建议插上后再固定主板，然后再插到电源上。。。\n3、机箱+CPU散热共6个风扇，一开机呼呼的，有点吵。。。\n\n### 装系统\n一个英特尔P760 500G的m.2，速度快，用来装黑苹果（主用系统）\n一个三星860 evo 500的sata，用来装win10和ubuntu\n一个希捷1T的机械硬盘，用来放视频资料什么的。\n\n#### win10\nwin10的安装没什么好说的，装就对了。装完之后发现上不了网，只能拿出主板附带的光盘，再找出以前笔记本换固态拆下来的古董级光驱（都8102年了，就不能给个U盘？显卡驱动也是），装了驱动，立马显示可以上网了。（因为板载网卡I219V比较新？后面Ubuntu也遇到了装完系统上不了网的情况，汗。。。）再放显卡附带光盘安装，毫无悬念，win10收工。\n\n#### 黑苹果\n黑苹果装的是10.13.6，10.14刚出来，bug多，而且没有显卡驱动。\n如果舍得花点钱，建议20块注册下黑苹果乐园，镜像驱动相关应用找起来容易点。有钱又懒得折腾的，x宝百来块，不到两个钟解决问题。\n生命在于折腾，说说折腾过程中遇到的几个问题：\n\n1、最好用usb2.0的U盘安装，别问我为什么？想着3.0的U盘速度快，结果跑码10s卡死，前前后后下了3、4个镜像，20来个G，呵呵。。。如果只有3.0U盘，插到主板2.0的USB口也可以，貌似。。。\n\n2、关于用MultiBeast安装驱动的问题，我网卡、USB都用这个装的，没问题，但是，声卡建议还是用其他方法，一开始不懂，一直没声音，直接用这个装了万能声卡、alc和Realtek 1220,直接进不了系统，gg…clover安全模式下删掉驱动也没解决，再次重装。\n\n3、识别不了USB3.0。可以参考下 https://hackintosher.com/guides/hackintosh-high-sierra-10-13-6-update-guide/\n\n4、进入win10、ubuntu之类的非OS X系统，关机时，务必先“关机”，不要选“重启”，有些驱动会掉，像万能声卡就掉了。。。\n\n#### Ubuntu16.04\nubuntu安装也没太多说的，win10盘分了200多G出来，照下面分区：\n\n1.大小：500MB；\n   新分区类型：主分区\n   新分区位置：空间起始位置\n   用于：EFI\n   \n2.大小：500MB；\n   新分区类型：主分区\n   新分区位置：空间起始位置\n   用于：Ext4\n   挂载点：/Boot\n   \n3.大小：18000MB；\n   新分区类型：主分区\n   新分区位置：空间起始位置\n   用于：交换空间（swap area）（=物理内存*2,8GB也够用）\n   \n4.大小：***MB；\n   新分区类型：主分区\n   新分区位置：空间起始位置\n   用于：Ext4\n   挂载点：/\n\n问题是安装好后EFI分区似乎没用到。开机，渣画面+没网络，需要网卡驱动和显卡驱动。\n\n网卡驱动：http://www.mamicode.com/info-detail-1710888.html\n\n显卡驱动：https://blog.csdn.net/weixin_40294256/article/details/79157838\n\n### 结论\n花了几天时间，自己组了台电脑，装了三个系统并成功运行，还是挺有成就感的。\n\n1、黑苹果声卡驱动为万能声卡，美中不足，但是平时也就戴耳机看看教学视频之类的，感觉还行，不强求了，以后有兴致了再研究研究重新整；\n\n2、ubuntu的引导没有添加到clover里面，需要切换开机启动项，比较麻烦，后面有时间再看；\n\n3、装了三个系统，隔了很多分区，有点乱。。。","slug":"主机-三系统","published":1,"updated":"2018-11-08T14:07:27.652Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjo8raw1m000ndrd3l9g1bxgt","content":"<p>双11还没到，就剁手配了台主机，z390+8700k+1080Ti。折腾了好几天，才把win10、黑苹果、ubuntu都给装上去了。先来个开机图：<br><img src=\"//www.cyrus.fun/2018/11/08/主机-三系统/主机.png\" alt=\"\"></p>\n<h3 id=\"装机\"><a href=\"#装机\" class=\"headerlink\" title=\"装机\"></a>装机</h3><p>机箱是安钛克P110搭配ATX主板，本以为跟之前看到的主机差不多大小，结果到手一看，整整大了好几圈，囧。。。第一次组装，从8多点装到半夜2、3点才装好，装上win10,一次点亮没毛病。这里啥专业几个点：<br>1、大霜塔散热真心大，也真心不好装。。。<br>2、主板固定后，CPU电源、主板电源线真心难插，建议插上后再固定主板，然后再插到电源上。。。<br>3、机箱+CPU散热共6个风扇，一开机呼呼的，有点吵。。。</p>\n<h3 id=\"装系统\"><a href=\"#装系统\" class=\"headerlink\" title=\"装系统\"></a>装系统</h3><p>一个英特尔P760 500G的m.2，速度快，用来装黑苹果（主用系统）<br>一个三星860 evo 500的sata，用来装win10和ubuntu<br>一个希捷1T的机械硬盘，用来放视频资料什么的。</p>\n<h4 id=\"win10\"><a href=\"#win10\" class=\"headerlink\" title=\"win10\"></a>win10</h4><p>win10的安装没什么好说的，装就对了。装完之后发现上不了网，只能拿出主板附带的光盘，再找出以前笔记本换固态拆下来的古董级光驱（都8102年了，就不能给个U盘？显卡驱动也是），装了驱动，立马显示可以上网了。（因为板载网卡I219V比较新？后面Ubuntu也遇到了装完系统上不了网的情况，汗。。。）再放显卡附带光盘安装，毫无悬念，win10收工。</p>\n<h4 id=\"黑苹果\"><a href=\"#黑苹果\" class=\"headerlink\" title=\"黑苹果\"></a>黑苹果</h4><p>黑苹果装的是10.13.6，10.14刚出来，bug多，而且没有显卡驱动。<br>如果舍得花点钱，建议20块注册下黑苹果乐园，镜像驱动相关应用找起来容易点。有钱又懒得折腾的，x宝百来块，不到两个钟解决问题。<br>生命在于折腾，说说折腾过程中遇到的几个问题：</p>\n<p>1、最好用usb2.0的U盘安装，别问我为什么？想着3.0的U盘速度快，结果跑码10s卡死，前前后后下了3、4个镜像，20来个G，呵呵。。。如果只有3.0U盘，插到主板2.0的USB口也可以，貌似。。。</p>\n<p>2、关于用MultiBeast安装驱动的问题，我网卡、USB都用这个装的，没问题，但是，声卡建议还是用其他方法，一开始不懂，一直没声音，直接用这个装了万能声卡、alc和Realtek 1220,直接进不了系统，gg…clover安全模式下删掉驱动也没解决，再次重装。</p>\n<p>3、识别不了USB3.0。可以参考下 <a href=\"https://hackintosher.com/guides/hackintosh-high-sierra-10-13-6-update-guide/\" target=\"_blank\" rel=\"noopener\">https://hackintosher.com/guides/hackintosh-high-sierra-10-13-6-update-guide/</a></p>\n<p>4、进入win10、ubuntu之类的非OS X系统，关机时，务必先“关机”，不要选“重启”，有些驱动会掉，像万能声卡就掉了。。。</p>\n<h4 id=\"Ubuntu16-04\"><a href=\"#Ubuntu16-04\" class=\"headerlink\" title=\"Ubuntu16.04\"></a>Ubuntu16.04</h4><p>ubuntu安装也没太多说的，win10盘分了200多G出来，照下面分区：</p>\n<p>1.大小：500MB；<br>   新分区类型：主分区<br>   新分区位置：空间起始位置<br>   用于：EFI</p>\n<p>2.大小：500MB；<br>   新分区类型：主分区<br>   新分区位置：空间起始位置<br>   用于：Ext4<br>   挂载点：/Boot</p>\n<p>3.大小：18000MB；<br>   新分区类型：主分区<br>   新分区位置：空间起始位置<br>   用于：交换空间（swap area）（=物理内存*2,8GB也够用）</p>\n<p>4.大小：***MB；<br>   新分区类型：主分区<br>   新分区位置：空间起始位置<br>   用于：Ext4<br>   挂载点：/</p>\n<p>问题是安装好后EFI分区似乎没用到。开机，渣画面+没网络，需要网卡驱动和显卡驱动。</p>\n<p>网卡驱动：<a href=\"http://www.mamicode.com/info-detail-1710888.html\" target=\"_blank\" rel=\"noopener\">http://www.mamicode.com/info-detail-1710888.html</a></p>\n<p>显卡驱动：<a href=\"https://blog.csdn.net/weixin_40294256/article/details/79157838\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/weixin_40294256/article/details/79157838</a></p>\n<h3 id=\"结论\"><a href=\"#结论\" class=\"headerlink\" title=\"结论\"></a>结论</h3><p>花了几天时间，自己组了台电脑，装了三个系统并成功运行，还是挺有成就感的。</p>\n<p>1、黑苹果声卡驱动为万能声卡，美中不足，但是平时也就戴耳机看看教学视频之类的，感觉还行，不强求了，以后有兴致了再研究研究重新整；</p>\n<p>2、ubuntu的引导没有添加到clover里面，需要切换开机启动项，比较麻烦，后面有时间再看；</p>\n<p>3、装了三个系统，隔了很多分区，有点乱。。。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>双11还没到，就剁手配了台主机，z390+8700k+1080Ti。折腾了好几天，才把win10、黑苹果、ubuntu都给装上去了。先来个开机图：<br><img src=\"//www.cyrus.fun/2018/11/08/主机-三系统/主机.png\" alt=\"\"></p>\n<h3 id=\"装机\"><a href=\"#装机\" class=\"headerlink\" title=\"装机\"></a>装机</h3><p>机箱是安钛克P110搭配ATX主板，本以为跟之前看到的主机差不多大小，结果到手一看，整整大了好几圈，囧。。。第一次组装，从8多点装到半夜2、3点才装好，装上win10,一次点亮没毛病。这里啥专业几个点：<br>1、大霜塔散热真心大，也真心不好装。。。<br>2、主板固定后，CPU电源、主板电源线真心难插，建议插上后再固定主板，然后再插到电源上。。。<br>3、机箱+CPU散热共6个风扇，一开机呼呼的，有点吵。。。</p>\n<h3 id=\"装系统\"><a href=\"#装系统\" class=\"headerlink\" title=\"装系统\"></a>装系统</h3><p>一个英特尔P760 500G的m.2，速度快，用来装黑苹果（主用系统）<br>一个三星860 evo 500的sata，用来装win10和ubuntu<br>一个希捷1T的机械硬盘，用来放视频资料什么的。</p>\n<h4 id=\"win10\"><a href=\"#win10\" class=\"headerlink\" title=\"win10\"></a>win10</h4><p>win10的安装没什么好说的，装就对了。装完之后发现上不了网，只能拿出主板附带的光盘，再找出以前笔记本换固态拆下来的古董级光驱（都8102年了，就不能给个U盘？显卡驱动也是），装了驱动，立马显示可以上网了。（因为板载网卡I219V比较新？后面Ubuntu也遇到了装完系统上不了网的情况，汗。。。）再放显卡附带光盘安装，毫无悬念，win10收工。</p>\n<h4 id=\"黑苹果\"><a href=\"#黑苹果\" class=\"headerlink\" title=\"黑苹果\"></a>黑苹果</h4><p>黑苹果装的是10.13.6，10.14刚出来，bug多，而且没有显卡驱动。<br>如果舍得花点钱，建议20块注册下黑苹果乐园，镜像驱动相关应用找起来容易点。有钱又懒得折腾的，x宝百来块，不到两个钟解决问题。<br>生命在于折腾，说说折腾过程中遇到的几个问题：</p>\n<p>1、最好用usb2.0的U盘安装，别问我为什么？想着3.0的U盘速度快，结果跑码10s卡死，前前后后下了3、4个镜像，20来个G，呵呵。。。如果只有3.0U盘，插到主板2.0的USB口也可以，貌似。。。</p>\n<p>2、关于用MultiBeast安装驱动的问题，我网卡、USB都用这个装的，没问题，但是，声卡建议还是用其他方法，一开始不懂，一直没声音，直接用这个装了万能声卡、alc和Realtek 1220,直接进不了系统，gg…clover安全模式下删掉驱动也没解决，再次重装。</p>\n<p>3、识别不了USB3.0。可以参考下 <a href=\"https://hackintosher.com/guides/hackintosh-high-sierra-10-13-6-update-guide/\" target=\"_blank\" rel=\"noopener\">https://hackintosher.com/guides/hackintosh-high-sierra-10-13-6-update-guide/</a></p>\n<p>4、进入win10、ubuntu之类的非OS X系统，关机时，务必先“关机”，不要选“重启”，有些驱动会掉，像万能声卡就掉了。。。</p>\n<h4 id=\"Ubuntu16-04\"><a href=\"#Ubuntu16-04\" class=\"headerlink\" title=\"Ubuntu16.04\"></a>Ubuntu16.04</h4><p>ubuntu安装也没太多说的，win10盘分了200多G出来，照下面分区：</p>\n<p>1.大小：500MB；<br>   新分区类型：主分区<br>   新分区位置：空间起始位置<br>   用于：EFI</p>\n<p>2.大小：500MB；<br>   新分区类型：主分区<br>   新分区位置：空间起始位置<br>   用于：Ext4<br>   挂载点：/Boot</p>\n<p>3.大小：18000MB；<br>   新分区类型：主分区<br>   新分区位置：空间起始位置<br>   用于：交换空间（swap area）（=物理内存*2,8GB也够用）</p>\n<p>4.大小：***MB；<br>   新分区类型：主分区<br>   新分区位置：空间起始位置<br>   用于：Ext4<br>   挂载点：/</p>\n<p>问题是安装好后EFI分区似乎没用到。开机，渣画面+没网络，需要网卡驱动和显卡驱动。</p>\n<p>网卡驱动：<a href=\"http://www.mamicode.com/info-detail-1710888.html\" target=\"_blank\" rel=\"noopener\">http://www.mamicode.com/info-detail-1710888.html</a></p>\n<p>显卡驱动：<a href=\"https://blog.csdn.net/weixin_40294256/article/details/79157838\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/weixin_40294256/article/details/79157838</a></p>\n<h3 id=\"结论\"><a href=\"#结论\" class=\"headerlink\" title=\"结论\"></a>结论</h3><p>花了几天时间，自己组了台电脑，装了三个系统并成功运行，还是挺有成就感的。</p>\n<p>1、黑苹果声卡驱动为万能声卡，美中不足，但是平时也就戴耳机看看教学视频之类的，感觉还行，不强求了，以后有兴致了再研究研究重新整；</p>\n<p>2、ubuntu的引导没有添加到clover里面，需要切换开机启动项，比较麻烦，后面有时间再看；</p>\n<p>3、装了三个系统，隔了很多分区，有点乱。。。</p>\n"},{"title":"冒泡排序","author":"Cyrus","date":"2018-10-23T15:16:00.000Z","_content":"冒泡排序，百度百科是这么介绍的：\n\n冒泡排序（Bubble Sort），是一种计算机科学领域的较简单的排序算法。\n它重复地走访过要排序的元素列，依次比较两个相邻的元素，如果他们的顺序（如从大到小、首字母从A到Z）错误就把他们交换过来。走访元素的工作是重复地进行直到没有相邻元素需要交换，也就是说该元素已经排序完成。\n这个算法的名字由来是因为越大的元素会经由交换慢慢“浮”到数列的顶端（升序或降序排列），就如同碳酸饮料中二氧化碳的气泡最终会上浮到顶端一样，故名“冒泡排序”。\n“冒泡” 这个词总让我感觉有点奇怪，因为根据这个排序方法，最先确定下来的数是数组尾端的数，根据循环由后往前一个一个的确定位置，这不是 <font color=#A52A2A size=4 >“沉底”</font>吗？\n\n——以数组尾端作为水面的吧，好吧，没毛病~~\n\n图示如下：\n![](冒泡.png)\n\nC代码算法：\n```\n#include <stdio.h>\n#define SIZE 8\nvoid bubble_sort(int a[], int n);\nvoid bubble_sort(int a[], int n)\n{\n    int i, j, temp;\n    for (j = 0; j < n - 1; j++)\n        for (i = 0; i < n - 1 - j; i++)\n        {\n            if(a[i] > a[i + 1])\n            {\n                temp = a[i];\n                a[i] = a[i + 1];\n                a[i + 1] = temp;\n            }\n        }\n}\nint main()\n{\n    int number[SIZE] = {95, 45, 15, 78, 84, 51, 24, 12};\n    int i;\n    bubble_sort(number, SIZE);\n    for (i = 0; i < SIZE; i++)\n    {\n        printf(\"%d\\n\", number[i]);\n    }\n}\n```\n\n时间复杂度O(N^2)，额外空间复杂度O(1)","source":"_posts/冒泡排序.md","raw":"title: 冒泡排序\nauthor: Cyrus\ntags:\n  - 八大排序\ncategories:\n  - 算法\ndate: 2018-10-23 23:16:00\n---\n冒泡排序，百度百科是这么介绍的：\n\n冒泡排序（Bubble Sort），是一种计算机科学领域的较简单的排序算法。\n它重复地走访过要排序的元素列，依次比较两个相邻的元素，如果他们的顺序（如从大到小、首字母从A到Z）错误就把他们交换过来。走访元素的工作是重复地进行直到没有相邻元素需要交换，也就是说该元素已经排序完成。\n这个算法的名字由来是因为越大的元素会经由交换慢慢“浮”到数列的顶端（升序或降序排列），就如同碳酸饮料中二氧化碳的气泡最终会上浮到顶端一样，故名“冒泡排序”。\n“冒泡” 这个词总让我感觉有点奇怪，因为根据这个排序方法，最先确定下来的数是数组尾端的数，根据循环由后往前一个一个的确定位置，这不是 <font color=#A52A2A size=4 >“沉底”</font>吗？\n\n——以数组尾端作为水面的吧，好吧，没毛病~~\n\n图示如下：\n![](冒泡.png)\n\nC代码算法：\n```\n#include <stdio.h>\n#define SIZE 8\nvoid bubble_sort(int a[], int n);\nvoid bubble_sort(int a[], int n)\n{\n    int i, j, temp;\n    for (j = 0; j < n - 1; j++)\n        for (i = 0; i < n - 1 - j; i++)\n        {\n            if(a[i] > a[i + 1])\n            {\n                temp = a[i];\n                a[i] = a[i + 1];\n                a[i + 1] = temp;\n            }\n        }\n}\nint main()\n{\n    int number[SIZE] = {95, 45, 15, 78, 84, 51, 24, 12};\n    int i;\n    bubble_sort(number, SIZE);\n    for (i = 0; i < SIZE; i++)\n    {\n        printf(\"%d\\n\", number[i]);\n    }\n}\n```\n\n时间复杂度O(N^2)，额外空间复杂度O(1)","slug":"冒泡排序","published":1,"updated":"2018-11-08T13:41:19.822Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjo8raw1o000sdrd393x278pi","content":"<p>冒泡排序，百度百科是这么介绍的：</p>\n<p>冒泡排序（Bubble Sort），是一种计算机科学领域的较简单的排序算法。<br>它重复地走访过要排序的元素列，依次比较两个相邻的元素，如果他们的顺序（如从大到小、首字母从A到Z）错误就把他们交换过来。走访元素的工作是重复地进行直到没有相邻元素需要交换，也就是说该元素已经排序完成。<br>这个算法的名字由来是因为越大的元素会经由交换慢慢“浮”到数列的顶端（升序或降序排列），就如同碳酸饮料中二氧化碳的气泡最终会上浮到顶端一样，故名“冒泡排序”。<br>“冒泡” 这个词总让我感觉有点奇怪，因为根据这个排序方法，最先确定下来的数是数组尾端的数，根据循环由后往前一个一个的确定位置，这不是 <font color=\"#A52A2A\" size=\"4\">“沉底”</font>吗？</p>\n<p>——以数组尾端作为水面的吧，好吧，没毛病~~</p>\n<p>图示如下：<br><img src=\"//www.cyrus.fun/2018/10/23/冒泡排序/冒泡.png\" alt=\"\"></p>\n<p>C代码算法：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;stdio.h&gt;</span><br><span class=\"line\">#define SIZE 8</span><br><span class=\"line\">void bubble_sort(int a[], int n);</span><br><span class=\"line\">void bubble_sort(int a[], int n)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    int i, j, temp;</span><br><span class=\"line\">    for (j = 0; j &lt; n - 1; j++)</span><br><span class=\"line\">        for (i = 0; i &lt; n - 1 - j; i++)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            if(a[i] &gt; a[i + 1])</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                temp = a[i];</span><br><span class=\"line\">                a[i] = a[i + 1];</span><br><span class=\"line\">                a[i + 1] = temp;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">int main()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    int number[SIZE] = &#123;95, 45, 15, 78, 84, 51, 24, 12&#125;;</span><br><span class=\"line\">    int i;</span><br><span class=\"line\">    bubble_sort(number, SIZE);</span><br><span class=\"line\">    for (i = 0; i &lt; SIZE; i++)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        printf(&quot;%d\\n&quot;, number[i]);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>时间复杂度O(N^2)，额外空间复杂度O(1)</p>\n","site":{"data":{}},"excerpt":"","more":"<p>冒泡排序，百度百科是这么介绍的：</p>\n<p>冒泡排序（Bubble Sort），是一种计算机科学领域的较简单的排序算法。<br>它重复地走访过要排序的元素列，依次比较两个相邻的元素，如果他们的顺序（如从大到小、首字母从A到Z）错误就把他们交换过来。走访元素的工作是重复地进行直到没有相邻元素需要交换，也就是说该元素已经排序完成。<br>这个算法的名字由来是因为越大的元素会经由交换慢慢“浮”到数列的顶端（升序或降序排列），就如同碳酸饮料中二氧化碳的气泡最终会上浮到顶端一样，故名“冒泡排序”。<br>“冒泡” 这个词总让我感觉有点奇怪，因为根据这个排序方法，最先确定下来的数是数组尾端的数，根据循环由后往前一个一个的确定位置，这不是 <font color=\"#A52A2A\" size=\"4\">“沉底”</font>吗？</p>\n<p>——以数组尾端作为水面的吧，好吧，没毛病~~</p>\n<p>图示如下：<br><img src=\"//www.cyrus.fun/2018/10/23/冒泡排序/冒泡.png\" alt=\"\"></p>\n<p>C代码算法：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;stdio.h&gt;</span><br><span class=\"line\">#define SIZE 8</span><br><span class=\"line\">void bubble_sort(int a[], int n);</span><br><span class=\"line\">void bubble_sort(int a[], int n)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    int i, j, temp;</span><br><span class=\"line\">    for (j = 0; j &lt; n - 1; j++)</span><br><span class=\"line\">        for (i = 0; i &lt; n - 1 - j; i++)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            if(a[i] &gt; a[i + 1])</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                temp = a[i];</span><br><span class=\"line\">                a[i] = a[i + 1];</span><br><span class=\"line\">                a[i + 1] = temp;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">int main()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    int number[SIZE] = &#123;95, 45, 15, 78, 84, 51, 24, 12&#125;;</span><br><span class=\"line\">    int i;</span><br><span class=\"line\">    bubble_sort(number, SIZE);</span><br><span class=\"line\">    for (i = 0; i &lt; SIZE; i++)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        printf(&quot;%d\\n&quot;, number[i]);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>时间复杂度O(N^2)，额外空间复杂度O(1)</p>\n"},{"title":"AVFoundation学习笔记三  AVAudioSession","author":"Cyrus","date":"2018-10-25T02:49:00.000Z","_content":"注：\n文章部分内容来自：[https://www.jianshu.com/p/3e0a399380df](https://www.jianshu.com/p/3e0a399380df)\n及参考《AVFoundation 开发秘籍》\n\n#### 一、AVAudioSession是用来干嘛的？\n\n简单来说AVAudioSession是用来控制app的音频行为，比如插拔耳机后是否继续播放音频、接电话后返回是否继续播放、是否和其他音频数据混音等。当你遇到:\n\n* 是进行录音还是播放？\n* 当系统静音键按下时该如何表现？\n* 是从扬声器还是从听筒里面播放声音？\n* 插拔耳机后如何表现？\n* 来电话/闹钟响了后如何表现？\n* 其他音频App启动后如何表现？\n* ...\n这些场景的时候，就可以考虑一下“AVAudioSession”了。\n\n#### 二、AVAudioSession是如何控制音频行为的？\nAVFoundation定义了7种分类（category）来描述应用程序所使用的音频行为。\n![](session_category.png)\n\n7种类别各自的行为总结如下：\n* ***AVAudioSessionCategoryAmbient***： 只用于播放音乐时，并且可以和QQ音乐同时播放，比如玩游戏的时候还想听QQ音乐的歌，那么把游戏播放背景音就设置成这种类别。同时，当用户锁屏或者静音时也会随着静音，这种类别基本使用所有App的背景场景。\n* ***AVAudioSessionCategorySoloAmbient(默认)***：也是只用于播放,但是和***\"AVAudioSessionCategoryAmbient\"***不同的是，用了它就别想听QQ音乐了，比如不希望QQ音乐干扰的App，类似节奏大师。同样当用户锁屏或者静音时也会随着静音，锁屏了就玩不了节奏大师了。\n* ***AVAudioSessionCategoryPlayback***：如果锁屏了还想听声音怎么办？用这个类别，比如App本身就是播放器，同时当App播放时，其他类似QQ音乐就不能播放了。所以这种类别一般用于播放器类App\n* ***AVAudioSessionCategoryRecord***：有了播放器，肯定要录音机，比如微信语音的录制，就要用到这个类别，既然要安静的录音，肯定不希望有QQ音乐了，所以其他播放声音会中断。想想微信语音的场景，就知道什么时候用他了。\n* ***AVAudioSessionCategoryPlayAndRecord***：如果既想播放又想录制该用什么模式呢？比如VoIP，打电话这种场景，PlayAndRecord就是专门为这样的场景设计的 。\n* ***AVAudioSessionCategoryMultiRoute***：想象一个DJ用的App，手机连着HDMI到扬声器播放当前的音乐，然后耳机里面播放下一曲，这种常人不理解的场景，这个类别可以支持多个设备输入输出。\n* ***AVAudioSessionCategoryAudioProcessing***: 主要用于音频格式处理，一般可以配合AudioUnit进行使用\n\n#### 三、如何设置AVAudioSession\n\n获取AVAudioSession单例,设置类别并激活。音频会话通常会在应用程序启动时进行一次配置，所以可以将代码写在- (BOOL)application:(UIApplication *)application didFinishLaunchingWithOptions:(NSDictionary *)launchOptions：中。\n```\nAVAudioSession *session = [AVAudioSession sharedInstance];\nNSError *error;\n    if (![session setCategory:AVAudioSessionCategoryPlayback error:&error]) {\n        NSLog(@\"Category Error:%@\", [error localizedDescription]);\n    }\n    if (![session setActive:YES error:&error]) {\n        NSLog(@\"Activation Error:%@\", [error localizedDescription]);\n    }\n```\n\n```\n因为AVAudioSession会影响其他App的表现，当自己App的Session被激活，其他App的就会被解除激活，如何要让自己的Session解除激活后恢复其他App Session的激活状态呢？\n\n此时可以使用：\n\n(BOOL)setActive:(BOOL)active\nwithOptions:(AVAudioSessionSetActiveOptions)options\nerror:(NSError * _Nullable *)outError;\n这里的options传入AVAudioSessionSetActiveOptionNotifyOthersOnDeactivation 即可。\n\n当然，也可以通过otherAudioPlaying变量来提前判断当前是否有其他App在播放音频。\n```\n\n#### 四、如何根据自己需求调整AVAudioSession\nAVAudioSession的设置可以分三个层级\n```\nCategory确定基调---> options微调 + mode微调\n```\n\n##### Category的选项options\n上面介绍的这个七大类别，可以认为是设定了七种主场景，而这七类肯定是不能满足开发者所有的需求的。CoreAudio提供的方法是，首先定下七种的一种基调，然后在进行微调。CoreAudio为每种Category都提供了些许选项来进行微调。\n在设置完类别后，可以通过\n```\n@property(readonly) AVAudioSessionCategoryOptions categoryOptions;\n```\n属性，查看当前类别设置了哪些选项，注意这里的返回值是AVAudioSessionCategoryOptions，实际是多个options的“|”运算。默认情况下是0。\n\n| 选项 | 适用类别 | 作用 |\n| ----- | ----- | ----- |\n| AVAudioSessionCategoryOptionMixWithOthers | AVAudioSessionCategoryPlayAndRecord, AVAudioSessionCategoryPlayback, and AVAudioSessionCategoryMultiRoute | 是否可以和其他后台App进行混音 |\n| AVAudioSessionCategoryOptionDuckOthers | AVAudioSessionCategoryAmbient, AVAudioSessionCategoryPlayAndRecord, AVAudioSessionCategoryPlayback, and AVAudioSessionCategoryMultiRoute | 是否压低其他App声音 |\n| AVAudioSessionCategoryOptionAllowBluetooth | AVAudioSessionCategoryRecord and AVAudioSessionCategoryPlayAndRecord | 是否支持蓝牙耳机 |\n| AVAudioSessionCategoryOptionDefaultToSpeaker | AVAudioSessionCategoryPlayAndRecord | 是否默认用免提声音 |\n\n来看每个选项的基本作用：\n* AVAudioSessionCategoryOptionMixWithOthers ： 如果确实用的AVAudioSessionCategoryPlayback实现的一个背景音，但是呢，又想和QQ音乐并存，那么可以在AVAudioSessionCategoryPlayback类别下在设置这个选项，就可以实现共存了。\n* AVAudioSessionCategoryOptionDuckOthers：在实时通话的场景，比如QQ音乐，当进行视频通话的时候，会发现QQ音乐自动声音降低了，此时就是通过设置这个选项来对其他音乐App进行了压制。\n* AVAudioSessionCategoryOptionAllowBluetooth：如果要支持蓝牙耳机电话，则需要设置这个选项\n* AVAudioSessionCategoryOptionDefaultToSpeaker： 如果在VoIP模式下，希望默认打开免提功能，需要设置这个选项\n\n通过接口：\n```\n- (BOOL)setCategory:(NSString *)category withOptions:(AVAudioSessionCategoryOptions)options error:(NSError **)outError\n```\n来对当前的类别进行选项的设置。\n\n#### 七大模式（Mode）\n\n刚讲完七大类别，现在再来七大模式。通过上面的七大类别，我们基本覆盖了常用的主场景，在每个主场景中可以通过Option进行微调。为此CoreAudio提供了七大比较常见微调后的子场景。叫做各个类别的模式。\n\n| mode | 适用的类别 | 场景 |\n| -- | -- | -- |\n| AVAudioSessionModeDefault | 所有类别 | 默认的模式 |\n| AVAudioSessionModeVoiceChat | AVAudioSessionCategoryPlayAndRecord | VoIP |\n| AVAudioSessionModeGameChat | AVAudioSessionCategoryPlayAndRecord | 游戏录制，由GKVoiceChat自动设置，无需手动调用 |\n| AVAudioSessionModeVideoRecording | AVAudioSessionCategoryPlayAndRecord AVAudioSessionCategoryRecord | 录制视频时 |\n| AVAudioSessionModeMoviePlayback | AVAudioSessionCategoryPlayback | 视频播放 |\n| AVAudioSessionModeMeasurement | AVAudioSessionCategoryPlayAndRecord AVAudioSessionCategoryRecord AVAudioSessionCategoryPlayback | 最小系统 |\n| AVAudioSessionModeVideoChat | AVAudioSessionCategoryPlayAndRecord | 视频通话 |\n\n每个模式有其适用的类别，所以，并不是有“七七 四十九”种组合。如果当前处于的类别下没有这个模式，那么是设置不成功的。设置完Category后可以通过：\n```\n@property(readonly) NSArray<NSString *> *availableModes;\n```\n属性，查看其支持哪些属性，做合法性校验。\n\n来看具体应用：\n\n* AVAudioSessionModeDefault： 每种类别默认的就是这个模式，所有要想还原的话，就设置成这个模式。\n* AVAudioSessionModeVoiceChat：主要用于VoIP场景，此时系统会选择最佳的输入设备，比如插上耳机就使用耳机上的麦克风进行采集。此时有个副作用，他会设置类别的选项为\"AVAudioSessionCategoryOptionAllowBluetooth\"从而支持蓝牙耳机。\n* AVAudioSessionModeVideoChat ： 主要用于视频通话，比如QQ视频、FaceTime。时系统也会选择最佳的输入设备，比如插上耳机就使用耳机上的麦克风进行采集并且会设置类别的选项为\"AVAudioSessionCategoryOptionAllowBluetooth\" 和 \"AVAudioSessionCategoryOptionDefaultToSpeaker\"。\n* AVAudioSessionModeGameChat ： 适用于游戏App的采集和播放，比如“GKVoiceChat”对象，一般不需要手动设置\n另外几种和音频APP关系不大，一般我们只需要关注VoIP或者视频通话即可。\n\n通过调用：\n```\n- (BOOL)setMode:(NSString *)mode error:(NSError **)outError\n```\n可以在设置Category之后再设置模式。\n\n#### 系统中断响应\n<font color=color=#ff0000>AVAudioSessionInterruptionNotification</font>:电话、闹铃响等中断的通知,其回调回来的userInfo主要包含两个键：\n\n* AVAudioSessionInterruptionTypeKey:取值为 <font color=#ff0000> AVAudioSessionInterruptionTypeBegan </font>:表示中断开始，我们应该暂停播放和采集，取值为<font color=color=#ff0000>AVAudioSessionInterruptionTypeEnded</font>表示中断结束，我们可以继续播放和采集。\n* AVAudioSessionInterruptionOptionKey:当前只有一种值<font color=color=#ff0000>AVAudioSessionInterruptionOptionShouldResume</font>:表示此时也应该恢复继续播放和采集。\n\n示例如下：\n\n```\n//注册通知\nNSNotificationCenter *nsnc = [NSNotificationCenter defaultCenter];\n        [nsnc addObserver:self selector:@selector(handleInterruption:) name:AVAudioSessionInterruptionNotification object:[AVAudioSession sharedInstance]];\n        \n//处理回调\n- (void)handleInterruption: (NSNotification *)notification\n{\n    NSDictionary *info = notification.userInfo;\n    AVAudioSessionInterruptionType type = [info[AVAudioSessionInterruptionTypeKey] unsignedIntegerValue];\n    \n    if (type == AVAudioSessionInterruptionTypeBegan) {\n        //Handle AVAudioSessionInterruptionTypeBegan\n    } else {\n       // Handle AVAudioSessionInterruptionTypeEnd\n        AVAudioSessionInterruptionOptions options = [info[AVAudioSessionInterruptionOptionKey] unsignedIntegerValue];\n        if (options == AVAudioSessionInterruptionOptionShouldResume) {\n        \n        }\n    }\n}\n```\n\n<font color=#ff0000>AVAudioSessionSilenceSecondaryAudioHintNotification</font>:其他App占据AudioSession的通知，其回调回来的userInfo键为：\n\n```\nAVAudioSessionSilenceSecondaryAudioHintTypeKey\n```\n\n可能包含的值\n* <font color=color=#ff0000>AVAudioSessionSilenceSecondaryAudioHintTypeBegin</font>:表示其他App开始占据Session\n* <font color=color=#ff0000>AVAudioSessionInterruptionTypeEnded</font>:表示其他App开始释放Session\n\n\n#### 外设改变\n\n默认情况下，AudioSession会在App启动时选择一个最优的输出方案，比如插入耳机的时候，就用耳机。但是这个过程中，用户可能拔出耳机，我们App要如何感知这样的情况呢？\n\n<font color=color=#ff0000>**AVAudioSessionRouteChangeNotification**</font> : 外设改变时通知，在NSNotificationCenter中对其进行注册，userInfo中有键：\n* AVAudioSessionRouteChangeReasonKey ： 表示改变的原因\n\n| 枚举值 | 意义 |\n| ----- | ----- |\n| AVAudioSessionRouteChangeReasonUnknown | 未知原因 |\n| AVAudioSessionRouteChangeReasonNewDeviceAvailable | 有新设备可用 |\n| AVAudioSessionRouteChangeReasonOldDeviceUnavailable | 老设备不可用 |\n| AVAudioSessionRouteChangeReasonCategoryChange | 类别改变了 |\n| AVAudioSessionRouteChangeReasonOverride | App重置了输出设置 |\n| AVAudioSessionRouteChangeReasonWakeFromSleep | 从睡眠状态呼醒 |\n| AVAudioSessionRouteChangeReasonNoSuitableRouteForCategory | 当前Category下没有合适的设备 |\n| AVAudioSessionRouteChangeReasonRouteConfigurationChange | Rotuer的配置改变了 |\n\n示例代码：\n```\nNSNotificationCenter *nsnc = [NSNotificationCenter defaultCenter];\n[nsnc addObserver:self selector:@selector(handleRouteChange:) name:AVAudioSessionRouteChangeNotification object:[AVAudioSession sharedInstance]];\n\n- (void)handleRouteChange:(NSNotification *)notification\n{\n    NSDictionary *info = notification.userInfo;\n    AVAudioSessionRouteChangeReason reason = [info[AVAudioSessionRouteChangeReasonKey] unsignedIntegerValue];\n    if (reason == AVAudioSessionRouteChangeReasonOldDeviceUnavailable) {\n        //如果拔出耳机，停止播放\n        AVAudioSessionRouteDescription *previousRoute = info[AVAudioSessionRouteChangePreviousRouteKey];\n        AVAudioSessionPortDescription *previousOutput = previousRoute.outputs[0];\n        NSString *portType = previousOutput.portType;\n        if ([portType isEqualToString:AVAudioSessionPortHeadphones]) {\n            [self stop];\n        }\n    }\n}\n```","source":"_posts/AVFoundation学习笔记二-AVAudioSession.md","raw":"title: AVFoundation学习笔记三  AVAudioSession\nauthor: Cyrus\ntags: []\ncategories:\n  - AVFoundation\ndate: 2018-10-25 10:49:00\n---\n注：\n文章部分内容来自：[https://www.jianshu.com/p/3e0a399380df](https://www.jianshu.com/p/3e0a399380df)\n及参考《AVFoundation 开发秘籍》\n\n#### 一、AVAudioSession是用来干嘛的？\n\n简单来说AVAudioSession是用来控制app的音频行为，比如插拔耳机后是否继续播放音频、接电话后返回是否继续播放、是否和其他音频数据混音等。当你遇到:\n\n* 是进行录音还是播放？\n* 当系统静音键按下时该如何表现？\n* 是从扬声器还是从听筒里面播放声音？\n* 插拔耳机后如何表现？\n* 来电话/闹钟响了后如何表现？\n* 其他音频App启动后如何表现？\n* ...\n这些场景的时候，就可以考虑一下“AVAudioSession”了。\n\n#### 二、AVAudioSession是如何控制音频行为的？\nAVFoundation定义了7种分类（category）来描述应用程序所使用的音频行为。\n![](session_category.png)\n\n7种类别各自的行为总结如下：\n* ***AVAudioSessionCategoryAmbient***： 只用于播放音乐时，并且可以和QQ音乐同时播放，比如玩游戏的时候还想听QQ音乐的歌，那么把游戏播放背景音就设置成这种类别。同时，当用户锁屏或者静音时也会随着静音，这种类别基本使用所有App的背景场景。\n* ***AVAudioSessionCategorySoloAmbient(默认)***：也是只用于播放,但是和***\"AVAudioSessionCategoryAmbient\"***不同的是，用了它就别想听QQ音乐了，比如不希望QQ音乐干扰的App，类似节奏大师。同样当用户锁屏或者静音时也会随着静音，锁屏了就玩不了节奏大师了。\n* ***AVAudioSessionCategoryPlayback***：如果锁屏了还想听声音怎么办？用这个类别，比如App本身就是播放器，同时当App播放时，其他类似QQ音乐就不能播放了。所以这种类别一般用于播放器类App\n* ***AVAudioSessionCategoryRecord***：有了播放器，肯定要录音机，比如微信语音的录制，就要用到这个类别，既然要安静的录音，肯定不希望有QQ音乐了，所以其他播放声音会中断。想想微信语音的场景，就知道什么时候用他了。\n* ***AVAudioSessionCategoryPlayAndRecord***：如果既想播放又想录制该用什么模式呢？比如VoIP，打电话这种场景，PlayAndRecord就是专门为这样的场景设计的 。\n* ***AVAudioSessionCategoryMultiRoute***：想象一个DJ用的App，手机连着HDMI到扬声器播放当前的音乐，然后耳机里面播放下一曲，这种常人不理解的场景，这个类别可以支持多个设备输入输出。\n* ***AVAudioSessionCategoryAudioProcessing***: 主要用于音频格式处理，一般可以配合AudioUnit进行使用\n\n#### 三、如何设置AVAudioSession\n\n获取AVAudioSession单例,设置类别并激活。音频会话通常会在应用程序启动时进行一次配置，所以可以将代码写在- (BOOL)application:(UIApplication *)application didFinishLaunchingWithOptions:(NSDictionary *)launchOptions：中。\n```\nAVAudioSession *session = [AVAudioSession sharedInstance];\nNSError *error;\n    if (![session setCategory:AVAudioSessionCategoryPlayback error:&error]) {\n        NSLog(@\"Category Error:%@\", [error localizedDescription]);\n    }\n    if (![session setActive:YES error:&error]) {\n        NSLog(@\"Activation Error:%@\", [error localizedDescription]);\n    }\n```\n\n```\n因为AVAudioSession会影响其他App的表现，当自己App的Session被激活，其他App的就会被解除激活，如何要让自己的Session解除激活后恢复其他App Session的激活状态呢？\n\n此时可以使用：\n\n(BOOL)setActive:(BOOL)active\nwithOptions:(AVAudioSessionSetActiveOptions)options\nerror:(NSError * _Nullable *)outError;\n这里的options传入AVAudioSessionSetActiveOptionNotifyOthersOnDeactivation 即可。\n\n当然，也可以通过otherAudioPlaying变量来提前判断当前是否有其他App在播放音频。\n```\n\n#### 四、如何根据自己需求调整AVAudioSession\nAVAudioSession的设置可以分三个层级\n```\nCategory确定基调---> options微调 + mode微调\n```\n\n##### Category的选项options\n上面介绍的这个七大类别，可以认为是设定了七种主场景，而这七类肯定是不能满足开发者所有的需求的。CoreAudio提供的方法是，首先定下七种的一种基调，然后在进行微调。CoreAudio为每种Category都提供了些许选项来进行微调。\n在设置完类别后，可以通过\n```\n@property(readonly) AVAudioSessionCategoryOptions categoryOptions;\n```\n属性，查看当前类别设置了哪些选项，注意这里的返回值是AVAudioSessionCategoryOptions，实际是多个options的“|”运算。默认情况下是0。\n\n| 选项 | 适用类别 | 作用 |\n| ----- | ----- | ----- |\n| AVAudioSessionCategoryOptionMixWithOthers | AVAudioSessionCategoryPlayAndRecord, AVAudioSessionCategoryPlayback, and AVAudioSessionCategoryMultiRoute | 是否可以和其他后台App进行混音 |\n| AVAudioSessionCategoryOptionDuckOthers | AVAudioSessionCategoryAmbient, AVAudioSessionCategoryPlayAndRecord, AVAudioSessionCategoryPlayback, and AVAudioSessionCategoryMultiRoute | 是否压低其他App声音 |\n| AVAudioSessionCategoryOptionAllowBluetooth | AVAudioSessionCategoryRecord and AVAudioSessionCategoryPlayAndRecord | 是否支持蓝牙耳机 |\n| AVAudioSessionCategoryOptionDefaultToSpeaker | AVAudioSessionCategoryPlayAndRecord | 是否默认用免提声音 |\n\n来看每个选项的基本作用：\n* AVAudioSessionCategoryOptionMixWithOthers ： 如果确实用的AVAudioSessionCategoryPlayback实现的一个背景音，但是呢，又想和QQ音乐并存，那么可以在AVAudioSessionCategoryPlayback类别下在设置这个选项，就可以实现共存了。\n* AVAudioSessionCategoryOptionDuckOthers：在实时通话的场景，比如QQ音乐，当进行视频通话的时候，会发现QQ音乐自动声音降低了，此时就是通过设置这个选项来对其他音乐App进行了压制。\n* AVAudioSessionCategoryOptionAllowBluetooth：如果要支持蓝牙耳机电话，则需要设置这个选项\n* AVAudioSessionCategoryOptionDefaultToSpeaker： 如果在VoIP模式下，希望默认打开免提功能，需要设置这个选项\n\n通过接口：\n```\n- (BOOL)setCategory:(NSString *)category withOptions:(AVAudioSessionCategoryOptions)options error:(NSError **)outError\n```\n来对当前的类别进行选项的设置。\n\n#### 七大模式（Mode）\n\n刚讲完七大类别，现在再来七大模式。通过上面的七大类别，我们基本覆盖了常用的主场景，在每个主场景中可以通过Option进行微调。为此CoreAudio提供了七大比较常见微调后的子场景。叫做各个类别的模式。\n\n| mode | 适用的类别 | 场景 |\n| -- | -- | -- |\n| AVAudioSessionModeDefault | 所有类别 | 默认的模式 |\n| AVAudioSessionModeVoiceChat | AVAudioSessionCategoryPlayAndRecord | VoIP |\n| AVAudioSessionModeGameChat | AVAudioSessionCategoryPlayAndRecord | 游戏录制，由GKVoiceChat自动设置，无需手动调用 |\n| AVAudioSessionModeVideoRecording | AVAudioSessionCategoryPlayAndRecord AVAudioSessionCategoryRecord | 录制视频时 |\n| AVAudioSessionModeMoviePlayback | AVAudioSessionCategoryPlayback | 视频播放 |\n| AVAudioSessionModeMeasurement | AVAudioSessionCategoryPlayAndRecord AVAudioSessionCategoryRecord AVAudioSessionCategoryPlayback | 最小系统 |\n| AVAudioSessionModeVideoChat | AVAudioSessionCategoryPlayAndRecord | 视频通话 |\n\n每个模式有其适用的类别，所以，并不是有“七七 四十九”种组合。如果当前处于的类别下没有这个模式，那么是设置不成功的。设置完Category后可以通过：\n```\n@property(readonly) NSArray<NSString *> *availableModes;\n```\n属性，查看其支持哪些属性，做合法性校验。\n\n来看具体应用：\n\n* AVAudioSessionModeDefault： 每种类别默认的就是这个模式，所有要想还原的话，就设置成这个模式。\n* AVAudioSessionModeVoiceChat：主要用于VoIP场景，此时系统会选择最佳的输入设备，比如插上耳机就使用耳机上的麦克风进行采集。此时有个副作用，他会设置类别的选项为\"AVAudioSessionCategoryOptionAllowBluetooth\"从而支持蓝牙耳机。\n* AVAudioSessionModeVideoChat ： 主要用于视频通话，比如QQ视频、FaceTime。时系统也会选择最佳的输入设备，比如插上耳机就使用耳机上的麦克风进行采集并且会设置类别的选项为\"AVAudioSessionCategoryOptionAllowBluetooth\" 和 \"AVAudioSessionCategoryOptionDefaultToSpeaker\"。\n* AVAudioSessionModeGameChat ： 适用于游戏App的采集和播放，比如“GKVoiceChat”对象，一般不需要手动设置\n另外几种和音频APP关系不大，一般我们只需要关注VoIP或者视频通话即可。\n\n通过调用：\n```\n- (BOOL)setMode:(NSString *)mode error:(NSError **)outError\n```\n可以在设置Category之后再设置模式。\n\n#### 系统中断响应\n<font color=color=#ff0000>AVAudioSessionInterruptionNotification</font>:电话、闹铃响等中断的通知,其回调回来的userInfo主要包含两个键：\n\n* AVAudioSessionInterruptionTypeKey:取值为 <font color=#ff0000> AVAudioSessionInterruptionTypeBegan </font>:表示中断开始，我们应该暂停播放和采集，取值为<font color=color=#ff0000>AVAudioSessionInterruptionTypeEnded</font>表示中断结束，我们可以继续播放和采集。\n* AVAudioSessionInterruptionOptionKey:当前只有一种值<font color=color=#ff0000>AVAudioSessionInterruptionOptionShouldResume</font>:表示此时也应该恢复继续播放和采集。\n\n示例如下：\n\n```\n//注册通知\nNSNotificationCenter *nsnc = [NSNotificationCenter defaultCenter];\n        [nsnc addObserver:self selector:@selector(handleInterruption:) name:AVAudioSessionInterruptionNotification object:[AVAudioSession sharedInstance]];\n        \n//处理回调\n- (void)handleInterruption: (NSNotification *)notification\n{\n    NSDictionary *info = notification.userInfo;\n    AVAudioSessionInterruptionType type = [info[AVAudioSessionInterruptionTypeKey] unsignedIntegerValue];\n    \n    if (type == AVAudioSessionInterruptionTypeBegan) {\n        //Handle AVAudioSessionInterruptionTypeBegan\n    } else {\n       // Handle AVAudioSessionInterruptionTypeEnd\n        AVAudioSessionInterruptionOptions options = [info[AVAudioSessionInterruptionOptionKey] unsignedIntegerValue];\n        if (options == AVAudioSessionInterruptionOptionShouldResume) {\n        \n        }\n    }\n}\n```\n\n<font color=#ff0000>AVAudioSessionSilenceSecondaryAudioHintNotification</font>:其他App占据AudioSession的通知，其回调回来的userInfo键为：\n\n```\nAVAudioSessionSilenceSecondaryAudioHintTypeKey\n```\n\n可能包含的值\n* <font color=color=#ff0000>AVAudioSessionSilenceSecondaryAudioHintTypeBegin</font>:表示其他App开始占据Session\n* <font color=color=#ff0000>AVAudioSessionInterruptionTypeEnded</font>:表示其他App开始释放Session\n\n\n#### 外设改变\n\n默认情况下，AudioSession会在App启动时选择一个最优的输出方案，比如插入耳机的时候，就用耳机。但是这个过程中，用户可能拔出耳机，我们App要如何感知这样的情况呢？\n\n<font color=color=#ff0000>**AVAudioSessionRouteChangeNotification**</font> : 外设改变时通知，在NSNotificationCenter中对其进行注册，userInfo中有键：\n* AVAudioSessionRouteChangeReasonKey ： 表示改变的原因\n\n| 枚举值 | 意义 |\n| ----- | ----- |\n| AVAudioSessionRouteChangeReasonUnknown | 未知原因 |\n| AVAudioSessionRouteChangeReasonNewDeviceAvailable | 有新设备可用 |\n| AVAudioSessionRouteChangeReasonOldDeviceUnavailable | 老设备不可用 |\n| AVAudioSessionRouteChangeReasonCategoryChange | 类别改变了 |\n| AVAudioSessionRouteChangeReasonOverride | App重置了输出设置 |\n| AVAudioSessionRouteChangeReasonWakeFromSleep | 从睡眠状态呼醒 |\n| AVAudioSessionRouteChangeReasonNoSuitableRouteForCategory | 当前Category下没有合适的设备 |\n| AVAudioSessionRouteChangeReasonRouteConfigurationChange | Rotuer的配置改变了 |\n\n示例代码：\n```\nNSNotificationCenter *nsnc = [NSNotificationCenter defaultCenter];\n[nsnc addObserver:self selector:@selector(handleRouteChange:) name:AVAudioSessionRouteChangeNotification object:[AVAudioSession sharedInstance]];\n\n- (void)handleRouteChange:(NSNotification *)notification\n{\n    NSDictionary *info = notification.userInfo;\n    AVAudioSessionRouteChangeReason reason = [info[AVAudioSessionRouteChangeReasonKey] unsignedIntegerValue];\n    if (reason == AVAudioSessionRouteChangeReasonOldDeviceUnavailable) {\n        //如果拔出耳机，停止播放\n        AVAudioSessionRouteDescription *previousRoute = info[AVAudioSessionRouteChangePreviousRouteKey];\n        AVAudioSessionPortDescription *previousOutput = previousRoute.outputs[0];\n        NSString *portType = previousOutput.portType;\n        if ([portType isEqualToString:AVAudioSessionPortHeadphones]) {\n            [self stop];\n        }\n    }\n}\n```","slug":"AVFoundation学习笔记二-AVAudioSession","published":1,"updated":"2018-11-08T13:41:19.807Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjo8raw1w001bdrd3n0g31fwy","content":"<p>注：<br>文章部分内容来自：<a href=\"https://www.jianshu.com/p/3e0a399380df\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/3e0a399380df</a><br>及参考《AVFoundation 开发秘籍》</p>\n<h4 id=\"一、AVAudioSession是用来干嘛的？\"><a href=\"#一、AVAudioSession是用来干嘛的？\" class=\"headerlink\" title=\"一、AVAudioSession是用来干嘛的？\"></a>一、AVAudioSession是用来干嘛的？</h4><p>简单来说AVAudioSession是用来控制app的音频行为，比如插拔耳机后是否继续播放音频、接电话后返回是否继续播放、是否和其他音频数据混音等。当你遇到:</p>\n<ul>\n<li>是进行录音还是播放？</li>\n<li>当系统静音键按下时该如何表现？</li>\n<li>是从扬声器还是从听筒里面播放声音？</li>\n<li>插拔耳机后如何表现？</li>\n<li>来电话/闹钟响了后如何表现？</li>\n<li>其他音频App启动后如何表现？</li>\n<li>…<br>这些场景的时候，就可以考虑一下“AVAudioSession”了。</li>\n</ul>\n<h4 id=\"二、AVAudioSession是如何控制音频行为的？\"><a href=\"#二、AVAudioSession是如何控制音频行为的？\" class=\"headerlink\" title=\"二、AVAudioSession是如何控制音频行为的？\"></a>二、AVAudioSession是如何控制音频行为的？</h4><p>AVFoundation定义了7种分类（category）来描述应用程序所使用的音频行为。<br><img src=\"//www.cyrus.fun/2018/10/25/AVFoundation学习笔记二-AVAudioSession/session_category.png\" alt=\"\"></p>\n<p>7种类别各自的行为总结如下：</p>\n<ul>\n<li><strong><em>AVAudioSessionCategoryAmbient</em></strong>： 只用于播放音乐时，并且可以和QQ音乐同时播放，比如玩游戏的时候还想听QQ音乐的歌，那么把游戏播放背景音就设置成这种类别。同时，当用户锁屏或者静音时也会随着静音，这种类别基本使用所有App的背景场景。</li>\n<li><strong><em>AVAudioSessionCategorySoloAmbient(默认)</em></strong>：也是只用于播放,但是和<strong><em>“AVAudioSessionCategoryAmbient”</em></strong>不同的是，用了它就别想听QQ音乐了，比如不希望QQ音乐干扰的App，类似节奏大师。同样当用户锁屏或者静音时也会随着静音，锁屏了就玩不了节奏大师了。</li>\n<li><strong><em>AVAudioSessionCategoryPlayback</em></strong>：如果锁屏了还想听声音怎么办？用这个类别，比如App本身就是播放器，同时当App播放时，其他类似QQ音乐就不能播放了。所以这种类别一般用于播放器类App</li>\n<li><strong><em>AVAudioSessionCategoryRecord</em></strong>：有了播放器，肯定要录音机，比如微信语音的录制，就要用到这个类别，既然要安静的录音，肯定不希望有QQ音乐了，所以其他播放声音会中断。想想微信语音的场景，就知道什么时候用他了。</li>\n<li><strong><em>AVAudioSessionCategoryPlayAndRecord</em></strong>：如果既想播放又想录制该用什么模式呢？比如VoIP，打电话这种场景，PlayAndRecord就是专门为这样的场景设计的 。</li>\n<li><strong><em>AVAudioSessionCategoryMultiRoute</em></strong>：想象一个DJ用的App，手机连着HDMI到扬声器播放当前的音乐，然后耳机里面播放下一曲，这种常人不理解的场景，这个类别可以支持多个设备输入输出。</li>\n<li><strong><em>AVAudioSessionCategoryAudioProcessing</em></strong>: 主要用于音频格式处理，一般可以配合AudioUnit进行使用</li>\n</ul>\n<h4 id=\"三、如何设置AVAudioSession\"><a href=\"#三、如何设置AVAudioSession\" class=\"headerlink\" title=\"三、如何设置AVAudioSession\"></a>三、如何设置AVAudioSession</h4><p>获取AVAudioSession单例,设置类别并激活。音频会话通常会在应用程序启动时进行一次配置，所以可以将代码写在- (BOOL)application:(UIApplication <em>)application didFinishLaunchingWithOptions:(NSDictionary </em>)launchOptions：中。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">AVAudioSession *session = [AVAudioSession sharedInstance];</span><br><span class=\"line\">NSError *error;</span><br><span class=\"line\">    if (![session setCategory:AVAudioSessionCategoryPlayback error:&amp;error]) &#123;</span><br><span class=\"line\">        NSLog(@&quot;Category Error:%@&quot;, [error localizedDescription]);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    if (![session setActive:YES error:&amp;error]) &#123;</span><br><span class=\"line\">        NSLog(@&quot;Activation Error:%@&quot;, [error localizedDescription]);</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">因为AVAudioSession会影响其他App的表现，当自己App的Session被激活，其他App的就会被解除激活，如何要让自己的Session解除激活后恢复其他App Session的激活状态呢？</span><br><span class=\"line\"></span><br><span class=\"line\">此时可以使用：</span><br><span class=\"line\"></span><br><span class=\"line\">(BOOL)setActive:(BOOL)active</span><br><span class=\"line\">withOptions:(AVAudioSessionSetActiveOptions)options</span><br><span class=\"line\">error:(NSError * _Nullable *)outError;</span><br><span class=\"line\">这里的options传入AVAudioSessionSetActiveOptionNotifyOthersOnDeactivation 即可。</span><br><span class=\"line\"></span><br><span class=\"line\">当然，也可以通过otherAudioPlaying变量来提前判断当前是否有其他App在播放音频。</span><br></pre></td></tr></table></figure>\n<h4 id=\"四、如何根据自己需求调整AVAudioSession\"><a href=\"#四、如何根据自己需求调整AVAudioSession\" class=\"headerlink\" title=\"四、如何根据自己需求调整AVAudioSession\"></a>四、如何根据自己需求调整AVAudioSession</h4><p>AVAudioSession的设置可以分三个层级<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Category确定基调---&gt; options微调 + mode微调</span><br></pre></td></tr></table></figure></p>\n<h5 id=\"Category的选项options\"><a href=\"#Category的选项options\" class=\"headerlink\" title=\"Category的选项options\"></a>Category的选项options</h5><p>上面介绍的这个七大类别，可以认为是设定了七种主场景，而这七类肯定是不能满足开发者所有的需求的。CoreAudio提供的方法是，首先定下七种的一种基调，然后在进行微调。CoreAudio为每种Category都提供了些许选项来进行微调。<br>在设置完类别后，可以通过<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">@property(readonly) AVAudioSessionCategoryOptions categoryOptions;</span><br></pre></td></tr></table></figure></p>\n<p>属性，查看当前类别设置了哪些选项，注意这里的返回值是AVAudioSessionCategoryOptions，实际是多个options的“|”运算。默认情况下是0。</p>\n<table>\n<thead>\n<tr>\n<th>选项</th>\n<th>适用类别</th>\n<th>作用</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>AVAudioSessionCategoryOptionMixWithOthers</td>\n<td>AVAudioSessionCategoryPlayAndRecord, AVAudioSessionCategoryPlayback, and AVAudioSessionCategoryMultiRoute</td>\n<td>是否可以和其他后台App进行混音</td>\n</tr>\n<tr>\n<td>AVAudioSessionCategoryOptionDuckOthers</td>\n<td>AVAudioSessionCategoryAmbient, AVAudioSessionCategoryPlayAndRecord, AVAudioSessionCategoryPlayback, and AVAudioSessionCategoryMultiRoute</td>\n<td>是否压低其他App声音</td>\n</tr>\n<tr>\n<td>AVAudioSessionCategoryOptionAllowBluetooth</td>\n<td>AVAudioSessionCategoryRecord and AVAudioSessionCategoryPlayAndRecord</td>\n<td>是否支持蓝牙耳机</td>\n</tr>\n<tr>\n<td>AVAudioSessionCategoryOptionDefaultToSpeaker</td>\n<td>AVAudioSessionCategoryPlayAndRecord</td>\n<td>是否默认用免提声音</td>\n</tr>\n</tbody>\n</table>\n<p>来看每个选项的基本作用：</p>\n<ul>\n<li>AVAudioSessionCategoryOptionMixWithOthers ： 如果确实用的AVAudioSessionCategoryPlayback实现的一个背景音，但是呢，又想和QQ音乐并存，那么可以在AVAudioSessionCategoryPlayback类别下在设置这个选项，就可以实现共存了。</li>\n<li>AVAudioSessionCategoryOptionDuckOthers：在实时通话的场景，比如QQ音乐，当进行视频通话的时候，会发现QQ音乐自动声音降低了，此时就是通过设置这个选项来对其他音乐App进行了压制。</li>\n<li>AVAudioSessionCategoryOptionAllowBluetooth：如果要支持蓝牙耳机电话，则需要设置这个选项</li>\n<li>AVAudioSessionCategoryOptionDefaultToSpeaker： 如果在VoIP模式下，希望默认打开免提功能，需要设置这个选项</li>\n</ul>\n<p>通过接口：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">- (BOOL)setCategory:(NSString *)category withOptions:(AVAudioSessionCategoryOptions)options error:(NSError **)outError</span><br></pre></td></tr></table></figure></p>\n<p>来对当前的类别进行选项的设置。</p>\n<h4 id=\"七大模式（Mode）\"><a href=\"#七大模式（Mode）\" class=\"headerlink\" title=\"七大模式（Mode）\"></a>七大模式（Mode）</h4><p>刚讲完七大类别，现在再来七大模式。通过上面的七大类别，我们基本覆盖了常用的主场景，在每个主场景中可以通过Option进行微调。为此CoreAudio提供了七大比较常见微调后的子场景。叫做各个类别的模式。</p>\n<table>\n<thead>\n<tr>\n<th>mode</th>\n<th>适用的类别</th>\n<th>场景</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>AVAudioSessionModeDefault</td>\n<td>所有类别</td>\n<td>默认的模式</td>\n</tr>\n<tr>\n<td>AVAudioSessionModeVoiceChat</td>\n<td>AVAudioSessionCategoryPlayAndRecord</td>\n<td>VoIP</td>\n</tr>\n<tr>\n<td>AVAudioSessionModeGameChat</td>\n<td>AVAudioSessionCategoryPlayAndRecord</td>\n<td>游戏录制，由GKVoiceChat自动设置，无需手动调用</td>\n</tr>\n<tr>\n<td>AVAudioSessionModeVideoRecording</td>\n<td>AVAudioSessionCategoryPlayAndRecord AVAudioSessionCategoryRecord</td>\n<td>录制视频时</td>\n</tr>\n<tr>\n<td>AVAudioSessionModeMoviePlayback</td>\n<td>AVAudioSessionCategoryPlayback</td>\n<td>视频播放</td>\n</tr>\n<tr>\n<td>AVAudioSessionModeMeasurement</td>\n<td>AVAudioSessionCategoryPlayAndRecord AVAudioSessionCategoryRecord AVAudioSessionCategoryPlayback</td>\n<td>最小系统</td>\n</tr>\n<tr>\n<td>AVAudioSessionModeVideoChat</td>\n<td>AVAudioSessionCategoryPlayAndRecord</td>\n<td>视频通话</td>\n</tr>\n</tbody>\n</table>\n<p>每个模式有其适用的类别，所以，并不是有“七七 四十九”种组合。如果当前处于的类别下没有这个模式，那么是设置不成功的。设置完Category后可以通过：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">@property(readonly) NSArray&lt;NSString *&gt; *availableModes;</span><br></pre></td></tr></table></figure></p>\n<p>属性，查看其支持哪些属性，做合法性校验。</p>\n<p>来看具体应用：</p>\n<ul>\n<li>AVAudioSessionModeDefault： 每种类别默认的就是这个模式，所有要想还原的话，就设置成这个模式。</li>\n<li>AVAudioSessionModeVoiceChat：主要用于VoIP场景，此时系统会选择最佳的输入设备，比如插上耳机就使用耳机上的麦克风进行采集。此时有个副作用，他会设置类别的选项为”AVAudioSessionCategoryOptionAllowBluetooth”从而支持蓝牙耳机。</li>\n<li>AVAudioSessionModeVideoChat ： 主要用于视频通话，比如QQ视频、FaceTime。时系统也会选择最佳的输入设备，比如插上耳机就使用耳机上的麦克风进行采集并且会设置类别的选项为”AVAudioSessionCategoryOptionAllowBluetooth” 和 “AVAudioSessionCategoryOptionDefaultToSpeaker”。</li>\n<li>AVAudioSessionModeGameChat ： 适用于游戏App的采集和播放，比如“GKVoiceChat”对象，一般不需要手动设置<br>另外几种和音频APP关系不大，一般我们只需要关注VoIP或者视频通话即可。</li>\n</ul>\n<p>通过调用：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">- (BOOL)setMode:(NSString *)mode error:(NSError **)outError</span><br></pre></td></tr></table></figure></p>\n<p>可以在设置Category之后再设置模式。</p>\n<h4 id=\"系统中断响应\"><a href=\"#系统中断响应\" class=\"headerlink\" title=\"系统中断响应\"></a>系统中断响应</h4><p><font color=\"color=#ff0000\">AVAudioSessionInterruptionNotification</font>:电话、闹铃响等中断的通知,其回调回来的userInfo主要包含两个键：</p>\n<ul>\n<li>AVAudioSessionInterruptionTypeKey:取值为 <font color=\"#ff0000\"> AVAudioSessionInterruptionTypeBegan </font>:表示中断开始，我们应该暂停播放和采集，取值为<font color=\"color=#ff0000\">AVAudioSessionInterruptionTypeEnded</font>表示中断结束，我们可以继续播放和采集。</li>\n<li>AVAudioSessionInterruptionOptionKey:当前只有一种值<font color=\"color=#ff0000\">AVAudioSessionInterruptionOptionShouldResume</font>:表示此时也应该恢复继续播放和采集。</li>\n</ul>\n<p>示例如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//注册通知</span><br><span class=\"line\">NSNotificationCenter *nsnc = [NSNotificationCenter defaultCenter];</span><br><span class=\"line\">        [nsnc addObserver:self selector:@selector(handleInterruption:) name:AVAudioSessionInterruptionNotification object:[AVAudioSession sharedInstance]];</span><br><span class=\"line\">        </span><br><span class=\"line\">//处理回调</span><br><span class=\"line\">- (void)handleInterruption: (NSNotification *)notification</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    NSDictionary *info = notification.userInfo;</span><br><span class=\"line\">    AVAudioSessionInterruptionType type = [info[AVAudioSessionInterruptionTypeKey] unsignedIntegerValue];</span><br><span class=\"line\">    </span><br><span class=\"line\">    if (type == AVAudioSessionInterruptionTypeBegan) &#123;</span><br><span class=\"line\">        //Handle AVAudioSessionInterruptionTypeBegan</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">       // Handle AVAudioSessionInterruptionTypeEnd</span><br><span class=\"line\">        AVAudioSessionInterruptionOptions options = [info[AVAudioSessionInterruptionOptionKey] unsignedIntegerValue];</span><br><span class=\"line\">        if (options == AVAudioSessionInterruptionOptionShouldResume) &#123;</span><br><span class=\"line\">        </span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><font color=\"#ff0000\">AVAudioSessionSilenceSecondaryAudioHintNotification</font>:其他App占据AudioSession的通知，其回调回来的userInfo键为：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">AVAudioSessionSilenceSecondaryAudioHintTypeKey</span><br></pre></td></tr></table></figure>\n<p>可能包含的值</p>\n<ul>\n<li><font color=\"color=#ff0000\">AVAudioSessionSilenceSecondaryAudioHintTypeBegin</font>:表示其他App开始占据Session</li>\n<li><font color=\"color=#ff0000\">AVAudioSessionInterruptionTypeEnded</font>:表示其他App开始释放Session</li>\n</ul>\n<h4 id=\"外设改变\"><a href=\"#外设改变\" class=\"headerlink\" title=\"外设改变\"></a>外设改变</h4><p>默认情况下，AudioSession会在App启动时选择一个最优的输出方案，比如插入耳机的时候，就用耳机。但是这个过程中，用户可能拔出耳机，我们App要如何感知这样的情况呢？</p>\n<p><font color=\"color=#ff0000\"><strong>AVAudioSessionRouteChangeNotification</strong></font> : 外设改变时通知，在NSNotificationCenter中对其进行注册，userInfo中有键：</p>\n<ul>\n<li>AVAudioSessionRouteChangeReasonKey ： 表示改变的原因</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>枚举值</th>\n<th>意义</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>AVAudioSessionRouteChangeReasonUnknown</td>\n<td>未知原因</td>\n</tr>\n<tr>\n<td>AVAudioSessionRouteChangeReasonNewDeviceAvailable</td>\n<td>有新设备可用</td>\n</tr>\n<tr>\n<td>AVAudioSessionRouteChangeReasonOldDeviceUnavailable</td>\n<td>老设备不可用</td>\n</tr>\n<tr>\n<td>AVAudioSessionRouteChangeReasonCategoryChange</td>\n<td>类别改变了</td>\n</tr>\n<tr>\n<td>AVAudioSessionRouteChangeReasonOverride</td>\n<td>App重置了输出设置</td>\n</tr>\n<tr>\n<td>AVAudioSessionRouteChangeReasonWakeFromSleep</td>\n<td>从睡眠状态呼醒</td>\n</tr>\n<tr>\n<td>AVAudioSessionRouteChangeReasonNoSuitableRouteForCategory</td>\n<td>当前Category下没有合适的设备</td>\n</tr>\n<tr>\n<td>AVAudioSessionRouteChangeReasonRouteConfigurationChange</td>\n<td>Rotuer的配置改变了</td>\n</tr>\n</tbody>\n</table>\n<p>示例代码：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">NSNotificationCenter *nsnc = [NSNotificationCenter defaultCenter];</span><br><span class=\"line\">[nsnc addObserver:self selector:@selector(handleRouteChange:) name:AVAudioSessionRouteChangeNotification object:[AVAudioSession sharedInstance]];</span><br><span class=\"line\"></span><br><span class=\"line\">- (void)handleRouteChange:(NSNotification *)notification</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    NSDictionary *info = notification.userInfo;</span><br><span class=\"line\">    AVAudioSessionRouteChangeReason reason = [info[AVAudioSessionRouteChangeReasonKey] unsignedIntegerValue];</span><br><span class=\"line\">    if (reason == AVAudioSessionRouteChangeReasonOldDeviceUnavailable) &#123;</span><br><span class=\"line\">        //如果拔出耳机，停止播放</span><br><span class=\"line\">        AVAudioSessionRouteDescription *previousRoute = info[AVAudioSessionRouteChangePreviousRouteKey];</span><br><span class=\"line\">        AVAudioSessionPortDescription *previousOutput = previousRoute.outputs[0];</span><br><span class=\"line\">        NSString *portType = previousOutput.portType;</span><br><span class=\"line\">        if ([portType isEqualToString:AVAudioSessionPortHeadphones]) &#123;</span><br><span class=\"line\">            [self stop];</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n","site":{"data":{}},"excerpt":"","more":"<p>注：<br>文章部分内容来自：<a href=\"https://www.jianshu.com/p/3e0a399380df\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/3e0a399380df</a><br>及参考《AVFoundation 开发秘籍》</p>\n<h4 id=\"一、AVAudioSession是用来干嘛的？\"><a href=\"#一、AVAudioSession是用来干嘛的？\" class=\"headerlink\" title=\"一、AVAudioSession是用来干嘛的？\"></a>一、AVAudioSession是用来干嘛的？</h4><p>简单来说AVAudioSession是用来控制app的音频行为，比如插拔耳机后是否继续播放音频、接电话后返回是否继续播放、是否和其他音频数据混音等。当你遇到:</p>\n<ul>\n<li>是进行录音还是播放？</li>\n<li>当系统静音键按下时该如何表现？</li>\n<li>是从扬声器还是从听筒里面播放声音？</li>\n<li>插拔耳机后如何表现？</li>\n<li>来电话/闹钟响了后如何表现？</li>\n<li>其他音频App启动后如何表现？</li>\n<li>…<br>这些场景的时候，就可以考虑一下“AVAudioSession”了。</li>\n</ul>\n<h4 id=\"二、AVAudioSession是如何控制音频行为的？\"><a href=\"#二、AVAudioSession是如何控制音频行为的？\" class=\"headerlink\" title=\"二、AVAudioSession是如何控制音频行为的？\"></a>二、AVAudioSession是如何控制音频行为的？</h4><p>AVFoundation定义了7种分类（category）来描述应用程序所使用的音频行为。<br><img src=\"//www.cyrus.fun/2018/10/25/AVFoundation学习笔记二-AVAudioSession/session_category.png\" alt=\"\"></p>\n<p>7种类别各自的行为总结如下：</p>\n<ul>\n<li><strong><em>AVAudioSessionCategoryAmbient</em></strong>： 只用于播放音乐时，并且可以和QQ音乐同时播放，比如玩游戏的时候还想听QQ音乐的歌，那么把游戏播放背景音就设置成这种类别。同时，当用户锁屏或者静音时也会随着静音，这种类别基本使用所有App的背景场景。</li>\n<li><strong><em>AVAudioSessionCategorySoloAmbient(默认)</em></strong>：也是只用于播放,但是和<strong><em>“AVAudioSessionCategoryAmbient”</em></strong>不同的是，用了它就别想听QQ音乐了，比如不希望QQ音乐干扰的App，类似节奏大师。同样当用户锁屏或者静音时也会随着静音，锁屏了就玩不了节奏大师了。</li>\n<li><strong><em>AVAudioSessionCategoryPlayback</em></strong>：如果锁屏了还想听声音怎么办？用这个类别，比如App本身就是播放器，同时当App播放时，其他类似QQ音乐就不能播放了。所以这种类别一般用于播放器类App</li>\n<li><strong><em>AVAudioSessionCategoryRecord</em></strong>：有了播放器，肯定要录音机，比如微信语音的录制，就要用到这个类别，既然要安静的录音，肯定不希望有QQ音乐了，所以其他播放声音会中断。想想微信语音的场景，就知道什么时候用他了。</li>\n<li><strong><em>AVAudioSessionCategoryPlayAndRecord</em></strong>：如果既想播放又想录制该用什么模式呢？比如VoIP，打电话这种场景，PlayAndRecord就是专门为这样的场景设计的 。</li>\n<li><strong><em>AVAudioSessionCategoryMultiRoute</em></strong>：想象一个DJ用的App，手机连着HDMI到扬声器播放当前的音乐，然后耳机里面播放下一曲，这种常人不理解的场景，这个类别可以支持多个设备输入输出。</li>\n<li><strong><em>AVAudioSessionCategoryAudioProcessing</em></strong>: 主要用于音频格式处理，一般可以配合AudioUnit进行使用</li>\n</ul>\n<h4 id=\"三、如何设置AVAudioSession\"><a href=\"#三、如何设置AVAudioSession\" class=\"headerlink\" title=\"三、如何设置AVAudioSession\"></a>三、如何设置AVAudioSession</h4><p>获取AVAudioSession单例,设置类别并激活。音频会话通常会在应用程序启动时进行一次配置，所以可以将代码写在- (BOOL)application:(UIApplication <em>)application didFinishLaunchingWithOptions:(NSDictionary </em>)launchOptions：中。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">AVAudioSession *session = [AVAudioSession sharedInstance];</span><br><span class=\"line\">NSError *error;</span><br><span class=\"line\">    if (![session setCategory:AVAudioSessionCategoryPlayback error:&amp;error]) &#123;</span><br><span class=\"line\">        NSLog(@&quot;Category Error:%@&quot;, [error localizedDescription]);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    if (![session setActive:YES error:&amp;error]) &#123;</span><br><span class=\"line\">        NSLog(@&quot;Activation Error:%@&quot;, [error localizedDescription]);</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">因为AVAudioSession会影响其他App的表现，当自己App的Session被激活，其他App的就会被解除激活，如何要让自己的Session解除激活后恢复其他App Session的激活状态呢？</span><br><span class=\"line\"></span><br><span class=\"line\">此时可以使用：</span><br><span class=\"line\"></span><br><span class=\"line\">(BOOL)setActive:(BOOL)active</span><br><span class=\"line\">withOptions:(AVAudioSessionSetActiveOptions)options</span><br><span class=\"line\">error:(NSError * _Nullable *)outError;</span><br><span class=\"line\">这里的options传入AVAudioSessionSetActiveOptionNotifyOthersOnDeactivation 即可。</span><br><span class=\"line\"></span><br><span class=\"line\">当然，也可以通过otherAudioPlaying变量来提前判断当前是否有其他App在播放音频。</span><br></pre></td></tr></table></figure>\n<h4 id=\"四、如何根据自己需求调整AVAudioSession\"><a href=\"#四、如何根据自己需求调整AVAudioSession\" class=\"headerlink\" title=\"四、如何根据自己需求调整AVAudioSession\"></a>四、如何根据自己需求调整AVAudioSession</h4><p>AVAudioSession的设置可以分三个层级<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Category确定基调---&gt; options微调 + mode微调</span><br></pre></td></tr></table></figure></p>\n<h5 id=\"Category的选项options\"><a href=\"#Category的选项options\" class=\"headerlink\" title=\"Category的选项options\"></a>Category的选项options</h5><p>上面介绍的这个七大类别，可以认为是设定了七种主场景，而这七类肯定是不能满足开发者所有的需求的。CoreAudio提供的方法是，首先定下七种的一种基调，然后在进行微调。CoreAudio为每种Category都提供了些许选项来进行微调。<br>在设置完类别后，可以通过<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">@property(readonly) AVAudioSessionCategoryOptions categoryOptions;</span><br></pre></td></tr></table></figure></p>\n<p>属性，查看当前类别设置了哪些选项，注意这里的返回值是AVAudioSessionCategoryOptions，实际是多个options的“|”运算。默认情况下是0。</p>\n<table>\n<thead>\n<tr>\n<th>选项</th>\n<th>适用类别</th>\n<th>作用</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>AVAudioSessionCategoryOptionMixWithOthers</td>\n<td>AVAudioSessionCategoryPlayAndRecord, AVAudioSessionCategoryPlayback, and AVAudioSessionCategoryMultiRoute</td>\n<td>是否可以和其他后台App进行混音</td>\n</tr>\n<tr>\n<td>AVAudioSessionCategoryOptionDuckOthers</td>\n<td>AVAudioSessionCategoryAmbient, AVAudioSessionCategoryPlayAndRecord, AVAudioSessionCategoryPlayback, and AVAudioSessionCategoryMultiRoute</td>\n<td>是否压低其他App声音</td>\n</tr>\n<tr>\n<td>AVAudioSessionCategoryOptionAllowBluetooth</td>\n<td>AVAudioSessionCategoryRecord and AVAudioSessionCategoryPlayAndRecord</td>\n<td>是否支持蓝牙耳机</td>\n</tr>\n<tr>\n<td>AVAudioSessionCategoryOptionDefaultToSpeaker</td>\n<td>AVAudioSessionCategoryPlayAndRecord</td>\n<td>是否默认用免提声音</td>\n</tr>\n</tbody>\n</table>\n<p>来看每个选项的基本作用：</p>\n<ul>\n<li>AVAudioSessionCategoryOptionMixWithOthers ： 如果确实用的AVAudioSessionCategoryPlayback实现的一个背景音，但是呢，又想和QQ音乐并存，那么可以在AVAudioSessionCategoryPlayback类别下在设置这个选项，就可以实现共存了。</li>\n<li>AVAudioSessionCategoryOptionDuckOthers：在实时通话的场景，比如QQ音乐，当进行视频通话的时候，会发现QQ音乐自动声音降低了，此时就是通过设置这个选项来对其他音乐App进行了压制。</li>\n<li>AVAudioSessionCategoryOptionAllowBluetooth：如果要支持蓝牙耳机电话，则需要设置这个选项</li>\n<li>AVAudioSessionCategoryOptionDefaultToSpeaker： 如果在VoIP模式下，希望默认打开免提功能，需要设置这个选项</li>\n</ul>\n<p>通过接口：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">- (BOOL)setCategory:(NSString *)category withOptions:(AVAudioSessionCategoryOptions)options error:(NSError **)outError</span><br></pre></td></tr></table></figure></p>\n<p>来对当前的类别进行选项的设置。</p>\n<h4 id=\"七大模式（Mode）\"><a href=\"#七大模式（Mode）\" class=\"headerlink\" title=\"七大模式（Mode）\"></a>七大模式（Mode）</h4><p>刚讲完七大类别，现在再来七大模式。通过上面的七大类别，我们基本覆盖了常用的主场景，在每个主场景中可以通过Option进行微调。为此CoreAudio提供了七大比较常见微调后的子场景。叫做各个类别的模式。</p>\n<table>\n<thead>\n<tr>\n<th>mode</th>\n<th>适用的类别</th>\n<th>场景</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>AVAudioSessionModeDefault</td>\n<td>所有类别</td>\n<td>默认的模式</td>\n</tr>\n<tr>\n<td>AVAudioSessionModeVoiceChat</td>\n<td>AVAudioSessionCategoryPlayAndRecord</td>\n<td>VoIP</td>\n</tr>\n<tr>\n<td>AVAudioSessionModeGameChat</td>\n<td>AVAudioSessionCategoryPlayAndRecord</td>\n<td>游戏录制，由GKVoiceChat自动设置，无需手动调用</td>\n</tr>\n<tr>\n<td>AVAudioSessionModeVideoRecording</td>\n<td>AVAudioSessionCategoryPlayAndRecord AVAudioSessionCategoryRecord</td>\n<td>录制视频时</td>\n</tr>\n<tr>\n<td>AVAudioSessionModeMoviePlayback</td>\n<td>AVAudioSessionCategoryPlayback</td>\n<td>视频播放</td>\n</tr>\n<tr>\n<td>AVAudioSessionModeMeasurement</td>\n<td>AVAudioSessionCategoryPlayAndRecord AVAudioSessionCategoryRecord AVAudioSessionCategoryPlayback</td>\n<td>最小系统</td>\n</tr>\n<tr>\n<td>AVAudioSessionModeVideoChat</td>\n<td>AVAudioSessionCategoryPlayAndRecord</td>\n<td>视频通话</td>\n</tr>\n</tbody>\n</table>\n<p>每个模式有其适用的类别，所以，并不是有“七七 四十九”种组合。如果当前处于的类别下没有这个模式，那么是设置不成功的。设置完Category后可以通过：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">@property(readonly) NSArray&lt;NSString *&gt; *availableModes;</span><br></pre></td></tr></table></figure></p>\n<p>属性，查看其支持哪些属性，做合法性校验。</p>\n<p>来看具体应用：</p>\n<ul>\n<li>AVAudioSessionModeDefault： 每种类别默认的就是这个模式，所有要想还原的话，就设置成这个模式。</li>\n<li>AVAudioSessionModeVoiceChat：主要用于VoIP场景，此时系统会选择最佳的输入设备，比如插上耳机就使用耳机上的麦克风进行采集。此时有个副作用，他会设置类别的选项为”AVAudioSessionCategoryOptionAllowBluetooth”从而支持蓝牙耳机。</li>\n<li>AVAudioSessionModeVideoChat ： 主要用于视频通话，比如QQ视频、FaceTime。时系统也会选择最佳的输入设备，比如插上耳机就使用耳机上的麦克风进行采集并且会设置类别的选项为”AVAudioSessionCategoryOptionAllowBluetooth” 和 “AVAudioSessionCategoryOptionDefaultToSpeaker”。</li>\n<li>AVAudioSessionModeGameChat ： 适用于游戏App的采集和播放，比如“GKVoiceChat”对象，一般不需要手动设置<br>另外几种和音频APP关系不大，一般我们只需要关注VoIP或者视频通话即可。</li>\n</ul>\n<p>通过调用：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">- (BOOL)setMode:(NSString *)mode error:(NSError **)outError</span><br></pre></td></tr></table></figure></p>\n<p>可以在设置Category之后再设置模式。</p>\n<h4 id=\"系统中断响应\"><a href=\"#系统中断响应\" class=\"headerlink\" title=\"系统中断响应\"></a>系统中断响应</h4><p><font color=\"color=#ff0000\">AVAudioSessionInterruptionNotification</font>:电话、闹铃响等中断的通知,其回调回来的userInfo主要包含两个键：</p>\n<ul>\n<li>AVAudioSessionInterruptionTypeKey:取值为 <font color=\"#ff0000\"> AVAudioSessionInterruptionTypeBegan </font>:表示中断开始，我们应该暂停播放和采集，取值为<font color=\"color=#ff0000\">AVAudioSessionInterruptionTypeEnded</font>表示中断结束，我们可以继续播放和采集。</li>\n<li>AVAudioSessionInterruptionOptionKey:当前只有一种值<font color=\"color=#ff0000\">AVAudioSessionInterruptionOptionShouldResume</font>:表示此时也应该恢复继续播放和采集。</li>\n</ul>\n<p>示例如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//注册通知</span><br><span class=\"line\">NSNotificationCenter *nsnc = [NSNotificationCenter defaultCenter];</span><br><span class=\"line\">        [nsnc addObserver:self selector:@selector(handleInterruption:) name:AVAudioSessionInterruptionNotification object:[AVAudioSession sharedInstance]];</span><br><span class=\"line\">        </span><br><span class=\"line\">//处理回调</span><br><span class=\"line\">- (void)handleInterruption: (NSNotification *)notification</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    NSDictionary *info = notification.userInfo;</span><br><span class=\"line\">    AVAudioSessionInterruptionType type = [info[AVAudioSessionInterruptionTypeKey] unsignedIntegerValue];</span><br><span class=\"line\">    </span><br><span class=\"line\">    if (type == AVAudioSessionInterruptionTypeBegan) &#123;</span><br><span class=\"line\">        //Handle AVAudioSessionInterruptionTypeBegan</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">       // Handle AVAudioSessionInterruptionTypeEnd</span><br><span class=\"line\">        AVAudioSessionInterruptionOptions options = [info[AVAudioSessionInterruptionOptionKey] unsignedIntegerValue];</span><br><span class=\"line\">        if (options == AVAudioSessionInterruptionOptionShouldResume) &#123;</span><br><span class=\"line\">        </span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><font color=\"#ff0000\">AVAudioSessionSilenceSecondaryAudioHintNotification</font>:其他App占据AudioSession的通知，其回调回来的userInfo键为：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">AVAudioSessionSilenceSecondaryAudioHintTypeKey</span><br></pre></td></tr></table></figure>\n<p>可能包含的值</p>\n<ul>\n<li><font color=\"color=#ff0000\">AVAudioSessionSilenceSecondaryAudioHintTypeBegin</font>:表示其他App开始占据Session</li>\n<li><font color=\"color=#ff0000\">AVAudioSessionInterruptionTypeEnded</font>:表示其他App开始释放Session</li>\n</ul>\n<h4 id=\"外设改变\"><a href=\"#外设改变\" class=\"headerlink\" title=\"外设改变\"></a>外设改变</h4><p>默认情况下，AudioSession会在App启动时选择一个最优的输出方案，比如插入耳机的时候，就用耳机。但是这个过程中，用户可能拔出耳机，我们App要如何感知这样的情况呢？</p>\n<p><font color=\"color=#ff0000\"><strong>AVAudioSessionRouteChangeNotification</strong></font> : 外设改变时通知，在NSNotificationCenter中对其进行注册，userInfo中有键：</p>\n<ul>\n<li>AVAudioSessionRouteChangeReasonKey ： 表示改变的原因</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>枚举值</th>\n<th>意义</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>AVAudioSessionRouteChangeReasonUnknown</td>\n<td>未知原因</td>\n</tr>\n<tr>\n<td>AVAudioSessionRouteChangeReasonNewDeviceAvailable</td>\n<td>有新设备可用</td>\n</tr>\n<tr>\n<td>AVAudioSessionRouteChangeReasonOldDeviceUnavailable</td>\n<td>老设备不可用</td>\n</tr>\n<tr>\n<td>AVAudioSessionRouteChangeReasonCategoryChange</td>\n<td>类别改变了</td>\n</tr>\n<tr>\n<td>AVAudioSessionRouteChangeReasonOverride</td>\n<td>App重置了输出设置</td>\n</tr>\n<tr>\n<td>AVAudioSessionRouteChangeReasonWakeFromSleep</td>\n<td>从睡眠状态呼醒</td>\n</tr>\n<tr>\n<td>AVAudioSessionRouteChangeReasonNoSuitableRouteForCategory</td>\n<td>当前Category下没有合适的设备</td>\n</tr>\n<tr>\n<td>AVAudioSessionRouteChangeReasonRouteConfigurationChange</td>\n<td>Rotuer的配置改变了</td>\n</tr>\n</tbody>\n</table>\n<p>示例代码：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">NSNotificationCenter *nsnc = [NSNotificationCenter defaultCenter];</span><br><span class=\"line\">[nsnc addObserver:self selector:@selector(handleRouteChange:) name:AVAudioSessionRouteChangeNotification object:[AVAudioSession sharedInstance]];</span><br><span class=\"line\"></span><br><span class=\"line\">- (void)handleRouteChange:(NSNotification *)notification</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    NSDictionary *info = notification.userInfo;</span><br><span class=\"line\">    AVAudioSessionRouteChangeReason reason = [info[AVAudioSessionRouteChangeReasonKey] unsignedIntegerValue];</span><br><span class=\"line\">    if (reason == AVAudioSessionRouteChangeReasonOldDeviceUnavailable) &#123;</span><br><span class=\"line\">        //如果拔出耳机，停止播放</span><br><span class=\"line\">        AVAudioSessionRouteDescription *previousRoute = info[AVAudioSessionRouteChangePreviousRouteKey];</span><br><span class=\"line\">        AVAudioSessionPortDescription *previousOutput = previousRoute.outputs[0];</span><br><span class=\"line\">        NSString *portType = previousOutput.portType;</span><br><span class=\"line\">        if ([portType isEqualToString:AVAudioSessionPortHeadphones]) &#123;</span><br><span class=\"line\">            [self stop];</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n"},{"title":"AVFoundation学习笔记八 AVPlayer及缩略图等相关功能","author":"Cyrus","date":"2018-11-08T15:25:00.000Z","_content":"\n![](player_classes.png)\n\n### AVPlayer\n一个用来播放基本时间的视听媒体的控制器对象。支持播放从本地、分步下载或通过HTTP Live Streaming协议得到的流媒体，并在多种播放场景中播放这些视频资源。AVPlayer是一个不可见组件，要将视频资源导出到用户界面的目标位置，需要使用AVPlyerLayer类。\n\n### AVPlayerLayer\n构建于Core animation上，是AVFoundation中能找到的为数不多的可见组件。AVPlayerLayer扩展了CoreAnimation的CALayer类，并通过框架在屏幕上显示视频内容。\n```\nAVPlayerLayer的videoGravity属性：\nAVLayerVideoGravityResizeAspect：默认值，保持视频原始宽高比，可能会有黑边；\nAVLayerVideoGravityResizeAspectFill： 保持原始宽高比，短边填充屏幕，长边可能会超出屏幕\nAVLayerVideoGravityResize：填充屏幕，不保持宽高比，图像会变形，最不常用。\n```\n\n### AVPlayerItem\nAVAsset包含一些媒体数据的静态信息，如创建日期、元数据和时长等，但是没有当前播放时间、音量和查找特定位置的方法这些动态数据，需要AVPlayerItem和AVPlayerItemTrack类构建相应的动态内容。\n\n```\n代码如下（简单，没啥说的）：\nNSURL *assetURL = [[NSBundle mainBundle] URLForResource:@\"1\" withExtension:@\"mp4\"];\n    AVAsset *asset = [AVAsset assetWithURL:assetURL];\n    \n    AVPlayerItem *item = [[AVPlayerItem alloc] initWithAsset:asset];\n    AVPlayer *player = [[AVPlayer alloc] initWithPlayerItem:item];\n    AVPlayerLayer *layer = [AVPlayerLayer playerLayerWithPlayer:player];\n    layer.frame = self.view.bounds;\n    [self.view.layer addSublayer:layer];\n    [player play];\n```\n\n### CMTime\nCMTime是Core Media的一种数据结构。CMTime为时间的正确表示给出了一种结构，即分数值的方式（分子、分母）,定义如下：\n```\n//value/timescale = seconds.\n    typedef struct\n    {\n        CMTimeValue    value;       //分子 int64_t\n        CMTimeScale    timescale;   //分母 int32_t\n        CMTimeFlags    flags;\n        CMTimeEpoch    epoch;\n    } CMTime;\n    \n    创建\n    //0.5s\n    CMTime halfSecond = CMTimeMake(1, 2);\n    //5s\n    CMTime fiveSeconds = CMTimeMake(5, 1);\n    //44.1kHz\n    CMTime oneSample = CMTimeMake(1, 44100);\n    //0\n    CMTime zeroTime = kCMTimeZero;\n```\n\n### 播放过程中的进度监听\n```\n- (void)addPlayerItemTimeObserver {\n    \n    // Create 0.5 second refresh interval - REFRESH_INTERVAL == 0.5\n    CMTime interval =\n        CMTimeMakeWithSeconds(0.5, NSEC_PER_SEC);              // 1\n    \n    // Main dispatch queue\n    dispatch_queue_t queue = dispatch_get_main_queue();                     // 2\n    \n    // Create callback block for time observer\n \n    void (^callback)(CMTime time) = ^(CMTime time) {\n        NSTimeInterval currentTime = CMTimeGetSeconds(time);\n        NSTimeInterval duration = CMTimeGetSeconds(weakSelf.playerItem.duration);\n        //do something with currentTime and duration\n    };\n    \n    // Add observer and store pointer for future use\n    self.timeObserver = [self.player addPeriodicTimeObserverForInterval:interval queue:queue usingBlock:callback];\n}\n\n\n可通过： [self.player removeTimeObserver:self.timeObserver]; 移除监听\n```\n\n### <font color=ff0000>视频进度缩略图</font>\nAVAssetImageGenerator工具类。这个类可以从一个Asset视频曲目中提取图片。生成一个或多个缩略图。主要包含两个方法：\n```\nAVAssetImageGenerator工具类。这个类可以从一个Asset视频曲目中提取图片。生成一个或多个缩略图。主要包含两个方法：\n/**\nrequestedTime: 指定获取缩略图的时间 传入数据\nactualTime:    生成图片的准确时间   传出数据\n*/\n\n- (nullable CGImageRef)copyCGImageAtTime:(CMTime)requestedTime actualTime:(nullable CMTime *)actualTime error:(NSError * _Nullable * _Nullable)outError //生成指定时间的单张缩略图\n```\n\n代码如下：\n```\n//指定时间生成缩略图\n//创建URL\n    NSURL *url=[NSURL URLWithString:[_videoURLStr stringByAddingPercentEscapesUsingEncoding:NSUTF8StringEncoding]];\n    AVURLAsset *urlAsset=[AVURLAsset assetWithURL:url];\n    AVAssetImageGenerator *imageGenerator=[AVAssetImageGenerator assetImageGeneratorWithAsset:urlAsset];\n    NSError *error=nil;\n    CMTime time=CMTimeMakeWithSeconds(timeBySecond, 10);\n    CMTime actualTime;\n    CGImageRef cgImage= [imageGenerator copyCGImageAtTime:time actualTime:&actualTime error:&error];\n    if(error){\n        return;\n    }\n    CMTimeShow(actualTime);\n    UIImage *image=[UIImage imageWithCGImage:cgImage];//转化为UIImage\n    //保存到相册\n    UIImageWriteToSavedPhotosAlbum(image,nil, nil, nil);\n    CGImageRelease(cgImage);\n```\n\n```\n//生成指定时间数组的一组缩略图\ntypedef void (^AVAssetImageGeneratorCompletionHandler)(CMTime requestedTime, CGImageRef _Nullable image, CMTime actualTime, AVAssetImageGeneratorResult result, NSError * _Nullable error);\n- (void)generateCGImagesAsynchronouslyForTimes:(NSArray<NSValue *> *)requestedTimes completionHandler:(AVAssetImageGeneratorCompletionHandler)handler;\n- (void)generateThumbnails {\n    \n    self.imageGenerator =                                                   // 1\n        [AVAssetImageGenerator assetImageGeneratorWithAsset:self.asset];\n    \n    // Generate the @2x equivalent\n    self.imageGenerator.maximumSize = CGSizeMake(200.0f, 0.0f);             // 2\n    CMTime duration = self.asset.duration;\n    NSMutableArray *times = [NSMutableArray array];                         // 3\n    CMTimeValue increment = duration.value / 20;\n    CMTimeValue currentValue = 2.0 * duration.timescale;\n    while (currentValue <= duration.value) {\n        CMTime time = CMTimeMake(currentValue, duration.timescale);\n        [times addObject:[NSValue valueWithCMTime:time]];\n        currentValue += increment;\n    }\n    __block NSUInteger imageCount = times.count;                            // 4\n    __block NSMutableArray *images = [NSMutableArray array];\n    AVAssetImageGeneratorCompletionHandler handler;                         // 5 handler会多次回调，每次生成一张缩略图/失败\n    \n    handler = ^(CMTime requestedTime,\n                CGImageRef imageRef,\n                CMTime actualTime,\n                AVAssetImageGeneratorResult result,\n                NSError *error) {\n        if (result == AVAssetImageGeneratorSucceeded) {                     // 6\n            UIImage *image = [UIImage imageWithCGImage:imageRef];\n            id thumbnail =\n                [THThumbnail thumbnailWithImage:image time:actualTime];\n            [images addObject:thumbnail];\n        } else {\n            NSLog(@\"Error: %@\", [error localizedDescription]);\n        }\n        // If the decremented image count is at 0, we're all done.\n        if (--imageCount == 0) {                                            // 7\n            dispatch_async(dispatch_get_main_queue(), ^{\n                NSString *name = THThumbnailsGeneratedNotification;\n                NSNotificationCenter *nc = [NSNotificationCenter defaultCenter];\n                [nc postNotificationName:name object:images];\n            });\n        }\n    };\n    [self.imageGenerator generateCGImagesAsynchronouslyForTimes:times completionHandler:handler];\n}\n```\n\n### 字幕切换\nAVFoundation在展示字幕和隐藏字幕方面提供了可靠方法。AVPlayerLayer会自动渲染这些元素，并且可以让开发者告诉应用程序哪些元素里面要渲染。完成这些操作需要用到AVMediaSelectionGroup和AVMediaSelectionOption两个类。\n```\nNSArray *mediaCharacteristics = asset.availableMediaCharacteristicsWithMediaSelectionOptions;\n    for (NSString *characteristic in mediaCharacteristics) {\n        //可选择的轨道组\n        AVMediaSelectionGroup *group = [asset mediaSelectionGroupForMediaCharacteristic:characteristic];\n        NSLog(@\"%@\", characteristic);\n        for (AVMediaSelectionOption *option in group.options) {\n            //option:轨道组中的轨道\n            NSLog(@\"Option:%@\", option.displayName);\n            \n            //- (void)selectMediaOption:(nullable AVMediaSelectionOption *)mediaSelectionOption inMediaSelectionGroup:(AVMediaSelectionGroup *)mediaSelectionGroup\n            //对所择轨道的切换，如切换字幕、音频等\n            [item selectMediaOption:option inMediaSelectionGroup:group];\n        }\n    }\n```\n结果显示：\n![](option_result.png)\n\n### airplay\n```\nMPVolumeView *volumeView = [[MPVolumeView alloc] initWithFrame:CGRectZero];\nvolumeView.showsVolumeSlider = NO;\n[volumeView sizeToFit];\n[self.view addSubview:volumeView];\n```\n可以弹出airplay播放设备，如mac上的air server，但air Server闪退，原因未知\n\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/AVFoundation学习笔记八-AVPlayer及缩略图等相关功能.md","raw":"title: AVFoundation学习笔记八 AVPlayer及缩略图等相关功能\nauthor: Cyrus\ntags: []\ncategories:\n  - AVFoundation\ndate: 2018-11-08 23:25:00\n---\n\n![](player_classes.png)\n\n### AVPlayer\n一个用来播放基本时间的视听媒体的控制器对象。支持播放从本地、分步下载或通过HTTP Live Streaming协议得到的流媒体，并在多种播放场景中播放这些视频资源。AVPlayer是一个不可见组件，要将视频资源导出到用户界面的目标位置，需要使用AVPlyerLayer类。\n\n### AVPlayerLayer\n构建于Core animation上，是AVFoundation中能找到的为数不多的可见组件。AVPlayerLayer扩展了CoreAnimation的CALayer类，并通过框架在屏幕上显示视频内容。\n```\nAVPlayerLayer的videoGravity属性：\nAVLayerVideoGravityResizeAspect：默认值，保持视频原始宽高比，可能会有黑边；\nAVLayerVideoGravityResizeAspectFill： 保持原始宽高比，短边填充屏幕，长边可能会超出屏幕\nAVLayerVideoGravityResize：填充屏幕，不保持宽高比，图像会变形，最不常用。\n```\n\n### AVPlayerItem\nAVAsset包含一些媒体数据的静态信息，如创建日期、元数据和时长等，但是没有当前播放时间、音量和查找特定位置的方法这些动态数据，需要AVPlayerItem和AVPlayerItemTrack类构建相应的动态内容。\n\n```\n代码如下（简单，没啥说的）：\nNSURL *assetURL = [[NSBundle mainBundle] URLForResource:@\"1\" withExtension:@\"mp4\"];\n    AVAsset *asset = [AVAsset assetWithURL:assetURL];\n    \n    AVPlayerItem *item = [[AVPlayerItem alloc] initWithAsset:asset];\n    AVPlayer *player = [[AVPlayer alloc] initWithPlayerItem:item];\n    AVPlayerLayer *layer = [AVPlayerLayer playerLayerWithPlayer:player];\n    layer.frame = self.view.bounds;\n    [self.view.layer addSublayer:layer];\n    [player play];\n```\n\n### CMTime\nCMTime是Core Media的一种数据结构。CMTime为时间的正确表示给出了一种结构，即分数值的方式（分子、分母）,定义如下：\n```\n//value/timescale = seconds.\n    typedef struct\n    {\n        CMTimeValue    value;       //分子 int64_t\n        CMTimeScale    timescale;   //分母 int32_t\n        CMTimeFlags    flags;\n        CMTimeEpoch    epoch;\n    } CMTime;\n    \n    创建\n    //0.5s\n    CMTime halfSecond = CMTimeMake(1, 2);\n    //5s\n    CMTime fiveSeconds = CMTimeMake(5, 1);\n    //44.1kHz\n    CMTime oneSample = CMTimeMake(1, 44100);\n    //0\n    CMTime zeroTime = kCMTimeZero;\n```\n\n### 播放过程中的进度监听\n```\n- (void)addPlayerItemTimeObserver {\n    \n    // Create 0.5 second refresh interval - REFRESH_INTERVAL == 0.5\n    CMTime interval =\n        CMTimeMakeWithSeconds(0.5, NSEC_PER_SEC);              // 1\n    \n    // Main dispatch queue\n    dispatch_queue_t queue = dispatch_get_main_queue();                     // 2\n    \n    // Create callback block for time observer\n \n    void (^callback)(CMTime time) = ^(CMTime time) {\n        NSTimeInterval currentTime = CMTimeGetSeconds(time);\n        NSTimeInterval duration = CMTimeGetSeconds(weakSelf.playerItem.duration);\n        //do something with currentTime and duration\n    };\n    \n    // Add observer and store pointer for future use\n    self.timeObserver = [self.player addPeriodicTimeObserverForInterval:interval queue:queue usingBlock:callback];\n}\n\n\n可通过： [self.player removeTimeObserver:self.timeObserver]; 移除监听\n```\n\n### <font color=ff0000>视频进度缩略图</font>\nAVAssetImageGenerator工具类。这个类可以从一个Asset视频曲目中提取图片。生成一个或多个缩略图。主要包含两个方法：\n```\nAVAssetImageGenerator工具类。这个类可以从一个Asset视频曲目中提取图片。生成一个或多个缩略图。主要包含两个方法：\n/**\nrequestedTime: 指定获取缩略图的时间 传入数据\nactualTime:    生成图片的准确时间   传出数据\n*/\n\n- (nullable CGImageRef)copyCGImageAtTime:(CMTime)requestedTime actualTime:(nullable CMTime *)actualTime error:(NSError * _Nullable * _Nullable)outError //生成指定时间的单张缩略图\n```\n\n代码如下：\n```\n//指定时间生成缩略图\n//创建URL\n    NSURL *url=[NSURL URLWithString:[_videoURLStr stringByAddingPercentEscapesUsingEncoding:NSUTF8StringEncoding]];\n    AVURLAsset *urlAsset=[AVURLAsset assetWithURL:url];\n    AVAssetImageGenerator *imageGenerator=[AVAssetImageGenerator assetImageGeneratorWithAsset:urlAsset];\n    NSError *error=nil;\n    CMTime time=CMTimeMakeWithSeconds(timeBySecond, 10);\n    CMTime actualTime;\n    CGImageRef cgImage= [imageGenerator copyCGImageAtTime:time actualTime:&actualTime error:&error];\n    if(error){\n        return;\n    }\n    CMTimeShow(actualTime);\n    UIImage *image=[UIImage imageWithCGImage:cgImage];//转化为UIImage\n    //保存到相册\n    UIImageWriteToSavedPhotosAlbum(image,nil, nil, nil);\n    CGImageRelease(cgImage);\n```\n\n```\n//生成指定时间数组的一组缩略图\ntypedef void (^AVAssetImageGeneratorCompletionHandler)(CMTime requestedTime, CGImageRef _Nullable image, CMTime actualTime, AVAssetImageGeneratorResult result, NSError * _Nullable error);\n- (void)generateCGImagesAsynchronouslyForTimes:(NSArray<NSValue *> *)requestedTimes completionHandler:(AVAssetImageGeneratorCompletionHandler)handler;\n- (void)generateThumbnails {\n    \n    self.imageGenerator =                                                   // 1\n        [AVAssetImageGenerator assetImageGeneratorWithAsset:self.asset];\n    \n    // Generate the @2x equivalent\n    self.imageGenerator.maximumSize = CGSizeMake(200.0f, 0.0f);             // 2\n    CMTime duration = self.asset.duration;\n    NSMutableArray *times = [NSMutableArray array];                         // 3\n    CMTimeValue increment = duration.value / 20;\n    CMTimeValue currentValue = 2.0 * duration.timescale;\n    while (currentValue <= duration.value) {\n        CMTime time = CMTimeMake(currentValue, duration.timescale);\n        [times addObject:[NSValue valueWithCMTime:time]];\n        currentValue += increment;\n    }\n    __block NSUInteger imageCount = times.count;                            // 4\n    __block NSMutableArray *images = [NSMutableArray array];\n    AVAssetImageGeneratorCompletionHandler handler;                         // 5 handler会多次回调，每次生成一张缩略图/失败\n    \n    handler = ^(CMTime requestedTime,\n                CGImageRef imageRef,\n                CMTime actualTime,\n                AVAssetImageGeneratorResult result,\n                NSError *error) {\n        if (result == AVAssetImageGeneratorSucceeded) {                     // 6\n            UIImage *image = [UIImage imageWithCGImage:imageRef];\n            id thumbnail =\n                [THThumbnail thumbnailWithImage:image time:actualTime];\n            [images addObject:thumbnail];\n        } else {\n            NSLog(@\"Error: %@\", [error localizedDescription]);\n        }\n        // If the decremented image count is at 0, we're all done.\n        if (--imageCount == 0) {                                            // 7\n            dispatch_async(dispatch_get_main_queue(), ^{\n                NSString *name = THThumbnailsGeneratedNotification;\n                NSNotificationCenter *nc = [NSNotificationCenter defaultCenter];\n                [nc postNotificationName:name object:images];\n            });\n        }\n    };\n    [self.imageGenerator generateCGImagesAsynchronouslyForTimes:times completionHandler:handler];\n}\n```\n\n### 字幕切换\nAVFoundation在展示字幕和隐藏字幕方面提供了可靠方法。AVPlayerLayer会自动渲染这些元素，并且可以让开发者告诉应用程序哪些元素里面要渲染。完成这些操作需要用到AVMediaSelectionGroup和AVMediaSelectionOption两个类。\n```\nNSArray *mediaCharacteristics = asset.availableMediaCharacteristicsWithMediaSelectionOptions;\n    for (NSString *characteristic in mediaCharacteristics) {\n        //可选择的轨道组\n        AVMediaSelectionGroup *group = [asset mediaSelectionGroupForMediaCharacteristic:characteristic];\n        NSLog(@\"%@\", characteristic);\n        for (AVMediaSelectionOption *option in group.options) {\n            //option:轨道组中的轨道\n            NSLog(@\"Option:%@\", option.displayName);\n            \n            //- (void)selectMediaOption:(nullable AVMediaSelectionOption *)mediaSelectionOption inMediaSelectionGroup:(AVMediaSelectionGroup *)mediaSelectionGroup\n            //对所择轨道的切换，如切换字幕、音频等\n            [item selectMediaOption:option inMediaSelectionGroup:group];\n        }\n    }\n```\n结果显示：\n![](option_result.png)\n\n### airplay\n```\nMPVolumeView *volumeView = [[MPVolumeView alloc] initWithFrame:CGRectZero];\nvolumeView.showsVolumeSlider = NO;\n[volumeView sizeToFit];\n[self.view addSubview:volumeView];\n```\n可以弹出airplay播放设备，如mac上的air server，但air Server闪退，原因未知\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"AVFoundation学习笔记八-AVPlayer及缩略图等相关功能","published":1,"updated":"2018-11-08T15:37:36.509Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjo8raw1w001cdrd3q3yh1bzg","content":"<p><img src=\"//www.cyrus.fun/2018/11/08/AVFoundation学习笔记八-AVPlayer及缩略图等相关功能/player_classes.png\" alt=\"\"></p>\n<h3 id=\"AVPlayer\"><a href=\"#AVPlayer\" class=\"headerlink\" title=\"AVPlayer\"></a>AVPlayer</h3><p>一个用来播放基本时间的视听媒体的控制器对象。支持播放从本地、分步下载或通过HTTP Live Streaming协议得到的流媒体，并在多种播放场景中播放这些视频资源。AVPlayer是一个不可见组件，要将视频资源导出到用户界面的目标位置，需要使用AVPlyerLayer类。</p>\n<h3 id=\"AVPlayerLayer\"><a href=\"#AVPlayerLayer\" class=\"headerlink\" title=\"AVPlayerLayer\"></a>AVPlayerLayer</h3><p>构建于Core animation上，是AVFoundation中能找到的为数不多的可见组件。AVPlayerLayer扩展了CoreAnimation的CALayer类，并通过框架在屏幕上显示视频内容。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">AVPlayerLayer的videoGravity属性：</span><br><span class=\"line\">AVLayerVideoGravityResizeAspect：默认值，保持视频原始宽高比，可能会有黑边；</span><br><span class=\"line\">AVLayerVideoGravityResizeAspectFill： 保持原始宽高比，短边填充屏幕，长边可能会超出屏幕</span><br><span class=\"line\">AVLayerVideoGravityResize：填充屏幕，不保持宽高比，图像会变形，最不常用。</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"AVPlayerItem\"><a href=\"#AVPlayerItem\" class=\"headerlink\" title=\"AVPlayerItem\"></a>AVPlayerItem</h3><p>AVAsset包含一些媒体数据的静态信息，如创建日期、元数据和时长等，但是没有当前播放时间、音量和查找特定位置的方法这些动态数据，需要AVPlayerItem和AVPlayerItemTrack类构建相应的动态内容。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">代码如下（简单，没啥说的）：</span><br><span class=\"line\">NSURL *assetURL = [[NSBundle mainBundle] URLForResource:@&quot;1&quot; withExtension:@&quot;mp4&quot;];</span><br><span class=\"line\">    AVAsset *asset = [AVAsset assetWithURL:assetURL];</span><br><span class=\"line\">    </span><br><span class=\"line\">    AVPlayerItem *item = [[AVPlayerItem alloc] initWithAsset:asset];</span><br><span class=\"line\">    AVPlayer *player = [[AVPlayer alloc] initWithPlayerItem:item];</span><br><span class=\"line\">    AVPlayerLayer *layer = [AVPlayerLayer playerLayerWithPlayer:player];</span><br><span class=\"line\">    layer.frame = self.view.bounds;</span><br><span class=\"line\">    [self.view.layer addSublayer:layer];</span><br><span class=\"line\">    [player play];</span><br></pre></td></tr></table></figure>\n<h3 id=\"CMTime\"><a href=\"#CMTime\" class=\"headerlink\" title=\"CMTime\"></a>CMTime</h3><p>CMTime是Core Media的一种数据结构。CMTime为时间的正确表示给出了一种结构，即分数值的方式（分子、分母）,定义如下：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//value/timescale = seconds.</span><br><span class=\"line\">    typedef struct</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        CMTimeValue    value;       //分子 int64_t</span><br><span class=\"line\">        CMTimeScale    timescale;   //分母 int32_t</span><br><span class=\"line\">        CMTimeFlags    flags;</span><br><span class=\"line\">        CMTimeEpoch    epoch;</span><br><span class=\"line\">    &#125; CMTime;</span><br><span class=\"line\">    </span><br><span class=\"line\">    创建</span><br><span class=\"line\">    //0.5s</span><br><span class=\"line\">    CMTime halfSecond = CMTimeMake(1, 2);</span><br><span class=\"line\">    //5s</span><br><span class=\"line\">    CMTime fiveSeconds = CMTimeMake(5, 1);</span><br><span class=\"line\">    //44.1kHz</span><br><span class=\"line\">    CMTime oneSample = CMTimeMake(1, 44100);</span><br><span class=\"line\">    //0</span><br><span class=\"line\">    CMTime zeroTime = kCMTimeZero;</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"播放过程中的进度监听\"><a href=\"#播放过程中的进度监听\" class=\"headerlink\" title=\"播放过程中的进度监听\"></a>播放过程中的进度监听</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">- (void)addPlayerItemTimeObserver &#123;</span><br><span class=\"line\">    </span><br><span class=\"line\">    // Create 0.5 second refresh interval - REFRESH_INTERVAL == 0.5</span><br><span class=\"line\">    CMTime interval =</span><br><span class=\"line\">        CMTimeMakeWithSeconds(0.5, NSEC_PER_SEC);              // 1</span><br><span class=\"line\">    </span><br><span class=\"line\">    // Main dispatch queue</span><br><span class=\"line\">    dispatch_queue_t queue = dispatch_get_main_queue();                     // 2</span><br><span class=\"line\">    </span><br><span class=\"line\">    // Create callback block for time observer</span><br><span class=\"line\"> </span><br><span class=\"line\">    void (^callback)(CMTime time) = ^(CMTime time) &#123;</span><br><span class=\"line\">        NSTimeInterval currentTime = CMTimeGetSeconds(time);</span><br><span class=\"line\">        NSTimeInterval duration = CMTimeGetSeconds(weakSelf.playerItem.duration);</span><br><span class=\"line\">        //do something with currentTime and duration</span><br><span class=\"line\">    &#125;;</span><br><span class=\"line\">    </span><br><span class=\"line\">    // Add observer and store pointer for future use</span><br><span class=\"line\">    self.timeObserver = [self.player addPeriodicTimeObserverForInterval:interval queue:queue usingBlock:callback];</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">可通过： [self.player removeTimeObserver:self.timeObserver]; 移除监听</span><br></pre></td></tr></table></figure>\n<h3 id=\"视频进度缩略图\"><a href=\"#视频进度缩略图\" class=\"headerlink\" title=\"视频进度缩略图\"></a><font color=\"ff0000\">视频进度缩略图</font></h3><p>AVAssetImageGenerator工具类。这个类可以从一个Asset视频曲目中提取图片。生成一个或多个缩略图。主要包含两个方法：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">AVAssetImageGenerator工具类。这个类可以从一个Asset视频曲目中提取图片。生成一个或多个缩略图。主要包含两个方法：</span><br><span class=\"line\">/**</span><br><span class=\"line\">requestedTime: 指定获取缩略图的时间 传入数据</span><br><span class=\"line\">actualTime:    生成图片的准确时间   传出数据</span><br><span class=\"line\">*/</span><br><span class=\"line\"></span><br><span class=\"line\">- (nullable CGImageRef)copyCGImageAtTime:(CMTime)requestedTime actualTime:(nullable CMTime *)actualTime error:(NSError * _Nullable * _Nullable)outError //生成指定时间的单张缩略图</span><br></pre></td></tr></table></figure></p>\n<p>代码如下：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//指定时间生成缩略图</span><br><span class=\"line\">//创建URL</span><br><span class=\"line\">    NSURL *url=[NSURL URLWithString:[_videoURLStr stringByAddingPercentEscapesUsingEncoding:NSUTF8StringEncoding]];</span><br><span class=\"line\">    AVURLAsset *urlAsset=[AVURLAsset assetWithURL:url];</span><br><span class=\"line\">    AVAssetImageGenerator *imageGenerator=[AVAssetImageGenerator assetImageGeneratorWithAsset:urlAsset];</span><br><span class=\"line\">    NSError *error=nil;</span><br><span class=\"line\">    CMTime time=CMTimeMakeWithSeconds(timeBySecond, 10);</span><br><span class=\"line\">    CMTime actualTime;</span><br><span class=\"line\">    CGImageRef cgImage= [imageGenerator copyCGImageAtTime:time actualTime:&amp;actualTime error:&amp;error];</span><br><span class=\"line\">    if(error)&#123;</span><br><span class=\"line\">        return;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    CMTimeShow(actualTime);</span><br><span class=\"line\">    UIImage *image=[UIImage imageWithCGImage:cgImage];//转化为UIImage</span><br><span class=\"line\">    //保存到相册</span><br><span class=\"line\">    UIImageWriteToSavedPhotosAlbum(image,nil, nil, nil);</span><br><span class=\"line\">    CGImageRelease(cgImage);</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//生成指定时间数组的一组缩略图</span><br><span class=\"line\">typedef void (^AVAssetImageGeneratorCompletionHandler)(CMTime requestedTime, CGImageRef _Nullable image, CMTime actualTime, AVAssetImageGeneratorResult result, NSError * _Nullable error);</span><br><span class=\"line\">- (void)generateCGImagesAsynchronouslyForTimes:(NSArray&lt;NSValue *&gt; *)requestedTimes completionHandler:(AVAssetImageGeneratorCompletionHandler)handler;</span><br><span class=\"line\">- (void)generateThumbnails &#123;</span><br><span class=\"line\">    </span><br><span class=\"line\">    self.imageGenerator =                                                   // 1</span><br><span class=\"line\">        [AVAssetImageGenerator assetImageGeneratorWithAsset:self.asset];</span><br><span class=\"line\">    </span><br><span class=\"line\">    // Generate the @2x equivalent</span><br><span class=\"line\">    self.imageGenerator.maximumSize = CGSizeMake(200.0f, 0.0f);             // 2</span><br><span class=\"line\">    CMTime duration = self.asset.duration;</span><br><span class=\"line\">    NSMutableArray *times = [NSMutableArray array];                         // 3</span><br><span class=\"line\">    CMTimeValue increment = duration.value / 20;</span><br><span class=\"line\">    CMTimeValue currentValue = 2.0 * duration.timescale;</span><br><span class=\"line\">    while (currentValue &lt;= duration.value) &#123;</span><br><span class=\"line\">        CMTime time = CMTimeMake(currentValue, duration.timescale);</span><br><span class=\"line\">        [times addObject:[NSValue valueWithCMTime:time]];</span><br><span class=\"line\">        currentValue += increment;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    __block NSUInteger imageCount = times.count;                            // 4</span><br><span class=\"line\">    __block NSMutableArray *images = [NSMutableArray array];</span><br><span class=\"line\">    AVAssetImageGeneratorCompletionHandler handler;                         // 5 handler会多次回调，每次生成一张缩略图/失败</span><br><span class=\"line\">    </span><br><span class=\"line\">    handler = ^(CMTime requestedTime,</span><br><span class=\"line\">                CGImageRef imageRef,</span><br><span class=\"line\">                CMTime actualTime,</span><br><span class=\"line\">                AVAssetImageGeneratorResult result,</span><br><span class=\"line\">                NSError *error) &#123;</span><br><span class=\"line\">        if (result == AVAssetImageGeneratorSucceeded) &#123;                     // 6</span><br><span class=\"line\">            UIImage *image = [UIImage imageWithCGImage:imageRef];</span><br><span class=\"line\">            id thumbnail =</span><br><span class=\"line\">                [THThumbnail thumbnailWithImage:image time:actualTime];</span><br><span class=\"line\">            [images addObject:thumbnail];</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">            NSLog(@&quot;Error: %@&quot;, [error localizedDescription]);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        // If the decremented image count is at 0, we&apos;re all done.</span><br><span class=\"line\">        if (--imageCount == 0) &#123;                                            // 7</span><br><span class=\"line\">            dispatch_async(dispatch_get_main_queue(), ^&#123;</span><br><span class=\"line\">                NSString *name = THThumbnailsGeneratedNotification;</span><br><span class=\"line\">                NSNotificationCenter *nc = [NSNotificationCenter defaultCenter];</span><br><span class=\"line\">                [nc postNotificationName:name object:images];</span><br><span class=\"line\">            &#125;);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;;</span><br><span class=\"line\">    [self.imageGenerator generateCGImagesAsynchronouslyForTimes:times completionHandler:handler];</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"字幕切换\"><a href=\"#字幕切换\" class=\"headerlink\" title=\"字幕切换\"></a>字幕切换</h3><p>AVFoundation在展示字幕和隐藏字幕方面提供了可靠方法。AVPlayerLayer会自动渲染这些元素，并且可以让开发者告诉应用程序哪些元素里面要渲染。完成这些操作需要用到AVMediaSelectionGroup和AVMediaSelectionOption两个类。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">NSArray *mediaCharacteristics = asset.availableMediaCharacteristicsWithMediaSelectionOptions;</span><br><span class=\"line\">    for (NSString *characteristic in mediaCharacteristics) &#123;</span><br><span class=\"line\">        //可选择的轨道组</span><br><span class=\"line\">        AVMediaSelectionGroup *group = [asset mediaSelectionGroupForMediaCharacteristic:characteristic];</span><br><span class=\"line\">        NSLog(@&quot;%@&quot;, characteristic);</span><br><span class=\"line\">        for (AVMediaSelectionOption *option in group.options) &#123;</span><br><span class=\"line\">            //option:轨道组中的轨道</span><br><span class=\"line\">            NSLog(@&quot;Option:%@&quot;, option.displayName);</span><br><span class=\"line\">            </span><br><span class=\"line\">            //- (void)selectMediaOption:(nullable AVMediaSelectionOption *)mediaSelectionOption inMediaSelectionGroup:(AVMediaSelectionGroup *)mediaSelectionGroup</span><br><span class=\"line\">            //对所择轨道的切换，如切换字幕、音频等</span><br><span class=\"line\">            [item selectMediaOption:option inMediaSelectionGroup:group];</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure></p>\n<p>结果显示：<br><img src=\"//www.cyrus.fun/2018/11/08/AVFoundation学习笔记八-AVPlayer及缩略图等相关功能/option_result.png\" alt=\"\"></p>\n<h3 id=\"airplay\"><a href=\"#airplay\" class=\"headerlink\" title=\"airplay\"></a>airplay</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">MPVolumeView *volumeView = [[MPVolumeView alloc] initWithFrame:CGRectZero];</span><br><span class=\"line\">volumeView.showsVolumeSlider = NO;</span><br><span class=\"line\">[volumeView sizeToFit];</span><br><span class=\"line\">[self.view addSubview:volumeView];</span><br></pre></td></tr></table></figure>\n<p>可以弹出airplay播放设备，如mac上的air server，但air Server闪退，原因未知</p>\n","site":{"data":{}},"excerpt":"","more":"<p><img src=\"//www.cyrus.fun/2018/11/08/AVFoundation学习笔记八-AVPlayer及缩略图等相关功能/player_classes.png\" alt=\"\"></p>\n<h3 id=\"AVPlayer\"><a href=\"#AVPlayer\" class=\"headerlink\" title=\"AVPlayer\"></a>AVPlayer</h3><p>一个用来播放基本时间的视听媒体的控制器对象。支持播放从本地、分步下载或通过HTTP Live Streaming协议得到的流媒体，并在多种播放场景中播放这些视频资源。AVPlayer是一个不可见组件，要将视频资源导出到用户界面的目标位置，需要使用AVPlyerLayer类。</p>\n<h3 id=\"AVPlayerLayer\"><a href=\"#AVPlayerLayer\" class=\"headerlink\" title=\"AVPlayerLayer\"></a>AVPlayerLayer</h3><p>构建于Core animation上，是AVFoundation中能找到的为数不多的可见组件。AVPlayerLayer扩展了CoreAnimation的CALayer类，并通过框架在屏幕上显示视频内容。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">AVPlayerLayer的videoGravity属性：</span><br><span class=\"line\">AVLayerVideoGravityResizeAspect：默认值，保持视频原始宽高比，可能会有黑边；</span><br><span class=\"line\">AVLayerVideoGravityResizeAspectFill： 保持原始宽高比，短边填充屏幕，长边可能会超出屏幕</span><br><span class=\"line\">AVLayerVideoGravityResize：填充屏幕，不保持宽高比，图像会变形，最不常用。</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"AVPlayerItem\"><a href=\"#AVPlayerItem\" class=\"headerlink\" title=\"AVPlayerItem\"></a>AVPlayerItem</h3><p>AVAsset包含一些媒体数据的静态信息，如创建日期、元数据和时长等，但是没有当前播放时间、音量和查找特定位置的方法这些动态数据，需要AVPlayerItem和AVPlayerItemTrack类构建相应的动态内容。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">代码如下（简单，没啥说的）：</span><br><span class=\"line\">NSURL *assetURL = [[NSBundle mainBundle] URLForResource:@&quot;1&quot; withExtension:@&quot;mp4&quot;];</span><br><span class=\"line\">    AVAsset *asset = [AVAsset assetWithURL:assetURL];</span><br><span class=\"line\">    </span><br><span class=\"line\">    AVPlayerItem *item = [[AVPlayerItem alloc] initWithAsset:asset];</span><br><span class=\"line\">    AVPlayer *player = [[AVPlayer alloc] initWithPlayerItem:item];</span><br><span class=\"line\">    AVPlayerLayer *layer = [AVPlayerLayer playerLayerWithPlayer:player];</span><br><span class=\"line\">    layer.frame = self.view.bounds;</span><br><span class=\"line\">    [self.view.layer addSublayer:layer];</span><br><span class=\"line\">    [player play];</span><br></pre></td></tr></table></figure>\n<h3 id=\"CMTime\"><a href=\"#CMTime\" class=\"headerlink\" title=\"CMTime\"></a>CMTime</h3><p>CMTime是Core Media的一种数据结构。CMTime为时间的正确表示给出了一种结构，即分数值的方式（分子、分母）,定义如下：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//value/timescale = seconds.</span><br><span class=\"line\">    typedef struct</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        CMTimeValue    value;       //分子 int64_t</span><br><span class=\"line\">        CMTimeScale    timescale;   //分母 int32_t</span><br><span class=\"line\">        CMTimeFlags    flags;</span><br><span class=\"line\">        CMTimeEpoch    epoch;</span><br><span class=\"line\">    &#125; CMTime;</span><br><span class=\"line\">    </span><br><span class=\"line\">    创建</span><br><span class=\"line\">    //0.5s</span><br><span class=\"line\">    CMTime halfSecond = CMTimeMake(1, 2);</span><br><span class=\"line\">    //5s</span><br><span class=\"line\">    CMTime fiveSeconds = CMTimeMake(5, 1);</span><br><span class=\"line\">    //44.1kHz</span><br><span class=\"line\">    CMTime oneSample = CMTimeMake(1, 44100);</span><br><span class=\"line\">    //0</span><br><span class=\"line\">    CMTime zeroTime = kCMTimeZero;</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"播放过程中的进度监听\"><a href=\"#播放过程中的进度监听\" class=\"headerlink\" title=\"播放过程中的进度监听\"></a>播放过程中的进度监听</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">- (void)addPlayerItemTimeObserver &#123;</span><br><span class=\"line\">    </span><br><span class=\"line\">    // Create 0.5 second refresh interval - REFRESH_INTERVAL == 0.5</span><br><span class=\"line\">    CMTime interval =</span><br><span class=\"line\">        CMTimeMakeWithSeconds(0.5, NSEC_PER_SEC);              // 1</span><br><span class=\"line\">    </span><br><span class=\"line\">    // Main dispatch queue</span><br><span class=\"line\">    dispatch_queue_t queue = dispatch_get_main_queue();                     // 2</span><br><span class=\"line\">    </span><br><span class=\"line\">    // Create callback block for time observer</span><br><span class=\"line\"> </span><br><span class=\"line\">    void (^callback)(CMTime time) = ^(CMTime time) &#123;</span><br><span class=\"line\">        NSTimeInterval currentTime = CMTimeGetSeconds(time);</span><br><span class=\"line\">        NSTimeInterval duration = CMTimeGetSeconds(weakSelf.playerItem.duration);</span><br><span class=\"line\">        //do something with currentTime and duration</span><br><span class=\"line\">    &#125;;</span><br><span class=\"line\">    </span><br><span class=\"line\">    // Add observer and store pointer for future use</span><br><span class=\"line\">    self.timeObserver = [self.player addPeriodicTimeObserverForInterval:interval queue:queue usingBlock:callback];</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">可通过： [self.player removeTimeObserver:self.timeObserver]; 移除监听</span><br></pre></td></tr></table></figure>\n<h3 id=\"视频进度缩略图\"><a href=\"#视频进度缩略图\" class=\"headerlink\" title=\"视频进度缩略图\"></a><font color=\"ff0000\">视频进度缩略图</font></h3><p>AVAssetImageGenerator工具类。这个类可以从一个Asset视频曲目中提取图片。生成一个或多个缩略图。主要包含两个方法：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">AVAssetImageGenerator工具类。这个类可以从一个Asset视频曲目中提取图片。生成一个或多个缩略图。主要包含两个方法：</span><br><span class=\"line\">/**</span><br><span class=\"line\">requestedTime: 指定获取缩略图的时间 传入数据</span><br><span class=\"line\">actualTime:    生成图片的准确时间   传出数据</span><br><span class=\"line\">*/</span><br><span class=\"line\"></span><br><span class=\"line\">- (nullable CGImageRef)copyCGImageAtTime:(CMTime)requestedTime actualTime:(nullable CMTime *)actualTime error:(NSError * _Nullable * _Nullable)outError //生成指定时间的单张缩略图</span><br></pre></td></tr></table></figure></p>\n<p>代码如下：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//指定时间生成缩略图</span><br><span class=\"line\">//创建URL</span><br><span class=\"line\">    NSURL *url=[NSURL URLWithString:[_videoURLStr stringByAddingPercentEscapesUsingEncoding:NSUTF8StringEncoding]];</span><br><span class=\"line\">    AVURLAsset *urlAsset=[AVURLAsset assetWithURL:url];</span><br><span class=\"line\">    AVAssetImageGenerator *imageGenerator=[AVAssetImageGenerator assetImageGeneratorWithAsset:urlAsset];</span><br><span class=\"line\">    NSError *error=nil;</span><br><span class=\"line\">    CMTime time=CMTimeMakeWithSeconds(timeBySecond, 10);</span><br><span class=\"line\">    CMTime actualTime;</span><br><span class=\"line\">    CGImageRef cgImage= [imageGenerator copyCGImageAtTime:time actualTime:&amp;actualTime error:&amp;error];</span><br><span class=\"line\">    if(error)&#123;</span><br><span class=\"line\">        return;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    CMTimeShow(actualTime);</span><br><span class=\"line\">    UIImage *image=[UIImage imageWithCGImage:cgImage];//转化为UIImage</span><br><span class=\"line\">    //保存到相册</span><br><span class=\"line\">    UIImageWriteToSavedPhotosAlbum(image,nil, nil, nil);</span><br><span class=\"line\">    CGImageRelease(cgImage);</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//生成指定时间数组的一组缩略图</span><br><span class=\"line\">typedef void (^AVAssetImageGeneratorCompletionHandler)(CMTime requestedTime, CGImageRef _Nullable image, CMTime actualTime, AVAssetImageGeneratorResult result, NSError * _Nullable error);</span><br><span class=\"line\">- (void)generateCGImagesAsynchronouslyForTimes:(NSArray&lt;NSValue *&gt; *)requestedTimes completionHandler:(AVAssetImageGeneratorCompletionHandler)handler;</span><br><span class=\"line\">- (void)generateThumbnails &#123;</span><br><span class=\"line\">    </span><br><span class=\"line\">    self.imageGenerator =                                                   // 1</span><br><span class=\"line\">        [AVAssetImageGenerator assetImageGeneratorWithAsset:self.asset];</span><br><span class=\"line\">    </span><br><span class=\"line\">    // Generate the @2x equivalent</span><br><span class=\"line\">    self.imageGenerator.maximumSize = CGSizeMake(200.0f, 0.0f);             // 2</span><br><span class=\"line\">    CMTime duration = self.asset.duration;</span><br><span class=\"line\">    NSMutableArray *times = [NSMutableArray array];                         // 3</span><br><span class=\"line\">    CMTimeValue increment = duration.value / 20;</span><br><span class=\"line\">    CMTimeValue currentValue = 2.0 * duration.timescale;</span><br><span class=\"line\">    while (currentValue &lt;= duration.value) &#123;</span><br><span class=\"line\">        CMTime time = CMTimeMake(currentValue, duration.timescale);</span><br><span class=\"line\">        [times addObject:[NSValue valueWithCMTime:time]];</span><br><span class=\"line\">        currentValue += increment;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    __block NSUInteger imageCount = times.count;                            // 4</span><br><span class=\"line\">    __block NSMutableArray *images = [NSMutableArray array];</span><br><span class=\"line\">    AVAssetImageGeneratorCompletionHandler handler;                         // 5 handler会多次回调，每次生成一张缩略图/失败</span><br><span class=\"line\">    </span><br><span class=\"line\">    handler = ^(CMTime requestedTime,</span><br><span class=\"line\">                CGImageRef imageRef,</span><br><span class=\"line\">                CMTime actualTime,</span><br><span class=\"line\">                AVAssetImageGeneratorResult result,</span><br><span class=\"line\">                NSError *error) &#123;</span><br><span class=\"line\">        if (result == AVAssetImageGeneratorSucceeded) &#123;                     // 6</span><br><span class=\"line\">            UIImage *image = [UIImage imageWithCGImage:imageRef];</span><br><span class=\"line\">            id thumbnail =</span><br><span class=\"line\">                [THThumbnail thumbnailWithImage:image time:actualTime];</span><br><span class=\"line\">            [images addObject:thumbnail];</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">            NSLog(@&quot;Error: %@&quot;, [error localizedDescription]);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        // If the decremented image count is at 0, we&apos;re all done.</span><br><span class=\"line\">        if (--imageCount == 0) &#123;                                            // 7</span><br><span class=\"line\">            dispatch_async(dispatch_get_main_queue(), ^&#123;</span><br><span class=\"line\">                NSString *name = THThumbnailsGeneratedNotification;</span><br><span class=\"line\">                NSNotificationCenter *nc = [NSNotificationCenter defaultCenter];</span><br><span class=\"line\">                [nc postNotificationName:name object:images];</span><br><span class=\"line\">            &#125;);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;;</span><br><span class=\"line\">    [self.imageGenerator generateCGImagesAsynchronouslyForTimes:times completionHandler:handler];</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"字幕切换\"><a href=\"#字幕切换\" class=\"headerlink\" title=\"字幕切换\"></a>字幕切换</h3><p>AVFoundation在展示字幕和隐藏字幕方面提供了可靠方法。AVPlayerLayer会自动渲染这些元素，并且可以让开发者告诉应用程序哪些元素里面要渲染。完成这些操作需要用到AVMediaSelectionGroup和AVMediaSelectionOption两个类。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">NSArray *mediaCharacteristics = asset.availableMediaCharacteristicsWithMediaSelectionOptions;</span><br><span class=\"line\">    for (NSString *characteristic in mediaCharacteristics) &#123;</span><br><span class=\"line\">        //可选择的轨道组</span><br><span class=\"line\">        AVMediaSelectionGroup *group = [asset mediaSelectionGroupForMediaCharacteristic:characteristic];</span><br><span class=\"line\">        NSLog(@&quot;%@&quot;, characteristic);</span><br><span class=\"line\">        for (AVMediaSelectionOption *option in group.options) &#123;</span><br><span class=\"line\">            //option:轨道组中的轨道</span><br><span class=\"line\">            NSLog(@&quot;Option:%@&quot;, option.displayName);</span><br><span class=\"line\">            </span><br><span class=\"line\">            //- (void)selectMediaOption:(nullable AVMediaSelectionOption *)mediaSelectionOption inMediaSelectionGroup:(AVMediaSelectionGroup *)mediaSelectionGroup</span><br><span class=\"line\">            //对所择轨道的切换，如切换字幕、音频等</span><br><span class=\"line\">            [item selectMediaOption:option inMediaSelectionGroup:group];</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure></p>\n<p>结果显示：<br><img src=\"//www.cyrus.fun/2018/11/08/AVFoundation学习笔记八-AVPlayer及缩略图等相关功能/option_result.png\" alt=\"\"></p>\n<h3 id=\"airplay\"><a href=\"#airplay\" class=\"headerlink\" title=\"airplay\"></a>airplay</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">MPVolumeView *volumeView = [[MPVolumeView alloc] initWithFrame:CGRectZero];</span><br><span class=\"line\">volumeView.showsVolumeSlider = NO;</span><br><span class=\"line\">[volumeView sizeToFit];</span><br><span class=\"line\">[self.view addSubview:volumeView];</span><br></pre></td></tr></table></figure>\n<p>可以弹出airplay播放设备，如mac上的air server，但air Server闪退，原因未知</p>\n"}],"PostAsset":[{"_id":"source/_posts/AVFoundation学习笔记一-iOS多媒体环境/ios_media.png","slug":"ios_media.png","post":"cjo8raw1a0002drd3v6lrnltw","modified":1,"renderable":0},{"_id":"source/_posts/AVFoundation学习笔记二-AVAudioSession/session_category.png","slug":"session_category.png","post":"cjo8raw1w001bdrd3n0g31fwy","modified":1,"renderable":0},{"_id":"source/_posts/AVFoundation学习笔记一-AVSpeechSynthesizer/SpeechSynthesizer.png","post":"cjo8raw170000drd3scbj6pdu","slug":"SpeechSynthesizer.png","modified":1,"renderable":1},{"_id":"source/_posts/AVFoundation学习笔记二-AVAudioPlayer/audioplayer.png","post":"cjo8raw1f0008drd3zcx5t78h","slug":"audioplayer.png","modified":1,"renderable":1},{"_id":"source/_posts/Xcode编译错误-This-application-does-not-support-this-device-s-CPU-type/buildSetting.png","post":"cjo8raw1l000ldrd3dyp6uvoa","slug":"buildSetting.png","modified":1,"renderable":1},{"_id":"source/_posts/主机-三系统/主机.png","slug":"主机.png","post":"cjo8raw1m000ndrd3l9g1bxgt","modified":1,"renderable":0},{"_id":"source/_posts/冒泡排序/冒泡.png","slug":"冒泡.png","post":"cjo8raw1o000sdrd393x278pi","modified":1,"renderable":0},{"_id":"source/_posts/AVFoundation学习笔记七-读取相册内容ALAsset和PHAsset/ALAsset.png","post":"cjo8raw1d0006drd3ven3mgar","slug":"ALAsset.png","modified":1,"renderable":1},{"_id":"source/_posts/AVFoundation学习笔记七-读取相册内容ALAsset和PHAsset/PHAsset.png","post":"cjo8raw1d0006drd3ven3mgar","slug":"PHAsset.png","modified":1,"renderable":1},{"_id":"source/_posts/AVFoundation学习笔记五-AVAudioRecorder/audio_format.png","post":"cjo8raw1g000bdrd3q0ww146v","slug":"audio_format.png","modified":1,"renderable":1},{"_id":"source/_posts/AVFoundation学习笔记五-AVAudioRecorder/recorder.png","post":"cjo8raw1g000bdrd3q0ww146v","slug":"recorder.png","modified":1,"renderable":1},{"_id":"source/_posts/SRS服务器搭建/obs.png","post":"cjo8raw1i000fdrd3jy9vijs7","slug":"obs.png","modified":1,"renderable":1},{"_id":"source/_posts/SRS服务器搭建/result_rtmp.png","slug":"result_rtmp.png","post":"cjo8raw1i000fdrd3jy9vijs7","modified":1,"renderable":0},{"_id":"source/_posts/SRS服务器搭建/rtmp映射.png","post":"cjo8raw1i000fdrd3jy9vijs7","slug":"rtmp映射.png","modified":1,"renderable":1},{"_id":"source/_posts/SRS服务器搭建/vlc.png","post":"cjo8raw1i000fdrd3jy9vijs7","slug":"vlc.png","modified":1,"renderable":1},{"_id":"source/_posts/SRS服务器-二-保存及拉取数据/obs_set.png","post":"cjo8raw1h000cdrd3l6cmdswq","slug":"obs_set.png","modified":1,"renderable":1},{"_id":"source/_posts/SRS服务器-二-保存及拉取数据/play_file.png","slug":"play_file.png","post":"cjo8raw1h000cdrd3l6cmdswq","modified":1,"renderable":0},{"_id":"source/_posts/SRS服务器-二-保存及拉取数据/pushed.png","post":"cjo8raw1h000cdrd3l6cmdswq","slug":"pushed.png","modified":1,"renderable":1},{"_id":"source/_posts/SRS服务器-二-保存及拉取数据/pushing.png","post":"cjo8raw1h000cdrd3l6cmdswq","slug":"pushing.png","modified":1,"renderable":1},{"_id":"source/_posts/SRS服务器-二-保存及拉取数据/vlc_play.png","slug":"vlc_play.png","post":"cjo8raw1h000cdrd3l6cmdswq","modified":1,"renderable":0},{"_id":"source/_posts/AVFoundation学习笔记八-AVPlayer及缩略图等相关功能/option_result.png","post":"cjo8raw1w001cdrd3q3yh1bzg","slug":"option_result.png","modified":1,"renderable":1},{"_id":"source/_posts/AVFoundation学习笔记八-AVPlayer及缩略图等相关功能/player_classes.png","slug":"player_classes.png","post":"cjo8raw1w001cdrd3q3yh1bzg","modified":1,"renderable":0}],"PostCategory":[{"post_id":"cjo8raw1e0007drd3f6rybsde","category_id":"cjo8raw1b0004drd3p6grgq5d","_id":"cjo8raw1i000ddrd3vdg210iw"},{"post_id":"cjo8raw170000drd3scbj6pdu","category_id":"cjo8raw1b0004drd3p6grgq5d","_id":"cjo8raw1k000gdrd38818r6gw"},{"post_id":"cjo8raw1f0008drd3zcx5t78h","category_id":"cjo8raw1b0004drd3p6grgq5d","_id":"cjo8raw1l000jdrd3fu1hz9zx"},{"post_id":"cjo8raw1g000bdrd3q0ww146v","category_id":"cjo8raw1b0004drd3p6grgq5d","_id":"cjo8raw1m000mdrd3kgzmt0de"},{"post_id":"cjo8raw1a0002drd3v6lrnltw","category_id":"cjo8raw1b0004drd3p6grgq5d","_id":"cjo8raw1n000pdrd3xfnr2k3t"},{"post_id":"cjo8raw1d0006drd3ven3mgar","category_id":"cjo8raw1b0004drd3p6grgq5d","_id":"cjo8raw1o000tdrd3xrc2v3wa"},{"post_id":"cjo8raw1h000cdrd3l6cmdswq","category_id":"cjo8raw1l000kdrd3jwixuv8t","_id":"cjo8raw1p000wdrd34qzsvrve"},{"post_id":"cjo8raw1i000fdrd3jy9vijs7","category_id":"cjo8raw1l000kdrd3jwixuv8t","_id":"cjo8raw1p000zdrd398joqh8k"},{"post_id":"cjo8raw1k000idrd3xqpejyw4","category_id":"cjo8raw1p000vdrd315pqxkn7","_id":"cjo8raw1q0013drd3ui1tk6qo"},{"post_id":"cjo8raw1l000ldrd3dyp6uvoa","category_id":"cjo8raw1p0010drd3py8qw6ct","_id":"cjo8raw1q0016drd3jwuklmpx"},{"post_id":"cjo8raw1m000ndrd3l9g1bxgt","category_id":"cjo8raw1q0014drd3fmpdykg6","_id":"cjo8raw1q0019drd36u9esf9m"},{"post_id":"cjo8raw1o000sdrd393x278pi","category_id":"cjo8raw1q0017drd3zdca005w","_id":"cjo8raw1q001adrd3y6duuceu"},{"post_id":"cjo8raw1w001bdrd3n0g31fwy","category_id":"cjo8raw1b0004drd3p6grgq5d","_id":"cjo8raw1z001ddrd3y1vmlryl"},{"post_id":"cjo8raw1w001cdrd3q3yh1bzg","category_id":"cjo8raw1b0004drd3p6grgq5d","_id":"cjo8raw21001edrd3m4o90gdr"}],"PostTag":[{"post_id":"cjo8raw170000drd3scbj6pdu","tag_id":"cjo8raw1d0005drd310akldm4","_id":"cjo8raw1g000adrd3b3ft3ims"},{"post_id":"cjo8raw1h000cdrd3l6cmdswq","tag_id":"cjo8raw1k000hdrd3z2el3c6n","_id":"cjo8raw1o000rdrd3iio04vdi"},{"post_id":"cjo8raw1i000fdrd3jy9vijs7","tag_id":"cjo8raw1k000hdrd3z2el3c6n","_id":"cjo8raw1p000xdrd3p8thjf89"},{"post_id":"cjo8raw1k000idrd3xqpejyw4","tag_id":"cjo8raw1o000udrd3nahll92y","_id":"cjo8raw1p0011drd36dah2nt7"},{"post_id":"cjo8raw1l000ldrd3dyp6uvoa","tag_id":"cjo8raw1p000ydrd3r2ys9608","_id":"cjo8raw1q0015drd3wao6h563"},{"post_id":"cjo8raw1o000sdrd393x278pi","tag_id":"cjo8raw1q0012drd3o1eb30px","_id":"cjo8raw1q0018drd35v91v9jv"}],"Tag":[{"name":"文本语音播报","_id":"cjo8raw1d0005drd310akldm4"},{"name":"SRS","_id":"cjo8raw1k000hdrd3z2el3c6n"},{"name":"TCP/IP","_id":"cjo8raw1o000udrd3nahll92y"},{"name":"Xcode问题","_id":"cjo8raw1p000ydrd3r2ys9608"},{"name":"八大排序","_id":"cjo8raw1q0012drd3o1eb30px"}]}}